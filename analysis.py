

import os
import json
import pandas as pd
import numpy as np
from typing import List, Dict, Any, Optional, Union, Tuple
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# Plotlyç›¸å…³å¯¼å…¥
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.offline as pyo

# SHAPç›¸å…³å¯¼å…¥
import shap
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Axç›¸å…³å¯¼å…¥ï¼ˆç”¨äºsliceplotï¼‰
from ax_optimizer import BayesianOptimizer, ExperimentResult

# æ–°å¢ï¼šæ”¯æŒè‡ªå®šä¹‰ä»£ç†æ¨¡å‹é…ç½®çš„å¯¼å…¥
from typing import Type
from botorch.models import SingleTaskGP, MultiTaskGP
from gpytorch.kernels import MaternKernel, RBFKernel

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class ParameterOptimizationAnalysis:
    """
    å‚æ•°ä¼˜åŒ–åˆ†æå™¨
    
    æä¾›åŸºäºAxæ¡†æ¶çš„å®Œæ•´åˆ†æåŠŸèƒ½ï¼ŒåŒ…æ‹¬æ•°æ®å¯è§†åŒ–ã€æ•æ„Ÿæ€§åˆ†æã€ä¼˜åŒ–è¿›åº¦è·Ÿè¸ªç­‰
    """
    
    def __init__(
        self,
        experiment_data: Optional[pd.DataFrame] = None,
        experiment_file: Optional[str] = None,
        output_dir: str = "analysis_output"
    ):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            experiment_data: å®éªŒæ•°æ®DataFrame
            experiment_file: å®éªŒæ•°æ®æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
        """
        self.experiment_data = experiment_data
        self.experiment_file = experiment_file
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # å¦‚æœæä¾›äº†æ–‡ä»¶è·¯å¾„ï¼ŒåŠ è½½æ•°æ®
        if experiment_file and experiment_data is None:
            self.load_experiment_data(experiment_file)
        
        # åˆå§‹åŒ–åˆ†æç»“æœå­˜å‚¨
        self.analysis_results = {}
        self.plots = {}
        
    def load_experiment_data(self, file_path: str) -> pd.DataFrame:
        """
        åŠ è½½å®éªŒæ•°æ®
        
        Args:
            file_path: æ•°æ®æ–‡ä»¶è·¯å¾„
            
        Returns:
            åŠ è½½çš„æ•°æ®DataFrame
        """
        file_path = Path(file_path)
        
        if file_path.suffix.lower() == '.csv':
            self.experiment_data = pd.read_csv(file_path)
        elif file_path.suffix.lower() in ['.xlsx', '.xls']:
            self.experiment_data = pd.read_excel(file_path)
        elif file_path.suffix.lower() == '.json':
            self.experiment_data = pd.read_json(file_path)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path.suffix}")
        
        print(f"ğŸ“Š æˆåŠŸåŠ è½½æ•°æ®: {len(self.experiment_data)} è¡Œ, {len(self.experiment_data.columns)} åˆ—")
        return self.experiment_data
    
    def get_parameter_types(self) -> Dict[str, str]:
        """
        è·å–å‚æ•°ç±»å‹ä¿¡æ¯
        
        Returns:
            å‚æ•°ç±»å‹å­—å…¸
        """
        if self.experiment_data is None:
            return {}
        
        param_types = {}
        for col in self.experiment_data.columns:
            if self.experiment_data[col].dtype == 'object':
                param_types[col] = 'categorical'
            else:
                param_types[col] = 'numerical'
        
        return param_types
    
    def create_parallel_coordinates_plots(
        self,
        parameters: List[str],
        objectives: List[str],
        color_by: Optional[str] = None,
        title_prefix: str = "å‚æ•°ä¼˜åŒ–å¹¶è¡Œåæ ‡å›¾"
    ) -> Dict[str, go.Figure]:
        """
        åˆ›å»ºå¹¶è¡Œåæ ‡å›¾
        
        Args:
            parameters: è¦å±•ç¤ºçš„å‚æ•°åˆ—è¡¨
            objectives: è¦å±•ç¤ºçš„ç›®æ ‡æŒ‡æ ‡åˆ—è¡¨
            color_by: ç”¨äºç€è‰²çš„æŒ‡æ ‡åç§°ï¼ˆå¯é€‰ï¼‰
            title_prefix: æ ‡é¢˜å‰ç¼€
            
        Returns:
            å¹¶è¡Œåæ ‡å›¾å­—å…¸
        """
        if self.experiment_data is None:
            raise ValueError("æ²¡æœ‰å®éªŒæ•°æ®")
        
        # æ£€æŸ¥å‚æ•°å’Œç›®æ ‡æ˜¯å¦å­˜åœ¨
        all_columns = parameters + objectives
        missing_columns = [col for col in all_columns if col not in self.experiment_data.columns]
        if missing_columns:
            raise ValueError(f"ä»¥ä¸‹åˆ—ä¸å­˜åœ¨äºæ•°æ®ä¸­: {missing_columns}")
        
        # è·å–å‚æ•°ç±»å‹ä¿¡æ¯
        param_types = self.get_parameter_types()
        
        # ç¡®å®šç€è‰²æ–¹å¼
        if color_by is None and objectives:
            color_by = objectives[0]
        elif color_by not in objectives:
            color_by = objectives[0]
        
        plots = {}
        
        # ä¸ºæ¯ä¸ªç›®æ ‡åˆ›å»ºå¹¶è¡Œåæ ‡å›¾
        for objective in objectives:
            print(f"ğŸ“Š ç”Ÿæˆç›®æ ‡ '{objective}' çš„å¹¶è¡Œåæ ‡å›¾...")
            
            # å‡†å¤‡æ•°æ®
            plot_data = self.experiment_data[parameters + [objective]].copy()
            plot_data['trial_index'] = range(len(plot_data))
            
            # åˆ›å»ºå¹¶è¡Œåæ ‡å›¾
            fig = go.Figure(data=
                go.Parcoords(
                    line=dict(
                        color=plot_data[objective],
                        colorscale='Viridis',
                        showscale=True,
                        colorbar=dict(
                            title=f"{objective} (Color Scale)",
                            x=1.1,
                            len=0.8
                        )
                    ),
                    dimensions=[
                        # Trial Index
                        dict(
                            range=[0, len(plot_data) - 1],
                            label='Trial Index',
                            values=plot_data['trial_index'],
                            ticktext=[f"Trial {i+1}" for i in range(len(plot_data))],
                            tickvals=list(range(len(plot_data)))
                        ),
                        # Parameters (handle categorical variables)
                        *[
                            self._create_dimension_for_parameter(
                                param, plot_data[param], param_types.get(param, 'numerical')
                            )
                            for param in parameters
                        ],
                        # Objective
                        dict(
                            range=[plot_data[objective].min(), plot_data[objective].max()],
                            label=f"{objective} (Objective)",
                            values=plot_data[objective],
                            tickformat='.2f'
                        )
                    ],
                    unselected=dict(line=dict(color='lightgray', opacity=0.3))
                )
            )
            
            # Update layout
            fig.update_layout(
                title=dict(
                    text=f"Parallel Coordinates for {objective}",
                    x=0.5,
                    font=dict(size=16)
                ),
                plot_bgcolor='white',
                paper_bgcolor='white',
                font=dict(size=11),
                height=700,
                width=1200,
                margin=dict(l=50, r=150, t=80, b=50)
            )
            
            plots[f"parallel_coords_{objective}"] = fig
        
        self.plots.update(plots)
        return plots
    
    def _create_dimension_for_parameter(
        self,
        param_name: str,
        param_values: pd.Series,
        param_type: str
    ) -> Dict[str, Any]:
        """
        ä¸ºå‚æ•°åˆ›å»ºç»´åº¦é…ç½®
        
        Args:
            param_name: å‚æ•°åç§°
            param_values: å‚æ•°å€¼
            param_type: å‚æ•°ç±»å‹
            
        Returns:
            ç»´åº¦é…ç½®å­—å…¸
        """
        if param_type == 'categorical':
            # ç±»åˆ«å˜é‡å¤„ç†
            unique_values = param_values.unique()
            value_to_index = {val: idx for idx, val in enumerate(unique_values)}
            numeric_values = [value_to_index[val] for val in param_values]
            
            return dict(
                range=[0, len(unique_values) - 1],
                label=f"{param_name} (Categorical)",
                values=numeric_values,
                ticktext=list(unique_values),
                tickvals=list(range(len(unique_values)))
            )
        else:
            # æ•°å€¼å˜é‡å¤„ç†
            return dict(
                range=[param_values.min(), param_values.max()],
                label=f"{param_name} (Numerical)",
                values=param_values,
                tickformat='.2f'
            )
    
    def generate_parallel_coordinates_analysis(
        self,
        parameters: List[str],
        objectives: List[str],
        save_results: bool = True
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆå¹¶è¡Œåæ ‡å›¾åˆ†æ
        
        Args:
            parameters: å‚æ•°åˆ—è¡¨
            objectives: ç›®æ ‡æŒ‡æ ‡åˆ—è¡¨
            save_results: æ˜¯å¦ä¿å­˜ç»“æœ
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        print("ğŸ” å¼€å§‹å¹¶è¡Œåæ ‡å›¾åˆ†æ...")
        
        # ç”Ÿæˆå¹¶è¡Œåæ ‡å›¾
        print("ğŸ“Š ç”Ÿæˆå¹¶è¡Œåæ ‡å›¾...")
        plots = self.create_parallel_coordinates_plots(
            parameters=parameters,
            objectives=objectives
        )
        
        # ä¿å­˜ç»“æœ
        if save_results:
            self.save_plots('html')
        
        print("âœ… å¹¶è¡Œåæ ‡å›¾åˆ†æå®Œæˆ!")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {self.output_dir}")
        
        return {
            'plots': plots,
            'total_plots': len(plots)
        }
    
    def create_feature_importance_analysis(
        self,
        parameters: List[str],
        objectives: List[str],
        model_type: str = 'random_forest',
        test_size: float = 0.2,
        random_state: int = 42
    ) -> Dict[str, Any]:
        """
        åˆ›å»ºç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆåŸºäºSHAPå€¼ï¼‰
        
        Args:
            parameters: ç‰¹å¾å‚æ•°åˆ—è¡¨
            objectives: ç›®æ ‡å˜é‡åˆ—è¡¨
            model_type: æ¨¡å‹ç±»å‹ ('random_forest', 'xgboost', 'lightgbm')
            test_size: æµ‹è¯•é›†æ¯”ä¾‹
            random_state: éšæœºç§å­
            
        Returns:
            ç‰¹å¾é‡è¦æ€§åˆ†æç»“æœ
        """
        if self.experiment_data is None:
            raise ValueError("æ²¡æœ‰å®éªŒæ•°æ®")
        
        print("ğŸ” å¼€å§‹ç‰¹å¾é‡è¦æ€§åˆ†æ...")
        
        # æ£€æŸ¥å‚æ•°å’Œç›®æ ‡æ˜¯å¦å­˜åœ¨
        all_columns = parameters + objectives
        missing_columns = [col for col in all_columns if col not in self.experiment_data.columns]
        if missing_columns:
            raise ValueError(f"ä»¥ä¸‹åˆ—ä¸å­˜åœ¨äºæ•°æ®ä¸­: {missing_columns}")
        
        # è·å–å‚æ•°ç±»å‹ä¿¡æ¯
        param_types = self.get_parameter_types()
        
        # å‡†å¤‡æ•°æ®
        X = self.experiment_data[parameters].copy()
        y_dict = {obj: self.experiment_data[obj] for obj in objectives}
        
        # å¤„ç†ç±»åˆ«å˜é‡
        label_encoders = {}
        for param in parameters:
            if param_types.get(param) == 'categorical':
                le = LabelEncoder()
                X[param] = le.fit_transform(X[param].astype(str))
                label_encoders[param] = le
        
        results = {}
        
        # ä¸ºæ¯ä¸ªç›®æ ‡åˆ›å»ºç‰¹å¾é‡è¦æ€§åˆ†æ
        for objective in objectives:
            print(f"ğŸ“Š ä¸ºç›®æ ‡ '{objective}' ç”Ÿæˆç‰¹å¾é‡è¦æ€§åˆ†æ...")
            
            y = y_dict[objective]
            
            # åˆ†å‰²æ•°æ®
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=random_state
            )
            
            # è®­ç»ƒæ¨¡å‹
            if model_type == 'random_forest':
                model = RandomForestRegressor(
                    n_estimators=100,
                    random_state=random_state,
                    n_jobs=-1
                )
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
            
            model.fit(X_train, y_train)
            
            # è®¡ç®—SHAPå€¼
            explainer = shap.TreeExplainer(model)
            shap_values = explainer.shap_values(X_test)
            
            # åˆ›å»ºç‰¹å¾é‡è¦æ€§å›¾
            feature_importance_fig = self._create_feature_importance_plot(
                X=X_test,
                y=y_test,
                shap_values=shap_values,
                feature_names=parameters,
                target_name=objective
            )
            
            # ä¿å­˜åˆ°plotså­—å…¸
            self.plots[f'feature_importance_{objective}'] = feature_importance_fig
            
            results[objective] = {
                'model': model,
                'explainer': explainer,
                'shap_values': shap_values,
                'feature_importance_plot': feature_importance_fig,
                'label_encoders': label_encoders
            }
        
        print("âœ… ç‰¹å¾é‡è¦æ€§åˆ†æå®Œæˆ!")
        return results
    
    def _create_feature_importance_plot(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        shap_values: np.ndarray,
        feature_names: List[str],
        target_name: str
    ) -> go.Figure:
        """
        åˆ›å»ºç‰¹å¾é‡è¦æ€§æ¡å½¢å›¾
        """
        # è®¡ç®—å¹³å‡SHAPå€¼
        mean_shap_values = np.abs(shap_values).mean(axis=0)
        
        # åˆ›å»ºæ¡å½¢å›¾
        fig = go.Figure(data=[
            go.Bar(
                x=mean_shap_values,
                y=feature_names,
                orientation='h',
                marker_color='#1f77b4',  # ä½¿ç”¨æ›´å¥½çœ‹çš„è“è‰²
                hovertemplate='<b>%{y}</b><br>' +
                            'Average SHAP Impact: %{x:.3f}<br>' +
                            '<extra></extra>'
            )
        ])
        
        fig.update_layout(
            title=dict(
                text=f"Feature Importance Analysis for {target_name}",
                x=0.5,  # æ ‡é¢˜å±…ä¸­
                font=dict(size=16)
            ),
            xaxis_title=f"Average SHAP Impact on {target_name}",
            yaxis_title="Features",
            plot_bgcolor='white',
            paper_bgcolor='white',
            height=500,
            width=800,
            margin=dict(l=50, r=50, t=80, b=50),
            # å›¾è¡¨æ•´ä½“å±…ä¸­
            xaxis=dict(
                showgrid=True,
                gridwidth=1,
                gridcolor='lightgray',
                zeroline=False
            ),
            yaxis=dict(
                showgrid=False,
                zeroline=False
            )
        )
        
        return fig
    
    def create_slice_plots(
        self,
        parameters: List[str],
        objectives: List[str],
        search_space: List[Dict[str, Any]],
        n_points: int = 100,
        confidence_level: float = 0.95,
        # æ–°å¢ï¼šè‡ªå®šä¹‰ä»£ç†æ¨¡å‹é…ç½®å‚æ•°
        surrogate_model_class: Optional[Type] = None,
        kernel_class: Optional[Type] = None,
        kernel_options: Optional[Dict[str, Any]] = None
    ) -> Dict[str, go.Figure]:
        """
        åˆ›å»ºsliceå›¾ï¼Œå±•ç¤ºå•ä¸€å‚æ•°å¯¹ç›®æ ‡çš„å½±å“åŠç½®ä¿¡åŒºé—´
        åŸºäºAxçš„SlicePlotå®ç°ï¼Œå½“ä¸”ä»…å½“æ‰€æœ‰å‚æ•°éƒ½æ˜¯rangeç±»å‹æ—¶ç”Ÿæˆ
        
        Args:
            parameters: å‚æ•°åˆ—è¡¨
            objectives: ç›®æ ‡æŒ‡æ ‡åˆ—è¡¨
            search_space: æœç´¢ç©ºé—´é…ç½®ï¼ˆå¿…é¡»æä¾›ï¼‰
            n_points: é¢„æµ‹ç‚¹çš„æ•°é‡
            confidence_level: ç½®ä¿¡åŒºé—´æ°´å¹³
            
        Returns:
            åˆ‡ç‰‡å›¾å­—å…¸
        """
        if self.experiment_data is None:
            raise ValueError("æ²¡æœ‰å®éªŒæ•°æ®")
        
        # æ£€æŸ¥å‚æ•°å’Œç›®æ ‡æ˜¯å¦å­˜åœ¨
        all_columns = parameters + objectives
        missing_columns = [col for col in all_columns if col not in self.experiment_data.columns]
        if missing_columns:
            raise ValueError(f"ä»¥ä¸‹åˆ—ä¸å­˜åœ¨äºæ•°æ®ä¸­: {missing_columns}")
        
        # è·å–å‚æ•°ç±»å‹ä¿¡æ¯
        param_types = self.get_parameter_types()
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å‚æ•°éƒ½æ˜¯rangeç±»å‹ï¼ˆæ’é™¤ç±»åˆ«å‚æ•°ï¼‰
        range_params = []
        categorical_params = []
        discrete_numeric_params = []
        
        for param in parameters:
            param_data = self.experiment_data[param]
            if pd.api.types.is_numeric_dtype(param_data):
                # æ£€æŸ¥æ˜¯å¦ä¸ºè¿ç»­æ•°å€¼å˜é‡
                unique_values = sorted(param_data.unique())
                if len(unique_values) > 10:  # å¦‚æœå”¯ä¸€å€¼æ•°é‡å¤šï¼Œè®¤ä¸ºæ˜¯rangeç±»å‹
                    range_params.append(param)
                else:
                    discrete_numeric_params.append(param)
                    print(f"  âš ï¸ å‚æ•° '{param}' æ˜¯ç¦»æ•£æ•°å€¼ç±»å‹ï¼ˆå”¯ä¸€å€¼æ•°é‡: {len(unique_values)}ï¼‰")
            else:
                categorical_params.append(param)
                print(f"  âš ï¸ å‚æ•° '{param}' æ˜¯ç±»åˆ«ç±»å‹")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç±»åˆ«å‚æ•°
        if categorical_params:
            print(f"âŒ å‘ç°ç±»åˆ«å‚æ•°: {categorical_params}")
            print("âŒ åŒ…å«ç±»åˆ«å‚æ•°çš„å®éªŒä¸ç”Ÿæˆsliceå›¾")
            return {}
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¦»æ•£æ•°å€¼å‚æ•°
        if discrete_numeric_params:
            print(f"âŒ å‘ç°ç¦»æ•£æ•°å€¼å‚æ•°: {discrete_numeric_params}")
            print("âŒ åŒ…å«ç¦»æ•£æ•°å€¼å‚æ•°çš„å®éªŒä¸ç”Ÿæˆsliceå›¾")
            return {}
        
        # åªæœ‰å½“æ‰€æœ‰å‚æ•°éƒ½æ˜¯è¿ç»­rangeç±»å‹æ—¶æ‰ç”Ÿæˆsliceå›¾
        if not range_params:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°è¿ç»­rangeç±»å‹çš„å‚æ•°ï¼Œæ— æ³•ç”Ÿæˆsliceå›¾")
            return {}
        
        if not range_params:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°rangeç±»å‹çš„å‚æ•°ï¼Œæ— æ³•ç”Ÿæˆsliceå›¾")
            return {}
        
        print(f"âœ… æ‰€æœ‰å‚æ•°éƒ½æ˜¯rangeç±»å‹: {range_params}")
        
        # é‡å»ºAxä¼˜åŒ–å™¨å’Œä»£ç†æ¨¡å‹
        print("ğŸ”§ é‡å»ºAxä¼˜åŒ–å™¨å’Œä»£ç†æ¨¡å‹...")
        ax_optimizer = self._rebuild_ax_optimizer(
            parameters=parameters,
            objectives=objectives,
            search_space=search_space,
            # ä¼ é€’è‡ªå®šä¹‰ä»£ç†æ¨¡å‹é…ç½®
            surrogate_model_class=surrogate_model_class,
            kernel_class=kernel_class,
            kernel_options=kernel_options
        )
        
        plots = {}
        
        # ä¸ºæ¯ä¸ªç›®æ ‡åˆ›å»ºsliceå›¾
        for objective in objectives:
            print(f"ğŸ“Š ä¸ºç›®æ ‡ '{objective}' ç”Ÿæˆsliceå›¾...")
            
            # åªä¸ºrangeå‚æ•°åˆ›å»ºsliceå›¾
            for param in range_params:
                print(f"  ğŸ“ˆ ç”Ÿæˆå‚æ•° '{param}' çš„sliceå›¾...")
                
                slice_fig = self._create_single_slice_plot_with_ax(
                    ax_optimizer=ax_optimizer,
                    param=param,
                    objective=objective,
                    param_types=param_types,
                    n_points=n_points,
                    confidence_level=confidence_level
                )
                
                plot_key = f"slice_{objective}_{param}"
                plots[plot_key] = slice_fig
                self.plots[plot_key] = slice_fig
        
        return plots
    
    def create_contour_plots(
        self,
        parameters: List[str],
        objectives: List[str],
        search_space: List[Dict[str, Any]],
        n_points: int = 50,
        confidence_level: float = 0.95,
        # æ–°å¢ï¼šè‡ªå®šä¹‰ä»£ç†æ¨¡å‹é…ç½®å‚æ•°
        surrogate_model_class: Optional[Type] = None,
        kernel_class: Optional[Type] = None,
        kernel_options: Optional[Dict[str, Any]] = None
    ) -> Dict[str, go.Figure]:
        """
        åˆ›å»ºç­‰é«˜çº¿å›¾ï¼Œå±•ç¤ºä¸¤ä¸ªå‚æ•°å¯¹ç›®æ ‡çš„å½±å“
        åŸºäºAxçš„ContourPlotå®ç°ï¼Œå½“ä¸”ä»…å½“æ‰€æœ‰å‚æ•°éƒ½æ˜¯rangeç±»å‹æ—¶ç”Ÿæˆ
        
        Args:
            parameters: å‚æ•°åˆ—è¡¨ï¼ˆéœ€è¦è‡³å°‘2ä¸ªå‚æ•°ï¼‰
            objectives: ç›®æ ‡æŒ‡æ ‡åˆ—è¡¨
            search_space: æœç´¢ç©ºé—´é…ç½®ï¼ˆå¿…é¡»æä¾›ï¼‰
            n_points: ç½‘æ ¼å¯†åº¦ï¼ˆn_points x n_pointsï¼‰
            confidence_level: ç½®ä¿¡åŒºé—´æ°´å¹³
            
        Returns:
            ç­‰é«˜çº¿å›¾å­—å…¸
        """
        if self.experiment_data is None:
            raise ValueError("æ²¡æœ‰å®éªŒæ•°æ®")
        
        # æ£€æŸ¥å‚æ•°å’Œç›®æ ‡æ˜¯å¦å­˜åœ¨
        all_columns = parameters + objectives
        missing_columns = [col for col in all_columns if col not in self.experiment_data.columns]
        if missing_columns:
            raise ValueError(f"ä»¥ä¸‹åˆ—ä¸å­˜åœ¨äºæ•°æ®ä¸­: {missing_columns}")
        
        # æ£€æŸ¥å‚æ•°æ•°é‡
        if len(parameters) < 2:
            print("âŒ ç­‰é«˜çº¿å›¾éœ€è¦è‡³å°‘2ä¸ªå‚æ•°")
            return {}
        
        # è·å–å‚æ•°ç±»å‹ä¿¡æ¯
        param_types = self.get_parameter_types()
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å‚æ•°éƒ½æ˜¯rangeç±»å‹
        range_params = []
        categorical_params = []
        discrete_numeric_params = []
        
        for param in parameters:
            param_data = self.experiment_data[param]
            if pd.api.types.is_numeric_dtype(param_data):
                unique_values = sorted(param_data.unique())
                if len(unique_values) > 10:
                    range_params.append(param)
                else:
                    discrete_numeric_params.append(param)
                    print(f"  âš ï¸ å‚æ•° '{param}' æ˜¯ç¦»æ•£æ•°å€¼ç±»å‹ï¼ˆå”¯ä¸€å€¼æ•°é‡: {len(unique_values)}ï¼‰")
            else:
                categorical_params.append(param)
                print(f"  âš ï¸ å‚æ•° '{param}' æ˜¯ç±»åˆ«ç±»å‹")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç±»åˆ«å‚æ•°
        if categorical_params:
            print(f"âŒ å‘ç°ç±»åˆ«å‚æ•°: {categorical_params}")
            print("âŒ åŒ…å«ç±»åˆ«å‚æ•°çš„å®éªŒä¸ç”Ÿæˆç­‰é«˜çº¿å›¾")
            return {}
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¦»æ•£æ•°å€¼å‚æ•°
        if discrete_numeric_params:
            print(f"âŒ å‘ç°ç¦»æ•£æ•°å€¼å‚æ•°: {discrete_numeric_params}")
            print("âŒ åŒ…å«ç¦»æ•£æ•°å€¼å‚æ•°çš„å®éªŒä¸ç”Ÿæˆç­‰é«˜çº¿å›¾")
            return {}
        
        # åªæœ‰å½“æ‰€æœ‰å‚æ•°éƒ½æ˜¯è¿ç»­rangeç±»å‹æ—¶æ‰ç”Ÿæˆç­‰é«˜çº¿å›¾
        if len(range_params) < 2:
            print("âŒ æ²¡æœ‰è¶³å¤Ÿçš„è¿ç»­rangeç±»å‹å‚æ•°ï¼Œæ— æ³•ç”Ÿæˆç­‰é«˜çº¿å›¾")
            return {}
        
        print(f"âœ… æ‰€æœ‰å‚æ•°éƒ½æ˜¯rangeç±»å‹: {range_params}")
        
        # é‡å»ºAxä¼˜åŒ–å™¨å’Œä»£ç†æ¨¡å‹
        print("ğŸ”§ é‡å»ºAxä¼˜åŒ–å™¨å’Œä»£ç†æ¨¡å‹...")
        ax_optimizer = self._rebuild_ax_optimizer(
            parameters=parameters,
            objectives=objectives,
            search_space=search_space,
            # ä¼ é€’è‡ªå®šä¹‰ä»£ç†æ¨¡å‹é…ç½®
            surrogate_model_class=surrogate_model_class,
            kernel_class=kernel_class,
            kernel_options=kernel_options
        )
        
        plots = {}
        
        # ä¸ºæ¯ä¸ªç›®æ ‡åˆ›å»ºç­‰é«˜çº¿å›¾
        for objective in objectives:
            print(f"ğŸ“Š ä¸ºç›®æ ‡ '{objective}' ç”Ÿæˆç­‰é«˜çº¿å›¾...")
            
            # ä¸ºæ¯å¯¹rangeå‚æ•°åˆ›å»ºç­‰é«˜çº¿å›¾
            for i in range(len(range_params)):
                for j in range(i + 1, len(range_params)):
                    param1 = range_params[i]
                    param2 = range_params[j]
                    
                    print(f"  ğŸ“ˆ ç”Ÿæˆå‚æ•° '{param1}' vs '{param2}' çš„ç­‰é«˜çº¿å›¾...")
                    
                    contour_fig = self._create_single_contour_plot_with_ax(
                        ax_optimizer=ax_optimizer,
                        param1=param1,
                        param2=param2,
                        objective=objective,
                        param_types=param_types,
                        n_points=n_points,
                        confidence_level=confidence_level
                    )
                    
                    plot_key = f"contour_{objective}_{param1}_{param2}"
                    plots[plot_key] = contour_fig
                    self.plots[plot_key] = contour_fig
        
        return plots
    
    def _create_single_contour_plot_with_ax(
        self,
        ax_optimizer,
        param1: str,
        param2: str,
        objective: str,
        param_types: Dict[str, str],
        n_points: int,
        confidence_level: float
    ) -> go.Figure:
        """
        ä½¿ç”¨Axä¼˜åŒ–å™¨çš„ä»£ç†æ¨¡å‹åˆ›å»ºä¸¤ä¸ªå‚æ•°çš„ç­‰é«˜çº¿å›¾
        åŸºäºAxçš„ContourPlotå®ç°
        """
        try:
            # è·å–Axçš„å®éªŒæ•°æ®
            trials_df = ax_optimizer.get_optimization_history()
            
            # è·å–å‚æ•°å€¼èŒƒå›´
            param1_values = np.linspace(
                trials_df[param1].min(),
                trials_df[param1].max(),
                n_points
            )
            param2_values = np.linspace(
                trials_df[param2].min(),
                trials_df[param2].max(),
                n_points
            )
            
            # åˆ›å»ºç½‘æ ¼
            param1_grid, param2_grid = np.meshgrid(param1_values, param2_values)
            
            # è®¡ç®—status_quoå€¼ï¼ˆå…¶ä»–å‚æ•°çš„å‡å€¼ï¼‰
            other_params = [p for p in trials_df.columns if p in param_types.keys() and p not in [param1, param2]]
            status_quo = {}
            for p in other_params:
                if pd.api.types.is_numeric_dtype(trials_df[p]):
                    status_quo[p] = trials_df[p].mean()
                else:
                    status_quo[p] = trials_df[p].mode().iloc[0] if not trials_df[p].mode().empty else trials_df[p].iloc[0]
            
            status_quo = pd.Series(status_quo)
            
            # ç”Ÿæˆé¢„æµ‹ç½‘æ ¼
            predictions_grid = np.zeros((n_points, n_points))
            
            for i in range(n_points):
                for j in range(n_points):
                    try:
                        # åˆ›å»ºé¢„æµ‹æ•°æ®ç‚¹
                        X_pred = status_quo.copy()
                        X_pred[param1] = param1_grid[i, j]
                        X_pred[param2] = param2_grid[i, j]
                        
                        # ä½¿ç”¨Axçš„é¢„æµ‹æ–¹æ³•
                        predictions_dict = ax_optimizer.ax_client.get_model_predictions(
                            metric_names=[objective],
                            parameterizations={0: X_pred.to_dict()}
                        )
                        
                        if 0 in predictions_dict and objective in predictions_dict[0]:
                            pred_mean, _ = predictions_dict[0][objective]
                            predictions_grid[i, j] = pred_mean
                        else:
                            predictions_grid[i, j] = 0.0
                            
                    except Exception as e:
                        predictions_grid[i, j] = 0.0
            
            # åˆ›å»ºç­‰é«˜çº¿å›¾
            fig = go.Figure()
            
            # æ·»åŠ ç­‰é«˜çº¿
            fig.add_trace(go.Contour(
                x=param1_values,
                y=param2_values,
                z=predictions_grid,
                colorscale='Viridis',
                contours=dict(
                    coloring='heatmap',
                    showlabels=True,
                    labelfont=dict(size=12, color='white')
                ),
                colorbar=dict(
                    title=dict(text=objective)
                ),
                name='Predicted Outcome'
            ))
            
            # æ·»åŠ å®é™…è§‚æµ‹ç‚¹
            fig.add_trace(go.Scatter(
                x=trials_df[param1],
                y=trials_df[param2],
                mode='markers',
                marker=dict(
                    color='red',
                    size=8,
                    symbol='circle'
                ),
                name='Actual Observations',
                hovertemplate=f'<b>{param1}</b>: %{{x}}<br>' +
                             f'<b>{param2}</b>: %{{y}}<br>' +
                             f'<b>{objective}</b>: %{{text}}<br>' +
                             '<extra></extra>',
                text=trials_df[objective]
            ))
            
            # æ›´æ–°å¸ƒå±€
            fig.update_layout(
                title=dict(
                    text=f"{param1} vs {param2} vs {objective} (Contour Plot)",
                    x=0.5,
                    font=dict(size=16)
                ),
                xaxis_title=param1,
                yaxis_title=param2,
                plot_bgcolor='white',
                paper_bgcolor='white',
                height=600,
                width=800,
                margin=dict(l=50, r=50, t=80, b=50),
                showlegend=True,
                legend=dict(
                    x=0.02,
                    y=0.98,
                    bgcolor='rgba(255, 255, 255, 0.8)',
                    bordercolor='lightgray',
                    borderwidth=1
                )
            )
            
            # æ·»åŠ ç½‘æ ¼
            fig.update_xaxes(
                showgrid=True,
                gridwidth=1,
                gridcolor='lightgray'
            )
            fig.update_yaxes(
                showgrid=True,
                gridwidth=1,
                gridcolor='lightgray'
            )
            
            return fig
            
        except Exception as e:
            print(f"      âš ï¸ åˆ›å»ºç­‰é«˜çº¿å›¾å¤±è´¥: {e}")
            # è¿”å›ç©ºå›¾è¡¨
            fig = go.Figure()
            fig.add_annotation(
                text=f"ç­‰é«˜çº¿å›¾åˆ›å»ºå¤±è´¥: {e}",
                xref="paper", yref="paper",
                x=0.5, y=0.5, showarrow=False
            )
            return fig
    
    def _create_single_slice_plot_with_ax(
        self,
        ax_optimizer,
        param: str,
        objective: str,
        param_types: Dict[str, str],
        n_points: int,
        confidence_level: float
    ) -> go.Figure:
        """
        ä½¿ç”¨Axä¼˜åŒ–å™¨çš„ä»£ç†æ¨¡å‹åˆ›å»ºå•ä¸ªå‚æ•°çš„sliceå›¾
        åŸºäºAxçš„SlicePlotå®ç°
        """
        try:
            # è·å–Axçš„å®éªŒæ•°æ®
            trials_df = ax_optimizer.get_optimization_history()
            
            # è·å–å‚æ•°å€¼èŒƒå›´
            param_values = self._get_parameter_values_for_slice(param, n_points)
            
            # è·å–å·²é‡‡æ ·çš„å‚æ•°å€¼
            sampled_values = sorted(trials_df[param].unique())
            
            # è®¡ç®—status_quoå€¼ï¼ˆå…¶ä»–å‚æ•°çš„å‡å€¼æˆ–ä¼—æ•°ï¼‰
            other_params = [p for p in trials_df.columns if p in param_types.keys() and p != param]
            status_quo = {}
            for p in other_params:
                if pd.api.types.is_numeric_dtype(trials_df[p]):
                    status_quo[p] = trials_df[p].mean()
                else:
                    # å¯¹äºç±»åˆ«å‚æ•°ï¼Œä½¿ç”¨ä¼—æ•°
                    status_quo[p] = trials_df[p].mode().iloc[0] if not trials_df[p].mode().empty else trials_df[p].iloc[0]
            
            status_quo = pd.Series(status_quo)
            
            # ç”Ÿæˆé¢„æµ‹æ•°æ®
            predictions = []
            confidence_intervals = []
            sampled_mask = []
            
            # å¯¹æ¯ä¸ªå‚æ•°å€¼è¿›è¡Œé¢„æµ‹
            for param_val in param_values:
                try:
                    # åˆ›å»ºé¢„æµ‹æ•°æ®ç‚¹ï¼ˆå›ºå®šå…¶ä»–å‚æ•°ä¸ºstatus_quoå€¼ï¼‰
                    X_pred = status_quo.copy()
                    X_pred[param] = param_val
                    
                    # ä½¿ç”¨Axçš„é¢„æµ‹æ–¹æ³•
                    predictions_dict = ax_optimizer.ax_client.get_model_predictions(
                        metric_names=[objective],
                        parameterizations={0: X_pred.to_dict()}
                    )
                    
                    if 0 in predictions_dict and objective in predictions_dict[0]:
                        pred_mean, pred_std = predictions_dict[0][objective]
                        
                        # è®¡ç®—ç½®ä¿¡åŒºé—´
                        z_score = 1.96  # 95%ç½®ä¿¡åŒºé—´
                        ci_lower = pred_mean - z_score * pred_std
                        ci_upper = pred_mean + z_score * pred_std
                        
                        predictions.append(pred_mean)
                        confidence_intervals.append([ci_lower, ci_upper])
                        
                        # æ£€æŸ¥è¿™ä¸ªå‚æ•°å€¼æ˜¯å¦åœ¨é‡‡æ ·å€¼ä¸­ï¼ˆä½¿ç”¨å®¹å·®æ¯”è¾ƒï¼‰
                        is_sampled = False
                        for sampled_val in sampled_values:
                            if abs(param_val - sampled_val) < 1e-6:  # ä½¿ç”¨å°çš„å®¹å·®
                                is_sampled = True
                                break
                        sampled_mask.append(is_sampled)
                    else:
                        print(f"      âš ï¸ é¢„æµ‹å¤±è´¥ï¼Œå‚æ•°å€¼={param_val}ï¼Œé¢„æµ‹ç»“æœæ— æ•ˆ")
                        predictions.append(0.0)
                        confidence_intervals.append([0.0, 0.0])
                        sampled_mask.append(False)
                        
                except Exception as e:
                    print(f"      âš ï¸ é¢„æµ‹å¤±è´¥ï¼Œå‚æ•°å€¼={param_val}ï¼Œé”™è¯¯: {e}")
                    predictions.append(0.0)
                    confidence_intervals.append([0.0, 0.0])
                    sampled_mask.append(False)
            
            # åˆ›å»ºå›¾è¡¨
            fig = go.Figure()
            
            # æ·»åŠ ç½®ä¿¡åŒºé—´
            fig.add_trace(go.Scatter(
                x=param_values,
                y=[ci[1] for ci in confidence_intervals],
                mode='lines',
                line=dict(width=0),
                showlegend=False,
                hoverinfo='skip'
            ))
            
            fig.add_trace(go.Scatter(
                x=param_values,
                y=[ci[0] for ci in confidence_intervals],
                mode='lines',
                line=dict(width=0),
                fill='tonexty',
                fillcolor='rgba(31, 119, 180, 0.2)',
                showlegend=False,
                hoverinfo='skip'
            ))
            
            # æ·»åŠ é¢„æµ‹çº¿
            fig.add_trace(go.Scatter(
                x=param_values,
                y=predictions,
                mode='lines',
                line=dict(color='#1f77b4', width=2),
                name='Predicted Outcome ',
                hovertemplate=f'<b>{param}</b>: %{{x}}<br>' +
                             f'<b>{objective} (Predicted)</b>: %{{y:.3f}}<br>' +
                             '<extra></extra>'
            ))
            
            # æ·»åŠ å·²é‡‡æ ·ç‚¹æ ‡è®°
            sampled_indices = [i for i, sampled in enumerate(sampled_mask) if sampled]
            if sampled_indices:
                # è·å–å·²é‡‡æ ·ç‚¹çš„å®é™…è§‚æµ‹å€¼ï¼ˆè€Œä¸æ˜¯é¢„æµ‹å€¼ï¼‰
                sampled_x = [param_values[i] for i in sampled_indices]
                sampled_y = []
                
                # ä»åŸå§‹æ•°æ®ä¸­è·å–å·²é‡‡æ ·ç‚¹çš„å®é™…è§‚æµ‹å€¼
                for x_val in sampled_x:
                    # æ‰¾åˆ°æœ€æ¥è¿‘çš„é‡‡æ ·ç‚¹
                    closest_idx = None
                    min_diff = float('inf')
                    for idx, row in trials_df.iterrows():
                        if abs(row[param] - x_val) < min_diff:
                            min_diff = abs(row[param] - x_val)
                            closest_idx = idx
                    
                    if closest_idx is not None:
                        sampled_y.append(trials_df.iloc[closest_idx][objective])
                    else:
                        sampled_y.append(predictions[sampled_indices[sampled_indices.index(x_val)]])
                
                fig.add_trace(go.Scatter(
                    x=sampled_x,
                    y=sampled_y,
                    mode='markers',
                    marker=dict(
                        color='black',
                        symbol='x',
                        size=8
                    ),
                    name='Sampled Points',
                    hovertemplate=f'<b>{param}</b>: %{{x}}<br>' +
                                 f'<b>{objective} (Observed)</b>: %{{y:.3f}}<br>' +
                                 '<extra></extra>'
                ))
            
            # æ›´æ–°å¸ƒå±€
            fig.update_layout(
                title=dict(
                    text=f"{param} vs {objective} (Slice Plot)",
                    x=0.5,
                    font=dict(size=16)
                ),
                xaxis_title=param,
                yaxis_title=objective,
                plot_bgcolor='white',
                paper_bgcolor='white',
                height=500,
                width=800,
                margin=dict(l=50, r=50, t=80, b=50),
                showlegend=True,
                legend=dict(
                    x=0.02,
                    y=0.98,
                    bgcolor='rgba(255, 255, 255, 0.8)',
                    bordercolor='lightgray',
                    borderwidth=1
                )
            )
            
            # æ·»åŠ ç½‘æ ¼
            fig.update_xaxes(
                showgrid=True,
                gridwidth=1,
                gridcolor='lightgray',
                zeroline=False
            )
            fig.update_yaxes(
                showgrid=True,
                gridwidth=1,
                gridcolor='lightgray',
                zeroline=False
            )
            
            return fig
            
        except Exception as e:
            print(f"    âŒ ä½¿ç”¨Axæ¨¡å‹åˆ›å»ºsliceå›¾å¤±è´¥: {e}")
            # å¦‚æœAxæ¨¡å‹å¤±è´¥ï¼Œè¿”å›é”™è¯¯å›¾è¡¨
            fig = go.Figure()
            fig.add_annotation(
                text=f"æ— æ³•åˆ›å»ºsliceå›¾<br>é”™è¯¯: {str(e)}",
                xref="paper", yref="paper",
                x=0.5, y=0.5,
                showarrow=False,
                font=dict(size=14, color="red")
            )
            fig.update_layout(
                title=f"{param} vs {objective} (Error)",
                plot_bgcolor='white',
                paper_bgcolor='white',
                height=500,
                width=800
            )
            return fig
    
    def _rebuild_ax_optimizer(
        self,
        parameters: List[str],
        objectives: List[str],
        search_space: List[Dict[str, Any]],
        # æ–°å¢ï¼šè‡ªå®šä¹‰ä»£ç†æ¨¡å‹é…ç½®å‚æ•°
        surrogate_model_class: Optional[Type] = None,
        kernel_class: Optional[Type] = None,
        kernel_options: Optional[Dict[str, Any]] = None
    ) -> BayesianOptimizer:
        """
        åŸºäºå®éªŒæ•°æ®é‡å»ºAxä¼˜åŒ–å™¨
        
        Args:
            parameters: å‚æ•°åˆ—è¡¨
            objectives: ç›®æ ‡åˆ—è¡¨
            search_space: æœç´¢ç©ºé—´é…ç½®ï¼ˆå¿…é¡»æä¾›ï¼‰
            surrogate_model_class: ä»£ç†æ¨¡å‹ç±»ï¼ˆå¯é€‰ï¼Œå¦‚SingleTaskGPã€MultiTaskGPç­‰ï¼‰
            kernel_class: æ ¸å‡½æ•°ç±»ï¼ˆå¯é€‰ï¼Œå¦‚MaternKernelã€RBFKernelç­‰ï¼‰
            kernel_options: æ ¸å‡½æ•°å‚æ•°ï¼ˆå¯é€‰ï¼Œå¦‚{"nu": 2.5}ç”¨äºMaternKernelï¼‰
            
        Returns:
            é‡å»ºçš„Axä¼˜åŒ–å™¨å®ä¾‹
        """
        # ä»æ•°æ®æ¨æ–­ä¼˜åŒ–é…ç½®ï¼ˆç”¨äºåˆ›å»ºå®éªŒï¼Œä¸å½±å“é¢„æµ‹ï¼‰
        optimization_config = self._infer_optimization_config(objectives)
        
        # åˆ›å»ºä¼˜åŒ–å™¨ï¼Œæ”¯æŒè‡ªå®šä¹‰ä»£ç†æ¨¡å‹é…ç½®
        optimizer = BayesianOptimizer(
            search_space=search_space,
            optimization_config=optimization_config,
            experiment_name="experiment_rebuild",
            random_seed=42,
            # ä¼ é€’è‡ªå®šä¹‰ä»£ç†æ¨¡å‹é…ç½®
            surrogate_model_class=surrogate_model_class,
            kernel_class=kernel_class,
            kernel_options=kernel_options
        )
        
        # å°†å®éªŒæ•°æ®è½¬æ¢ä¸ºExperimentResultæ ¼å¼
        experiments = []
        for _, row in self.experiment_data.iterrows():
            # å¤„ç†å‚æ•°ä¸­çš„Noneå€¼
            exp_params = {}
            for param in parameters:
                val = row[param]
                # å¤„ç†Noneå€¼ï¼Œå°†å…¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²"None"
                if pd.isna(val) or val is None:
                    exp_params[param] = "None"
                else:
                    exp_params[param] = val
            
            exp_metrics = {obj: row[obj] for obj in objectives}
            experiments.append(ExperimentResult(
                parameters=exp_params,
                metrics=exp_metrics
            ))
        
        # æ·»åŠ å…ˆéªŒå®éªŒæ•°æ®
        optimizer.add_prior_experiments(experiments)
        
        return optimizer
    
    def create_cross_validation_plots(
        self,
        parameters: List[str],
        objectives: List[str],
        search_space: List[Dict[str, Any]],
        untransform: bool = True,
        # æ–°å¢ï¼šè‡ªå®šä¹‰ä»£ç†æ¨¡å‹é…ç½®å‚æ•°
        surrogate_model_class: Optional[Type] = None,
        kernel_class: Optional[Type] = None,
        kernel_options: Optional[Dict[str, Any]] = None
    ) -> Dict[str, go.Figure]:
        """
        åˆ›å»ºç•™ä¸€æ³•äº¤å‰éªŒè¯å›¾ï¼Œå±•ç¤ºæ¨¡å‹é¢„æµ‹å‡†ç¡®æ€§
        åŸºäºAxä»£ç†æ¨¡å‹çš„å®ç°
        
        Args:
            parameters: å‚æ•°åˆ—è¡¨
            objectives: ç›®æ ‡æŒ‡æ ‡åˆ—è¡¨
            search_space: æœç´¢ç©ºé—´é…ç½®ï¼ˆå¿…é¡»æä¾›ï¼‰
            untransform: æ˜¯å¦åå˜æ¢é¢„æµ‹ç»“æœ
            
        Returns:
            äº¤å‰éªŒè¯å›¾å­—å…¸
        """
        if self.experiment_data is None:
            raise ValueError("æ²¡æœ‰å®éªŒæ•°æ®")
        
        # æ£€æŸ¥å‚æ•°å’Œç›®æ ‡æ˜¯å¦å­˜åœ¨
        all_columns = parameters + objectives
        missing_columns = [col for col in all_columns if col not in self.experiment_data.columns]
        if missing_columns:
            raise ValueError(f"ä»¥ä¸‹åˆ—ä¸å­˜åœ¨äºæ•°æ®ä¸­: {missing_columns}")
        
        print(f"ğŸ” å¼€å§‹ç•™ä¸€æ³•äº¤å‰éªŒè¯åˆ†æ...")
        
        # é‡å»ºAxä¼˜åŒ–å™¨å’Œä»£ç†æ¨¡å‹
        print("ğŸ”§ é‡å»ºAxä¼˜åŒ–å™¨å’Œä»£ç†æ¨¡å‹...")
        ax_optimizer = self._rebuild_ax_optimizer(
            parameters=parameters,
            objectives=objectives,
            search_space=search_space,
            # ä¼ é€’è‡ªå®šä¹‰ä»£ç†æ¨¡å‹é…ç½®
            surrogate_model_class=surrogate_model_class,
            kernel_class=kernel_class,
            kernel_options=kernel_options
        )
        
        plots = {}
        
        # ä¸ºæ¯ä¸ªç›®æ ‡åˆ›å»ºäº¤å‰éªŒè¯å›¾
        for objective in objectives:
            print(f"ğŸ“Š ä¸ºç›®æ ‡ '{objective}' ç”Ÿæˆäº¤å‰éªŒè¯å›¾...")
            
            cv_fig = self._create_single_cross_validation_plot(
                ax_optimizer=ax_optimizer,
                objective=objective,
                parameters=parameters,
                objectives=objectives,
                search_space=search_space,
                untransform=untransform
            )
            
            plot_key = f"cross_validation_{objective}"
            plots[plot_key] = cv_fig
            self.plots[plot_key] = cv_fig
        
        return plots
    
    def _create_single_cross_validation_plot(
        self,
        ax_optimizer,
        objective: str,
        parameters: List[str],
        objectives: List[str],
        search_space: List[Dict[str, Any]],
        untransform: bool
    ) -> go.Figure:
        """
        åˆ›å»ºå•ä¸ªç›®æ ‡çš„äº¤å‰éªŒè¯å›¾
        åŸºäºAxä»£ç†æ¨¡å‹çš„ç•™ä¸€æ³•äº¤å‰éªŒè¯
        """
        try:
            # æ‰§è¡Œç•™ä¸€æ³•äº¤å‰éªŒè¯
            cv_results = self._perform_leave_one_out_cv(
                ax_optimizer=ax_optimizer,
                objective=objective,
                parameters=parameters,
                objectives=objectives,
                search_space=search_space,
                untransform=untransform
            )
            
            if not cv_results:
                print(f"      âš ï¸ äº¤å‰éªŒè¯å¤±è´¥ï¼Œç›®æ ‡: {objective}")
                return self._create_error_figure(f"äº¤å‰éªŒè¯å¤±è´¥: {objective}")
            
            # åˆ›å»ºäº¤å‰éªŒè¯å›¾
            fig = go.Figure()
            
            # æ·»åŠ æ•£ç‚¹å›¾ï¼Œåªæœ‰å‚ç›´è¯¯å·®æ£’ï¼ˆé¢„æµ‹å€¼çš„ç½®ä¿¡åŒºé—´ï¼‰
            fig.add_trace(go.Scatter(
                x=cv_results['observed'],
                y=cv_results['predicted'],
                mode='markers',
                marker=dict(
                    color='blue',
                    size=8,
                    opacity=0.7
                ),
                error_y=dict(
                    type='data',
                    array=cv_results['predicted_ci'],
                    visible=True,
                    color='blue',
                    thickness=1,
                    width=3
                ),
                name='Cross Validation Points',
                hovertemplate=(
                    '<b>Point: %{text}</b><br>' +
                    f'<b>Predicted:</b> %{{y:.6f}} Â± %{{error_y.array:.6f}}<br>' +
                    f'<b>Observed:</b> %{{x:.6f}}<br>' +
                    '<extra></extra>'
                ),
                text=cv_results['point_names']
            ))
            
            # æ·»åŠ å¯¹è§’çº¿ï¼ˆå®Œç¾é¢„æµ‹çº¿ï¼‰
            min_val = min(
                cv_results['observed'].min(),
                (cv_results['predicted'] - cv_results['predicted_ci']).min()
            )
            max_val = max(
                cv_results['observed'].max(),
                (cv_results['predicted'] + cv_results['predicted_ci']).max()
            )
            
            fig.add_trace(go.Scatter(
                x=[min_val * 0.99, max_val * 1.01],
                y=[min_val * 0.99, max_val * 1.01],
                mode='lines',
                line=dict(
                    color='gray',
                    dash='dash',
                    width=2
                ),
                name='Perfect Prediction (y=x)',
                showlegend=True
            ))
            
            # è®¡ç®—æ¨¡å‹æ€§èƒ½æŒ‡æ ‡
            mse = np.mean((cv_results['observed'] - cv_results['predicted']) ** 2)
            rmse = np.sqrt(mse)
            mae = np.mean(np.abs(cv_results['observed'] - cv_results['predicted']))
            r2 = 1 - np.sum((cv_results['observed'] - cv_results['predicted']) ** 2) / np.sum((cv_results['observed'] - cv_results['observed'].mean()) ** 2)
            
            # æ›´æ–°å¸ƒå±€
            fig.update_layout(
                title=dict(
                    text=f"Cross Validation for {objective} (Leave-One-Out)",
                    x=0.5,
                    font=dict(size=16)
                ),
                xaxis_title=f"Actual {objective}",
                yaxis_title=f"Predicted {objective}",
                plot_bgcolor='white',
                paper_bgcolor='white',
                height=600,
                width=800,
                margin=dict(l=50, r=50, t=100, b=50),
                showlegend=True,
                legend=dict(
                    x=0.02,
                    y=0.98,
                    bgcolor='rgba(255, 255, 255, 0.8)',
                    bordercolor='lightgray',
                    borderwidth=1
                ),
                # æ·»åŠ æ€§èƒ½æŒ‡æ ‡æ³¨é‡Š
                annotations=[
                    dict(
                        x=0.02,
                        y=0.3,
                        xref='paper',
                        yref='paper',
                        text=f"RMSE: {rmse:.3f}<br>MAE: {mae:.3f}<br>RÂ²: {r2:.3f}",
                        showarrow=False,
                        bgcolor='rgba(255, 255, 255, 0.9)',
                        bordercolor='lightgray',
                        borderwidth=1,
                        font=dict(size=12)
                    )
                ]
            )
            
            # è®¾ç½®åæ ‡è½´ä¸ºæ­£æ–¹å½¢
            fig.update_xaxes(
                range=[min_val * 0.99, max_val * 1.01],
                showgrid=True,
                gridwidth=1,
                gridcolor='lightgray'
            )
            fig.update_yaxes(
                range=[min_val * 0.99, max_val * 1.01],
                scaleanchor='x',
                scaleratio=1,
                showgrid=True,
                gridwidth=1,
                gridcolor='lightgray'
            )
            
            return fig
            
        except Exception as e:
            print(f"      âš ï¸ åˆ›å»ºäº¤å‰éªŒè¯å›¾å¤±è´¥: {e}")
            return self._create_error_figure(f"åˆ›å»ºäº¤å‰éªŒè¯å›¾å¤±è´¥: {e}")
    
    def _perform_leave_one_out_cv(
        self,
        ax_optimizer,
        objective: str,
        parameters: List[str],
        objectives: List[str],
        search_space: List[Dict[str, Any]],
        untransform: bool
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œç•™ä¸€æ³•äº¤å‰éªŒè¯
        ä½¿ç”¨Axä»£ç†æ¨¡å‹è¿›è¡Œé¢„æµ‹
        """
        try:
            # è·å–å®éªŒæ•°æ®
            trials_df = ax_optimizer.get_optimization_history()
            n_samples = len(trials_df)
            
            if n_samples < 3:
                print(f"      âš ï¸ æ ·æœ¬æ•°é‡å¤ªå°‘ ({n_samples})ï¼Œæ— æ³•è¿›è¡Œäº¤å‰éªŒè¯")
                return {}
            
            observed_values = []
            predicted_values = []
            predicted_cis = []
            point_names = []
            
            print(f"      ğŸ”„ æ‰§è¡Œç•™ä¸€æ³•äº¤å‰éªŒè¯ï¼Œå…± {n_samples} ä¸ªæ ·æœ¬...")
            
            # æ‰§è¡Œç•™ä¸€æ³•äº¤å‰éªŒè¯
            for i in range(n_samples):
                try:
                    # è·å–å½“å‰æ ·æœ¬çš„å®é™…å€¼
                    actual_value = trials_df.iloc[i][objective]
                    point_name = f"Point_{i+1}"
                    
                    # åˆ›å»ºä¸´æ—¶è®­ç»ƒæ•°æ®ï¼ˆæ’é™¤å½“å‰æ ·æœ¬ï¼‰
                    temp_data = trials_df.drop(index=trials_df.index[i]).copy()
                    
                    if len(temp_data) < 2:  # è‡³å°‘éœ€è¦2ä¸ªæ ·æœ¬è¿›è¡Œè®­ç»ƒ
                        continue
                    
                    # åˆ›å»ºä¸´æ—¶ä¼˜åŒ–å™¨è¿›è¡Œé¢„æµ‹
                    prediction_result = self._predict_with_temp_optimizer(
                        temp_data, trials_df.iloc[i], objective, parameters, objectives, search_space, untransform
                    )
                    
                    if prediction_result is not None:
                        observed_values.append(actual_value)
                        predicted_values.append(prediction_result['predicted'])
                        predicted_cis.append(prediction_result['ci'])
                        point_names.append(point_name)
                        
                        print(f"        âœ… æ ·æœ¬ {i+1}/{n_samples}: è§‚æµ‹å€¼={actual_value:.3f}, é¢„æµ‹å€¼={prediction_result['predicted']:.3f}Â±{prediction_result['ci']:.3f}")
                    
                except Exception as e:
                    print(f"        âš ï¸ æ ·æœ¬ {i+1} é¢„æµ‹å¤±è´¥: {e}")
                    continue
            
            if not observed_values:
                print(f"      âŒ æ²¡æœ‰æˆåŠŸçš„é¢„æµ‹ç»“æœ")
                return {}
            
            print(f"      âœ… æˆåŠŸå®Œæˆ {len(observed_values)}/{n_samples} ä¸ªæ ·æœ¬çš„äº¤å‰éªŒè¯")
            
            return {
                'observed': np.array(observed_values),
                'predicted': np.array(predicted_values),
                'predicted_ci': np.array(predicted_cis),
                'point_names': point_names
            }
            
        except Exception as e:
            print(f"      âš ï¸ äº¤å‰éªŒè¯æ‰§è¡Œå¤±è´¥: {e}")
            return {}
    
    def _predict_with_temp_optimizer(
        self,
        temp_data: pd.DataFrame,
        test_point: pd.Series,
        objective: str,
        parameters: List[str],
        objectives: List[str],
        search_space: List[Dict[str, Any]],
        untransform: bool
    ) -> Optional[Dict[str, float]]:
        """
        ä½¿ç”¨ä¸´æ—¶ä¼˜åŒ–å™¨è¿›è¡Œé¢„æµ‹
        """
        try:
            # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„å‚æ•°åˆ—è¡¨ï¼Œæ’é™¤æ‰€æœ‰ç›®æ ‡å˜é‡
            user_params = [col for col in temp_data.columns 
                          if col in parameters]
            
            # åˆ›å»ºä¸´æ—¶åˆ†æå™¨
            temp_analyzer = ParameterOptimizationAnalysis(
                experiment_data=temp_data,
                output_dir="temp_cv"
            )
            
            # é‡å»ºä¸´æ—¶Axä¼˜åŒ–å™¨
            temp_optimizer = temp_analyzer._rebuild_ax_optimizer(
                parameters=user_params,
                objectives=[objective],
                search_space=search_space
            )
            
            # å‡†å¤‡æµ‹è¯•æ ·æœ¬çš„å‚æ•°
            test_params = {}
            for param in user_params:
                val = test_point[param]
                # å¤„ç†Noneå€¼ï¼Œå°†å…¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²"None"
                if pd.isna(val) or val is None:
                    test_params[param] = "None"
                else:
                    test_params[param] = val
            
            # ä½¿ç”¨Axçš„é¢„æµ‹æ–¹æ³•
            predictions_dict = temp_optimizer.ax_client.get_model_predictions(
                metric_names=[objective],
                parameterizations={0: test_params}
            )
            
            if 0 in predictions_dict and objective in predictions_dict[0]:
                pred_mean, pred_std = predictions_dict[0][objective]
                
                # è®¡ç®—95%ç½®ä¿¡åŒºé—´
                ci = pred_std * 1.96
                
                return {
                    'predicted': pred_mean,
                    'std': pred_std,
                    'ci': ci
                }
            else:
                print(f"        âš ï¸ é¢„æµ‹è¿”å›ç©ºç»“æœ")
                return None
                
        except Exception as e:
            print(f"        âš ï¸ ä¸´æ—¶ä¼˜åŒ–å™¨é¢„æµ‹å¤±è´¥: {str(e)}")
            import traceback
            print(f"        ğŸ” è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return None
    
    def _create_error_figure(self, error_message: str) -> go.Figure:
        """
        åˆ›å»ºé”™è¯¯å›¾è¡¨
        """
        fig = go.Figure()
        fig.add_annotation(
            text=f"âŒ {error_message}",
            xref="paper", yref="paper",
            x=0.5, y=0.5,
            showarrow=False,
            font=dict(size=14, color="red")
        )
        fig.update_layout(
            title="Cross Validation Error",
            plot_bgcolor='white',
            paper_bgcolor='white',
            height=400,
            width=600
        )
        return fig
    

    
    def _infer_optimization_config(self, objectives: List[str]) -> Dict[str, Any]:
        """
        ä»å®éªŒæ•°æ®æ¨æ–­ä¼˜åŒ–é…ç½®
        """
        # é»˜è®¤æ‰€æœ‰ç›®æ ‡éƒ½æ˜¯æœ€å°åŒ–
        objectives_config = {obj: {"minimize": True} for obj in objectives}
        
        return {
            "objectives": objectives_config,
            "use_weights": False,
            "additional_metrics": []
        }
    
    def _get_parameter_values_for_slice(
        self,
        param: str,
        n_points: int
    ) -> List[float]:
        """
        è·å–å‚æ•°å€¼èŒƒå›´ï¼ˆç”¨äºsliceå›¾ï¼‰
        åŸºäºAxçš„get_parameter_valueså®ç°
        """
        param_data = self.experiment_data[param]
        param_min = param_data.min()
        param_max = param_data.max()
        
        # ç”Ÿæˆå‡åŒ€åˆ†å¸ƒçš„ç‚¹
        param_values = np.linspace(param_min, param_max, n_points).tolist()
        
        # ç¡®ä¿é‡‡æ ·å€¼ä¹ŸåŒ…å«åœ¨é¢„æµ‹ç‚¹ä¸­
        sampled_values = sorted(param_data.unique())
        for sampled_val in sampled_values:
            if sampled_val not in param_values:
                param_values.append(sampled_val)
        
        # é‡æ–°æ’åº
        param_values.sort()
        
        return param_values
    
    def _create_interactive_feature_analysis(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        shap_values: np.ndarray,
        feature_names: List[str],
        target_name: str
    ) -> go.Figure:
        """
        åˆ›å»ºäº¤äº’å¼ç‰¹å¾åˆ†æå›¾ï¼ˆåŒ…å«ç‰¹å¾é‡è¦æ€§ã€ç›¸å…³æ€§æ•£ç‚¹å›¾å’ŒSHAPå½±å“æ•£ç‚¹å›¾ï¼‰
        """
        # è®¡ç®—å¹³å‡SHAPå€¼
        mean_shap_values = np.abs(shap_values).mean(axis=0)
        
        # åˆ›å»ºå­å›¾
        fig = make_subplots(
            rows=1, cols=3,
            subplot_titles=(
                f"Feature Importance for {target_name}",
                "Feature vs Target Correlation",
                "SHAP Impact Analysis"
            ),
            specs=[[{"type": "bar"}, {"type": "scatter"}, {"type": "scatter"}]],
            horizontal_spacing=0.1
        )
        
        # 1. ç‰¹å¾é‡è¦æ€§æ¡å½¢å›¾
        fig.add_trace(
            go.Bar(
                x=mean_shap_values,
                y=feature_names,
                orientation='h',
                marker_color='lightblue',
                name="Feature Importance",
                hovertemplate='<b>%{y}</b><br>' +
                            'Average SHAP Impact: %{x:.3f}<br>' +
                            '<extra></extra>'
            ),
            row=1, col=1
        )
        
        # 2. é»˜è®¤æ˜¾ç¤ºç¬¬ä¸€ä¸ªç‰¹å¾çš„ç›¸å…³æ€§æ•£ç‚¹å›¾
        default_feature = feature_names[0]
        fig.add_trace(
            go.Scatter(
                x=X[default_feature],
                y=y,
                mode='markers',
                marker=dict(color='lightblue', size=8),
                name=f"{default_feature} vs {target_name}",
                hovertemplate='<b>%{x}</b><br>' +
                            f'{target_name}: %{{y}}<br>' +
                            '<extra></extra>'
            ),
            row=1, col=2
        )
        
        # æ·»åŠ å‚è€ƒçº¿
        fig.add_hline(
            y=y.mean(),
            line_dash="dash",
            line_color="red",
            row=1, col=2,
            annotation_text=f"Mean {target_name}: {y.mean():.2f}"
        )
        
        # 3. é»˜è®¤æ˜¾ç¤ºç¬¬ä¸€ä¸ªç‰¹å¾çš„SHAPå½±å“æ•£ç‚¹å›¾
        feature_idx = feature_names.index(default_feature)
        fig.add_trace(
            go.Scatter(
                x=X[default_feature],
                y=shap_values[:, feature_idx],
                mode='markers',
                marker=dict(color='lightblue', size=8),
                name=f"SHAP Impact of {default_feature}",
                hovertemplate='<b>%{x}</b><br>' +
                            'SHAP Impact: %{y:.3f}<br>' +
                            '<extra></extra>'
            ),
            row=1, col=3
        )
        
        # æ·»åŠ å‚è€ƒçº¿
        fig.add_hline(
            y=0,
            line_dash="dash",
            line_color="red",
            row=1, col=3,
            annotation_text="Zero Impact"
        )
        
        # æ›´æ–°å¸ƒå±€
        fig.update_layout(
            title=f"Interactive Feature Analysis for {target_name}",
            plot_bgcolor='white',
            paper_bgcolor='white',
            height=500,
            width=1500,
            margin=dict(l=50, r=50, t=80, b=50),
            showlegend=False
        )
        
        # æ›´æ–°åæ ‡è½´æ ‡ç­¾
        fig.update_xaxes(title_text="Average SHAP Impact", row=1, col=1)
        fig.update_yaxes(title_text="Features", row=1, col=1)
        
        fig.update_xaxes(title_text=default_feature, row=1, col=2)
        fig.update_yaxes(title_text=target_name, row=1, col=2)
        
        fig.update_xaxes(title_text=default_feature, row=1, col=3)
        fig.update_yaxes(title_text="SHAP Impact", row=1, col=3)
        
        # æ·»åŠ JavaScriptå›è°ƒç”¨äºäº¤äº’
        fig.update_layout(
            updatemenus=[
                dict(
                    type="dropdown",
                    direction="down",
                    showactive=True,
                    x=0.1,
                    y=1.1,
                    xanchor="left",
                    yanchor="top",
                    buttons=[
                        dict(
                            label=feature,
                            method="update",
                            args=[
                                {
                                    "xaxis2.title": feature,
                                    "xaxis3.title": feature,
                                    "xaxis2.range": [X[feature].min(), X[feature].max()],
                                    "xaxis3.range": [X[feature].min(), X[feature].max()]
                                },
                                {
                                    "data": [
                                        # æ›´æ–°ç›¸å…³æ€§æ•£ç‚¹å›¾
                                        dict(
                                            x=X[feature],
                                            y=y
                                        ),
                                        # æ›´æ–°SHAPå½±å“æ•£ç‚¹å›¾
                                        dict(
                                            x=X[feature],
                                            y=shap_values[:, feature_names.index(feature)]
                                        )
                                    ]
                                }
                            ]
                        ) for feature in feature_names
                    ]
                )
            ]
        )
        
        return fig
    
    def save_plots(self, format: str = 'html') -> List[str]:
        """
        ä¿å­˜æ‰€æœ‰ç”Ÿæˆçš„å›¾è¡¨
        
        Args:
            format: ä¿å­˜æ ¼å¼ ('html', 'png', 'jpg', 'svg')
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        saved_files = []
        
        for plot_name, fig in self.plots.items():
            filename = f"{plot_name}.{format}"
            filepath = self.output_dir / filename
            
            if format == 'html':
                fig.write_html(str(filepath))
            else:
                fig.write_image(str(filepath))
            
            saved_files.append(str(filepath))
            print(f"ğŸ’¾ ä¿å­˜å›¾è¡¨: {filename}")
        
        return saved_files
    
    def generate_feature_importance_analysis(
        self,
        parameters: List[str],
        objectives: List[str],
        save_results: bool = True
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆç‰¹å¾é‡è¦æ€§åˆ†æ
        
        Args:
            parameters: å‚æ•°åˆ—è¡¨
            objectives: ç›®æ ‡æŒ‡æ ‡åˆ—è¡¨
            save_results: æ˜¯å¦ä¿å­˜ç»“æœ
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        print("ğŸ” å¼€å§‹ç‰¹å¾é‡è¦æ€§åˆ†æ...")
        
        # ç”Ÿæˆç‰¹å¾é‡è¦æ€§åˆ†æ
        results = self.create_feature_importance_analysis(
            parameters=parameters,
            objectives=objectives
        )
        
        # ä¿å­˜ç»“æœ
        if save_results:
            self.save_plots('html')
        
        print("âœ… ç‰¹å¾é‡è¦æ€§åˆ†æå®Œæˆ!")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {self.output_dir}")
        
        return results


# ä¾¿æ·å‡½æ•°
def analyze_parallel_coordinates(
    data_file: str,
    parameters: List[str],
    objectives: List[str],
    output_dir: str = "analysis_output"
) -> ParameterOptimizationAnalysis:
    """
    ä¾¿æ·å‡½æ•°ï¼šç”Ÿæˆå¹¶è¡Œåæ ‡å›¾åˆ†æ
    
    Args:
        data_file: æ•°æ®æ–‡ä»¶è·¯å¾„
        parameters: å‚æ•°åˆ—è¡¨
        objectives: ç›®æ ‡æŒ‡æ ‡åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        åˆ†æå™¨å®ä¾‹
    """
    analyzer = ParameterOptimizationAnalysis(
        experiment_file=data_file,
        output_dir=output_dir
    )
    
    analyzer.generate_parallel_coordinates_analysis(parameters, objectives)
    return analyzer


def analyze_feature_importance(
    data_file: str,
    parameters: List[str],
    objectives: List[str],
    output_dir: str = "analysis_output"
) -> ParameterOptimizationAnalysis:
    """
    ä¾¿æ·å‡½æ•°ï¼šç”Ÿæˆç‰¹å¾é‡è¦æ€§åˆ†æ
    
    Args:
        data_file: æ•°æ®æ–‡ä»¶è·¯å¾„
        parameters: å‚æ•°åˆ—è¡¨
        objectives: ç›®æ ‡æŒ‡æ ‡åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        åˆ†æå™¨å®ä¾‹
    """
    analyzer = ParameterOptimizationAnalysis(
        experiment_file=data_file,
        output_dir=output_dir
    )
    
    analyzer.generate_feature_importance_analysis(parameters, objectives)
    return analyzer


def analyze_slice_plots(
    data_file: str,
    parameters: List[str],
    objectives: List[str],
    search_space: List[Dict[str, Any]] = None,
    optimization_config: Dict[str, Any] = None,
    output_dir: str = "analysis_output"
) -> ParameterOptimizationAnalysis:
    """
    ä¾¿æ·å‡½æ•°ï¼šç”Ÿæˆsliceå›¾åˆ†æ
    
    Args:
        data_file: æ•°æ®æ–‡ä»¶è·¯å¾„
        parameters: å‚æ•°åˆ—è¡¨
        objectives: ç›®æ ‡æŒ‡æ ‡åˆ—è¡¨
        search_space: æœç´¢ç©ºé—´é…ç½®ï¼ˆå¯é€‰ï¼Œä»æ•°æ®æ¨æ–­ï¼‰
        optimization_config: ä¼˜åŒ–é…ç½®ï¼ˆå¯é€‰ï¼Œä»æ•°æ®æ¨æ–­ï¼‰
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        åˆ†æå™¨å®ä¾‹
    """
    analyzer = ParameterOptimizationAnalysis(
        experiment_file=data_file,
        output_dir=output_dir
    )
    
    analyzer.create_slice_plots(parameters, objectives, search_space, optimization_config)
    return analyzer


def analyze_cross_validation_plots(
    data_file: str,
    parameters: List[str],
    objectives: List[str],
    search_space: List[Dict[str, Any]],
    untransform: bool = True,
    output_dir: str = "analysis_output",
    # æ–°å¢ï¼šè‡ªå®šä¹‰ä»£ç†æ¨¡å‹é…ç½®å‚æ•°
    surrogate_model_class: Optional[Type] = None,
    kernel_class: Optional[Type] = None,
    kernel_options: Optional[Dict[str, Any]] = None
) -> ParameterOptimizationAnalysis:
    """
    ä¾¿æ·å‡½æ•°ï¼šç”Ÿæˆäº¤å‰éªŒè¯åˆ†æ
    
    Args:
        data_file: æ•°æ®æ–‡ä»¶è·¯å¾„
        parameters: å‚æ•°åˆ—è¡¨
        objectives: ç›®æ ‡æŒ‡æ ‡åˆ—è¡¨
        search_space: æœç´¢ç©ºé—´é…ç½®ï¼ˆå¿…é¡»æä¾›ï¼‰
        untransform: æ˜¯å¦åå˜æ¢é¢„æµ‹ç»“æœ
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        åˆ†æå™¨å®ä¾‹
    """
    analyzer = ParameterOptimizationAnalysis(
        experiment_file=data_file,
        output_dir=output_dir
    )
    
    # ç”Ÿæˆäº¤å‰éªŒè¯å›¾
    plots = analyzer.create_cross_validation_plots(
        parameters, objectives, search_space, untransform,
        # ä¼ é€’è‡ªå®šä¹‰ä»£ç†æ¨¡å‹é…ç½®
        surrogate_model_class=surrogate_model_class,
        kernel_class=kernel_class,
        kernel_options=kernel_options
    )
    
    # ä¿å­˜ç”Ÿæˆçš„å›¾è¡¨
    if plots:
        print(f"\nğŸ“Š ç”Ÿæˆçš„å›¾è¡¨:")
        for plot_name in plots.keys():
            print(f"  - {plot_name}")
        
        print(f"\nğŸ’¾ ä¿å­˜å›¾è¡¨...")
        analyzer.save_plots()
        print(f"âœ… å›¾è¡¨å·²ä¿å­˜!")
        print(f"ğŸ“ è¯·æŸ¥çœ‹ {output_dir}/ ç›®å½•ä¸­çš„HTMLæ–‡ä»¶")
    
    return analyzer


def analyze_contour_plots(
    data_file: str,
    parameters: List[str],
    objectives: List[str],
    search_space: List[Dict[str, Any]],
    output_dir: str = "analysis_output",
    # æ–°å¢ï¼šè‡ªå®šä¹‰ä»£ç†æ¨¡å‹é…ç½®å‚æ•°
    surrogate_model_class: Optional[Type] = None,
    kernel_class: Optional[Type] = None,
    kernel_options: Optional[Dict[str, Any]] = None
) -> ParameterOptimizationAnalysis:
    """
    ä¾¿æ·å‡½æ•°ï¼šç”Ÿæˆç­‰é«˜çº¿å›¾åˆ†æ
    
    Args:
        data_file: æ•°æ®æ–‡ä»¶è·¯å¾„
        parameters: å‚æ•°åˆ—è¡¨ï¼ˆéœ€è¦è‡³å°‘2ä¸ªå‚æ•°ï¼‰
        objectives: ç›®æ ‡æŒ‡æ ‡åˆ—è¡¨
        search_space: æœç´¢ç©ºé—´é…ç½®ï¼ˆå¿…é¡»æä¾›ï¼‰
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        åˆ†æå™¨å®ä¾‹
    """
    analyzer = ParameterOptimizationAnalysis(
        experiment_file=data_file,
        output_dir=output_dir
    )
    
    analyzer.create_contour_plots(
        parameters, objectives, search_space,
        # ä¼ é€’è‡ªå®šä¹‰ä»£ç†æ¨¡å‹é…ç½®
        surrogate_model_class=surrogate_model_class,
        kernel_class=kernel_class,
        kernel_options=kernel_options
    )
    return analyzer


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    print("ğŸš€ å‚æ•°ä¼˜åŒ–åˆ†ææ¨¡å—")
    print("=" * 50)
    
    # ä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œåˆ†æ
    data_file = "experiment_data.csv"
    if os.path.exists(data_file):
        print(f"ğŸ“Š åˆ†ææ–‡ä»¶: {data_file}")
        
        # å®šä¹‰å‚æ•°å’Œç›®æ ‡
        parameters = ['solvent', 'catalyst', 'temperature', 'concentration']  # åŒ…å«ç±»åˆ«å˜é‡
        objectives = ['yield', 'side_product']  # å¤šç›®æ ‡
        
        # ç”¨æˆ·æŒ‡å®šçš„å‚æ•°ç©ºé—´é…ç½®
        search_space = [
            {
                "name": "solvent",
                "type": "choice",
                "values": ["THF", "Toluene", "DMSO"]
            },
            {
                "name": "catalyst",
                "type": "choice", 
                "values": ["Pd/C", "CuO", "None"]
            },
            {
                "name": "temperature",
                "type": "range",
                "bounds": [-10, 25]
            },
            {
                "name": "concentration",
                "type": "range",
                "bounds": [0.1, 1.0]
            }
        ]
        
        # ä¼˜åŒ–é…ç½®
        optimization_config = {
            "objectives": {
                "yield": {"minimize": False},  # æœ€å¤§åŒ–äº§ç‡
                "side_product": {"minimize": True}  # æœ€å°åŒ–å‰¯äº§ç‰©
            }
        }
        
        # åˆ›å»ºåˆ†æå™¨å®ä¾‹
        analyzer = ParameterOptimizationAnalysis(
            experiment_file=data_file,
            output_dir="analysis_output"
        )
        
        # ç”Ÿæˆå¹¶è¡Œåæ ‡å›¾åˆ†æ
        print("\nğŸ“Š ç”Ÿæˆå¹¶è¡Œåæ ‡å›¾åˆ†æ...")
        parallel_results = analyzer.generate_parallel_coordinates_analysis(
            parameters=parameters,
            objectives=objectives
        )
        
        # ç”Ÿæˆç‰¹å¾é‡è¦æ€§åˆ†æ
        print("\nğŸ“Š ç”Ÿæˆç‰¹å¾é‡è¦æ€§åˆ†æ...")
        feature_results = analyzer.generate_feature_importance_analysis(
            parameters=parameters,
            objectives=objectives
        )
        
        # ç”Ÿæˆäº¤å‰éªŒè¯å›¾åˆ†æ
        print("\nğŸ“Š ç”Ÿæˆäº¤å‰éªŒè¯å›¾åˆ†æ...")
        cv_results = analyzer.create_cross_validation_plots(
            parameters=parameters,
            objectives=objectives,
            search_space=search_space,
            untransform=True,
            # ç¤ºä¾‹ï¼šä½¿ç”¨è‡ªå®šä¹‰ä»£ç†æ¨¡å‹é…ç½®ï¼ˆå¯é€‰ï¼‰
            surrogate_model_class=SingleTaskGP,
            kernel_class=MaternKernel,
            kernel_options={"nu": 2.5}
        )
        
        # ä¿å­˜æ‰€æœ‰å›¾è¡¨
        print("\nğŸ’¾ ä¿å­˜æ‰€æœ‰å›¾è¡¨...")
        analyzer.save_plots()
        
        print(f"\nâœ… åˆ†æå®Œæˆï¼")
        print(f"ğŸ“Š å¹¶è¡Œåæ ‡å›¾: {parallel_results['total_plots']} ä¸ªå›¾è¡¨")
        print(f"ğŸ“Š ç‰¹å¾é‡è¦æ€§åˆ†æ: {len(objectives)} ä¸ªå›¾è¡¨")
        print(f"ğŸ“Š äº¤å‰éªŒè¯å›¾: {len(cv_results)} ä¸ªå›¾è¡¨")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {analyzer.output_dir}")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°ç¤ºä¾‹æ•°æ®æ–‡ä»¶ï¼Œè¯·æä¾›å®éªŒæ•°æ®æ–‡ä»¶è¿›è¡Œåˆ†æã€‚")
