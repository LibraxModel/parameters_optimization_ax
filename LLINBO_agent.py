"""
LLINBO Agent: Large Language Model for Bayesian Optimization Agent
åŸºäºå¤§æ¨¡å‹çš„è´å¶æ–¯ä¼˜åŒ–æ™ºèƒ½ä½“

åŠŸèƒ½ï¼š
1. æ¥å—å¯é…ç½®çš„ä¼˜åŒ–é—®é¢˜èƒŒæ™¯å’Œè¡Œä¸šæè¿°
2. æ”¯æŒå¯é…ç½®çš„å‚æ•°ç©ºé—´èŒƒå›´
3. åˆ©ç”¨å†å²å…ˆéªŒå®éªŒæ•°æ®è¿›è¡Œä¼˜åŒ–å»ºè®®
4. ä½¿ç”¨å¤§æ¨¡å‹æ¨¡æ‹Ÿè´å¶æ–¯ä¼˜åŒ–è¿‡ç¨‹
"""

from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field
import json
import os
import pandas as pd
import numpy as np
from abc import ABC, abstractmethod


@dataclass
class ProblemContext:
    """ä¼˜åŒ–é—®é¢˜èƒŒæ™¯é…ç½®"""
    problem_description: str  # é—®é¢˜æè¿°
    industry: str  # è¡Œä¸šé¢†åŸŸ
    domain_knowledge: Optional[str] = None  # é¢†åŸŸçŸ¥è¯†
    constraints: Optional[List[str]] = None  # çº¦æŸæ¡ä»¶
    optimization_goals: Optional[List[str]] = None  # ä¼˜åŒ–ç›®æ ‡è¯´æ˜


@dataclass
class Parameter:
    """å‚æ•°ç©ºé—´å®šä¹‰"""
    name: str  # å‚æ•°åç§°
    type: str  # å‚æ•°ç±»å‹: "range" æˆ– "choice"
    bounds: Optional[List[float]] = None  # èŒƒå›´å‚æ•°: [min, max]
    values: Optional[List[Any]] = None  # é€‰æ‹©å‚æ•°: [value1, value2, ...]
    value_type: str = "float"  # å€¼ç±»å‹: "int", "float", "str"
    description: Optional[str] = None  # å‚æ•°æè¿°
    unit: Optional[str] = None  # å•ä½   


@dataclass
class PriorExperiment:
    """å…ˆéªŒå®éªŒæ•°æ®"""
    parameters: Dict[str, Any]  # å‚æ•°é…ç½®
    metrics: Dict[str, float]  # å®éªŒç»“æœæŒ‡æ ‡
    metadata: Optional[Dict[str, Any]] = None  # é¢å¤–å…ƒæ•°æ®


@dataclass
class LLMConfig:
    """å¤§æ¨¡å‹é…ç½®"""
    model_name: str = "gpt-4"  # æ¨¡å‹åç§°
    api_key: Optional[str] = None  # APIå¯†é’¥
    base_url: Optional[str] = None  # APIåŸºç¡€URL
    
    


class LLMProvider(ABC):
    """å¤§æ¨¡å‹æä¾›è€…æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    def generate(self, prompt: str, **kwargs) -> str:
        """ç”Ÿæˆæ–‡æœ¬"""
        pass


class OpenAIProvider(LLMProvider):
    """OpenAI API æä¾›è€…"""
    
    def __init__(self, config: LLMConfig):
        self.config = config
        try:
            import openai
            self.client = openai.OpenAI(
                api_key=config.api_key or None,
                base_url=config.base_url
            )
        except ImportError:
            raise ImportError("è¯·å®‰è£… openai åº“: pip install openai")
        except Exception as e:
            raise RuntimeError(f"åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯å¤±è´¥: {e}")
    
    def generate(self, prompt: str, **kwargs) -> str:
        """ä½¿ç”¨ OpenAI API ç”Ÿæˆæ–‡æœ¬"""
        try:
            response = self.client.chat.completions.create(
                model=self.config.model_name,
                messages=[
                    {"role": "system", "content": """
                    You are a professional parameter optimization algorithm expert,
                    skilled in providing parameter optimization recommendations for specific domains based on prior experimental data provided by users and domain knowledge from your training data.
                    Only recommend a parameter combination if you are 80% confident that the experimental results from your recommended parameter combination will be better than the best results in the prior data.
                    Please strictly return results in JSON format only, without any other content.
                    âš ï¸ WARNING! Your recommendations must not come from the prior data.
                    
                    """ },
                    {"role": "user", "content": prompt}
                ]
            
            
        )
        except Exception as e:
            raise RuntimeError(f"è°ƒç”¨ OpenAI API å¤±è´¥: {e}")
        return response.choices[0].message.content


class LLINBOAgent:
    """
    åŸºäºå¤§æ¨¡å‹çš„è´å¶æ–¯ä¼˜åŒ–æ™ºèƒ½ä½“
    
    ä½¿ç”¨å¤§æ¨¡å‹æ¥æ¨¡æ‹Ÿè´å¶æ–¯ä¼˜åŒ–è¿‡ç¨‹ï¼Œç»“åˆé—®é¢˜èƒŒæ™¯ã€å‚æ•°ç©ºé—´å’Œå…ˆéªŒæ•°æ®
    ç”Ÿæˆä¼˜åŒ–å»ºè®®ã€‚
    """
    
    def __init__(
        self,
        problem_context: ProblemContext,
        parameters: List[Parameter],
        objectives: Dict[str, Dict[str, bool]],  # {"metric_name": {"minimize": bool}}
        llm_config: Optional[LLMConfig] = None,
        prior_experiments: Optional[List[PriorExperiment]] = None,
        random_seed: Optional[int] = None
    ):
        """
        åˆå§‹åŒ– LLINBO Agent
        
        Args:
            problem_context: ä¼˜åŒ–é—®é¢˜èƒŒæ™¯
            parameters: å‚æ•°å®šä¹‰åˆ—è¡¨
            objectives: ä¼˜åŒ–ç›®æ ‡é…ç½®
            llm_config: å¤§æ¨¡å‹é…ç½®ï¼ˆå¯é€‰ï¼‰
            prior_experiments: å…ˆéªŒå®éªŒæ•°æ®ï¼ˆå¯é€‰ï¼‰
            random_seed: éšæœºç§å­ï¼ˆå¯é€‰ï¼‰
        """
        self.problem_context = problem_context
        self.parameters = parameters
        self.objectives = objectives
        self.prior_experiments = prior_experiments or []
        self.random_seed = random_seed
        
        # åˆå§‹åŒ–å¤§æ¨¡å‹æä¾›è€…
        if llm_config is None:
            llm_config = LLMConfig()
        self.llm_config = llm_config
        
        # æ ¹æ®é…ç½®é€‰æ‹©æä¾›è€…
        self.llm_provider = OpenAIProvider(llm_config)

        # ä¼˜åŒ–å†å²è®°å½•

        self.optimization_history: List[Dict[str, Any]] = []
    
    def _build_context_prompt(self) -> str:
        """æ„å»ºåŒ…å«é—®é¢˜èƒŒæ™¯çš„æç¤ºè¯"""
        prompt_parts = [
            "# Optimization Problem Context",
            f"**Problem Description**: {self.problem_context.problem_description}",
            f"**Industry Domain**: {self.problem_context.industry}",
        ]
        
        if self.problem_context.domain_knowledge:
            prompt_parts.append(f"**Domain Knowledge**: {self.problem_context.domain_knowledge}")
        
        if self.problem_context.constraints:
            prompt_parts.append(f"**Constraints**: {', '.join(self.problem_context.constraints)}")
        
        if self.problem_context.optimization_goals:
            prompt_parts.append(f"**Optimization Goals**: {', '.join(self.problem_context.optimization_goals)}")
        
        return "\n".join(prompt_parts)
    
    def _build_parameter_space_prompt(self) -> str:
        """æ„å»ºå‚æ•°ç©ºé—´æè¿°æç¤ºè¯"""
        prompt_parts = [
            "# Parameter Space Definition",
            "The following are the parameters to be optimized and their ranges:",
            "",
            "**Important Note**: If a parameter is discrete, you must select from the listed optional values and cannot choose other values; if a parameter is continuous, the value must be within the [minimum, maximum] range."
        ]
        
        for i, param in enumerate(self.parameters, 1):
            param_desc = [f"{i}. **{param.name}**"]
            
            if param.description:
                param_desc.append(f"   Description: {param.description}")
            
            if param.type == "range" and param.bounds:
                param_desc.append(f"   Type: Continuous parameter")
                param_desc.append(f"   Range: [{param.bounds[0]}, {param.bounds[1]}]")
                if param.unit:
                    param_desc.append(f"   Unit: {param.unit}")
            elif param.type == "choice" and param.values:
                param_desc.append(f"   Type: Discrete parameter (must select one from the following values)")
                # æ˜ç¡®åˆ—å‡ºæ‰€æœ‰å¯é€‰å€¼
                values_str = ", ".join([str(v) for v in param.values])
                param_desc.append(f"   Optional values: [{values_str}]")
                param_desc.append(f"   Number of optional values: {len(param.values)}")
                param_desc.append(f"   âš ï¸ Important: Only values from the list can be selected, no other values or intermediate values")
            
            if param.value_type:
                param_desc.append(f"   Value type: {param.value_type}")
            
            prompt_parts.append("\n".join(param_desc))
        
        return "\n".join(prompt_parts)
    
    def _build_objectives_prompt(self) -> str:
        """æ„å»ºä¼˜åŒ–ç›®æ ‡æè¿°æç¤ºè¯"""
        prompt_parts = [
            "# Optimization Objectives",
            "Metrics to be optimized and their directions:"
        ]
        
        for metric_name, config in self.objectives.items():
            minimize = config.get("minimize", True)
            direction = "minimize" if minimize else "maximize"
            prompt_parts.append(f"- **{metric_name}**: {direction}")
        
        # æ·»åŠ ä¼˜åŒ–æ–¹å‘è¯´æ˜
        if len(self.objectives) > 1:
            prompt_parts.append("\n**Note**: This is a multi-objective optimization problem that requires balancing multiple objectives.")
        
        return "\n".join(prompt_parts)
    
    def _build_optimization_direction_instruction(self) -> str:
        """æ„å»ºä¼˜åŒ–æ–¹å‘è¯´æ˜"""
        instructions = []
        
        for metric_name, config in self.objectives.items():
            minimize = config.get("minimize", True)
            if minimize:
                instructions.append(
                    f"- **{metric_name}**: Needs to be **minimized**, prioritize parameter combinations that can reduce this metric value"
                )
            else:
                instructions.append(
                    f"- **{metric_name}**: Needs to be **maximized**, prioritize parameter combinations that can increase this metric value"
                )
        
        return "\n".join(instructions)
    
    def _build_prior_data_prompt(self) -> str:
        """æ„å»ºå…ˆéªŒå®éªŒæ•°æ®æç¤ºè¯"""
        if not self.prior_experiments:
            return "# Prior Experimental Data\nNo prior experimental data available."
        
        prompt_parts = [
            "# Prior Experimental Data",
            f"The following are {len(self.prior_experiments)} historical experimental results:",
            ""
        ]
        
        # è½¬æ¢ä¸ºè¡¨æ ¼æ ¼å¼
        data_rows = []
        for i, exp in enumerate(self.prior_experiments, 1):
            row = {
                "Experiment_ID": i,
                **exp.parameters,
                **exp.metrics
            }
            data_rows.append(row)
        
        df = pd.DataFrame(data_rows)
        prompt_parts.append("```")
        prompt_parts.append(df.to_string(index=False))
        prompt_parts.append("```")
        
        
        return "\n".join(prompt_parts)
    
    def _build_initial_sampling_prompt(self, num_suggestions: int = 1) -> str:
        """æ„å»ºåˆå§‹é‡‡æ ·æç¤ºè¯ï¼ˆæ— å…ˆéªŒæ•°æ®æ—¶ä½¿ç”¨ï¼‰"""
        prompt_parts = [
            self._build_context_prompt(),
            "",
            self._build_parameter_space_prompt(),
            "",
            self._build_objectives_prompt(),
            "",
            "# Initial Sampling Task",
            f"Currently there is no prior experimental data. Please recommend {num_suggestions} initial parameter configurations.",
            "",
            "**Task Objective**:",
            "Based on your domain knowledge, recommend parameter combinations that you believe are **most promising to reach near the optimal solution**.",
            "You do not need to uniformly cover the parameter space; just recommend sufficiently good parameter combinations.",
            "",
            "**Recommendation Strategy**:",
            "1. **Parameter values must strictly conform to definitions**:",
            "   - For continuous parameters (range type), values must be within the [minimum, maximum] range",
            "   - For discrete parameters (choice type), values must **exactly equal** one of the values in the optional values list, no other values allowed",
            "   - For example: if optional values are ['A', 'B', 'C', 'D'], you can only choose one of these 4 values",
            "2. **Domain knowledge guidance**: Based on your deep understanding of this domain, recommend parameter combinations that you believe are most likely to produce excellent results",
            "3. **Optimization objective orientation**: According to optimization objectives (maximize or minimize), recommend parameter combinations that can achieve these objectives",
            "4. If there are multiple objectives, consider multi-objective optimization and recommend parameter combinations that can balance different objectives",
            "5. You can recommend multiple different parameter combinations, but all should be combinations that are promising to reach near good results",
            "",
            "**Output Requirements**:",
            "- Please explain in the recommendation reason why you recommend this parameter combination and why you believe it can reach near good results",
            "- Explain how this parameter combination satisfies the optimization objectives",
            "",
            "Please return the recommended parameter configurations in JSON format as follows:",
            "```json",
            "{",
            '  "suggestions": [',
            '    {',
            '      "parameter_name_1": value1,',
            '      "parameter_name_2": value2,',
            '      ...',
            '      "reason": "Recommendation reason (explain why you chose this parameter combination and why it can reach near the optimal solution)"',
            '    }',
            '  ]',
            "}",
            "```"
        ]
        
        return "\n".join(prompt_parts)
    
    def _build_optimization_prompt(self, num_suggestions: int = 1) -> str:
        """æ„å»ºå®Œæ•´çš„ä¼˜åŒ–æç¤ºè¯"""
        prompt_parts = [
            self._build_context_prompt(),
            "",
            self._build_parameter_space_prompt(),
            "",
            self._build_objectives_prompt(),
            "",
            self._build_prior_data_prompt(),
            "",
            "# Optimization Task",
            f"Based on the above information, please recommend {num_suggestions} parameter configurations for the next experiment.",
            "",
            "**Optimization Direction Requirements**:",
            self._build_optimization_direction_instruction(),
            "",
            "**Other Requirements**:",
            "1. **Parameter values must strictly conform to definitions**:",
            "   - For continuous parameters (range type), values must be within the [minimum, maximum] range",
            "   - For discrete parameters (choice type), values must **exactly equal** one of the values in the optional values list, no other values allowed",
            "   - For example: if optional values are ['A', 'B', 'C', 'D'], you can only choose one of these 4 values",
            "2. Only recommend a parameter combination if you are 80% confident that the experimental results from your recommended parameter combination will be better than the best results in the prior data.",
            "2.1 If multiple parameter groups are required, recommend them in order of confidence from high to low until the requirement is met",
            "3. Consider patterns and trends in the prior data, but do not directly recommend points that already exist in the prior data",
            "4. Balance between exploration and exploitation",
            "5. If there are multiple objectives, consider multi-objective optimization (Pareto optimality)",
            "6. âš ï¸ WARNING! Your recommendations must be based on reasoning from the prior data and your industry background knowledge, and cannot directly recommend points that already exist in the prior data.",
            "7. âš ï¸ WARNING! Your recommendations must not duplicate the prior data. The recommended parameter combinations must not already exist in the prior data",
            "8. Please explain in the recommendation reason why you recommend this parameter combination.",
            
            "",
            "Please return the recommended parameter configurations in JSON format as follows:",
            "```json",
            "{",
            '  "suggestions": [',
            '    {',
            '      "parameter_name_1": value1,',
            '      "parameter_name_2": value2,',
            '      ...',
            '      "reason": "Recommendation reason"',
            '    }',
            '  ]',
            "}",
            "```"
        ]
        
        return "\n".join(prompt_parts)
    
    def _parse_llm_response(self, response: str) -> List[Dict[str, Any]]:
        """è§£æå¤§æ¨¡å‹è¿”å›çš„JSONæ ¼å¼å“åº”"""
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†
            json_str = None
            
            # æ–¹æ³•1: æŸ¥æ‰¾ ```json ... ```
            if "```json" in response:
                json_start = response.find("```json") + 7
                json_end = response.find("```", json_start)
                if json_end > json_start:
                    json_str = response[json_start:json_end].strip()
            
            # æ–¹æ³•2: æŸ¥æ‰¾ ``` ... ```
            if json_str is None and "```" in response:
                parts = response.split("```")
                for i in range(1, len(parts), 2):
                    candidate = parts[i].strip()
                    if candidate.startswith("json"):
                        candidate = candidate[4:].strip()
                    if candidate.startswith("{") or candidate.startswith("["):
                        json_str = candidate
                        break
            
            # æ–¹æ³•3: æŸ¥æ‰¾ç¬¬ä¸€ä¸ª { æˆ– [
            if json_str is None:
                for start_char in ["{", "["]:
                    start_idx = response.find(start_char)
                    if start_idx >= 0:
                        # æ‰¾åˆ°åŒ¹é…çš„ç»“æŸå­—ç¬¦
                        end_char = "}" if start_char == "{" else "]"
                        depth = 0
                        for i in range(start_idx, len(response)):
                            if response[i] == start_char:
                                depth += 1
                            elif response[i] == end_char:
                                depth -= 1
                                if depth == 0:
                                    json_str = response[start_idx:i+1]
                                    break
                        if json_str:
                            break
            
            # æ–¹æ³•4: ç›´æ¥è§£ææ•´ä¸ªå“åº”
            if json_str is None:
                json_str = response.strip()
            
            result = json.loads(json_str)
            
            if "suggestions" in result:
                return result["suggestions"]
            elif isinstance(result, list):
                return result
            elif isinstance(result, dict):
                # å¦‚æœç»“æœæ˜¯å•ä¸ªå­—å…¸ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«å‚æ•°
                if any(key in result for key in [p.name for p in self.parameters]):
                    return [result]
                else:
                    return []
            else:
                return []
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
            print(f"å“åº”å†…å®¹ï¼ˆå‰500å­—ç¬¦ï¼‰: {response[:500]}")
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
            return []
        except Exception as e:
            print(f"âš ï¸ è§£æå“åº”æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return []
    
    def _validate_parameters(self, params: Dict[str, Any]) -> bool:
        """éªŒè¯å‚æ•°æ˜¯å¦åœ¨å®šä¹‰çš„ç©ºé—´å†…"""
        for param_def in self.parameters:
            param_name = param_def.name
            if param_name not in params:
                continue  # å…è®¸ç¼ºå°‘æŸäº›å‚æ•°
            
            value = params[param_name]
            
            if param_def.type == "range":
                if param_def.bounds is None:
                    continue
                min_val, max_val = param_def.bounds
                if not (min_val <= value <= max_val):
                    return False
                
                # ç±»å‹è½¬æ¢æ£€æŸ¥
                if param_def.value_type == "int":
                    if not isinstance(value, (int, float)) or int(value) != value:
                        return False
            elif param_def.type == "choice":
                if param_def.values is None:
                    continue
                if value not in param_def.values:
                    return False
        
        return True
    
    def _normalize_parameters(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """è§„èŒƒåŒ–å‚æ•°å€¼ï¼ˆç±»å‹è½¬æ¢ç­‰ï¼‰"""
        normalized = {}
        
        for param_def in self.parameters:
            param_name = param_def.name
            if param_name not in params:
                continue
            
            value = params[param_name]
            
            # ç±»å‹è½¬æ¢
            if param_def.value_type == "int":
                value = int(float(value))
            elif param_def.value_type == "float":
                value = float(value)
            elif param_def.value_type == "str":
                value = str(value)
            
            normalized[param_name] = value
        
        return normalized
    
    def suggest_initial_parameters(
        self, 
        num_suggestions: int = 1, 
        print_prompt: bool = False, 
        print_response: bool = False
    ) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆåˆå§‹é‡‡æ ·å‚æ•°å»ºè®®ï¼ˆæ— å…ˆéªŒæ•°æ®æ—¶ä½¿ç”¨ï¼‰
        
        è¯¥æ–¹æ³•ä¸“é—¨ç”¨äºæ²¡æœ‰å…ˆéªŒå®éªŒæ•°æ®çš„æƒ…å†µï¼ŒåŸºäºé¢†åŸŸçŸ¥è¯†æ¨èæœ€æœ‰å¸Œæœ›è¾¾åˆ°æœ€ä¼˜è§£é™„è¿‘çš„å‚æ•°ç»„åˆã€‚
        ä¸éœ€è¦å‡åŒ€è¦†ç›–å‚æ•°ç©ºé—´ï¼Œåªéœ€è¦æ¨èè¶³å¤Ÿå¥½çš„å‚æ•°ç»„åˆå³å¯ã€‚
        
        Args:
            num_suggestions: éœ€è¦ç”Ÿæˆçš„å»ºè®®æ•°é‡
            print_prompt: æ˜¯å¦æ‰“å°è¾“å…¥å¤§æ¨¡å‹çš„å®Œæ•´æç¤ºè¯
            print_response: æ˜¯å¦æ‰“å°å¤§æ¨¡å‹çš„åŸå§‹å›ç­”
            
        Returns:
            æ¨èçš„å‚æ•°é…ç½®åˆ—è¡¨
        """
        # æ„å»ºåˆå§‹é‡‡æ ·æç¤ºè¯
        prompt = self._build_initial_sampling_prompt(num_suggestions=num_suggestions)
        
        # æ ¹æ® print_prompt å‚æ•°å†³å®šæ˜¯å¦æ‰“å°å®Œæ•´æç¤ºè¯
        if print_prompt:
            print("\n" + "=" * 80)
            print("ğŸ“ è¾“å…¥å¤§æ¨¡å‹çš„å®Œæ•´æç¤ºè¯ï¼ˆåˆå§‹é‡‡æ ·æ¨¡å¼ï¼‰:")
            print("=" * 80)
            print(prompt)
            print("=" * 80 + "\n")
        
        # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå»ºè®®
        print("ğŸ¤– æ­£åœ¨ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆåˆå§‹é‡‡æ ·å»ºè®®...")
        response = self.llm_provider.generate(prompt)
        
        # æ ¹æ® print_response å‚æ•°å†³å®šæ˜¯å¦æ‰“å°å¤§æ¨¡å‹çš„åŸå§‹å›ç­”
        if print_response:
            print("\n" + "=" * 80)
            print("ğŸ“¤ å¤§æ¨¡å‹çš„åŸå§‹å›ç­”:")
            print("=" * 80)
            print(response)
            print("=" * 80 + "\n")
        
        # è§£æå“åº”
        suggestions = self._parse_llm_response(response)
        
        # éªŒè¯å’Œè§„èŒƒåŒ–å‚æ•°
        valid_suggestions = []
        for suggestion in suggestions:
            params = {k: v for k, v in suggestion.items() if k != "reason"}
            
            if self._validate_parameters(params):
                normalized = self._normalize_parameters(params)
                valid_suggestions.append(normalized)
            else:
                print(f"âš ï¸ å‚æ•°éªŒè¯å¤±è´¥ï¼Œè·³è¿‡: {params}")
        
        # å¦‚æœéªŒè¯åçš„å»ºè®®æ•°é‡ä¸è¶³ï¼Œå°è¯•ç”Ÿæˆæ›´å¤š
        if len(valid_suggestions) < num_suggestions:
            print(f"âš ï¸ åªç”Ÿæˆäº† {len(valid_suggestions)} ä¸ªæœ‰æ•ˆå»ºè®®ï¼ŒæœŸæœ› {num_suggestions} ä¸ª")
        
        # è®°å½•åˆ°å†å²
        for suggestion in valid_suggestions:
            self.optimization_history.append({
                "suggestion": suggestion,
                "timestamp": pd.Timestamp.now().isoformat(),
                "type": "initial_sampling"
            })
        
        return valid_suggestions[:num_suggestions]
    
    def suggest_parameters(
        self, 
        num_suggestions: int = 1, 
        print_prompt: bool = False, 
        print_response: bool = False,
        auto_initial_sampling: bool = True
    ) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆå‚æ•°ä¼˜åŒ–å»ºè®®
        
        Args:
            num_suggestions: éœ€è¦ç”Ÿæˆçš„å»ºè®®æ•°é‡
            print_prompt: æ˜¯å¦æ‰“å°è¾“å…¥å¤§æ¨¡å‹çš„å®Œæ•´æç¤ºè¯
            print_response: æ˜¯å¦æ‰“å°å¤§æ¨¡å‹çš„åŸå§‹å›ç­”
            auto_initial_sampling: å¦‚æœæ²¡æœ‰å…ˆéªŒæ•°æ®ï¼Œæ˜¯å¦è‡ªåŠ¨åˆ‡æ¢åˆ°åˆå§‹é‡‡æ ·æ¨¡å¼ï¼ˆé»˜è®¤Trueï¼‰
            
        Returns:
            æ¨èçš„å‚æ•°é…ç½®åˆ—è¡¨
        """
        # å¦‚æœæ²¡æœ‰å…ˆéªŒæ•°æ®ä¸”å¯ç”¨äº†è‡ªåŠ¨åˆå§‹é‡‡æ ·ï¼Œåˆ™ä½¿ç”¨åˆå§‹é‡‡æ ·æ¨¡å¼
        if not self.prior_experiments and auto_initial_sampling:
            print("ğŸ“Š æ£€æµ‹åˆ°æ²¡æœ‰å…ˆéªŒå®éªŒæ•°æ®ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°åˆå§‹é‡‡æ ·æ¨¡å¼...")
            return self.suggest_initial_parameters(
                num_suggestions=num_suggestions,
                print_prompt=print_prompt,
                print_response=print_response
            )
        
        # æ„å»ºæç¤ºè¯
        prompt = self._build_optimization_prompt(num_suggestions=num_suggestions)
        
        # æ ¹æ® print_prompt å‚æ•°å†³å®šæ˜¯å¦æ‰“å°å®Œæ•´æç¤ºè¯
        if print_prompt:
            print("\n" + "=" * 80)
            print("ğŸ“ è¾“å…¥å¤§æ¨¡å‹çš„å®Œæ•´æç¤ºè¯:")
            print("=" * 80)
            print(prompt)
            print("=" * 80 + "\n")
        
        # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå»ºè®®
        print("ğŸ¤– æ­£åœ¨ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆä¼˜åŒ–å»ºè®®...")
        response = self.llm_provider.generate(prompt)
        
        # æ ¹æ® print_response å‚æ•°å†³å®šæ˜¯å¦æ‰“å°å¤§æ¨¡å‹çš„åŸå§‹å›ç­”
        if print_response:
            print("\n" + "=" * 80)
            print("ğŸ“¤ å¤§æ¨¡å‹çš„åŸå§‹å›ç­”:")
            print("=" * 80)
            print(response)
            print("=" * 80 + "\n")
        
        # è§£æå“åº”
        suggestions = self._parse_llm_response(response)
        
        # éªŒè¯å’Œè§„èŒƒåŒ–å‚æ•°
        valid_suggestions = []
        for suggestion in suggestions:
            params = {k: v for k, v in suggestion.items() if k != "reason"}
            
            if self._validate_parameters(params):
                normalized = self._normalize_parameters(params)
                valid_suggestions.append(normalized)
            else:
                print(f"âš ï¸ å‚æ•°éªŒè¯å¤±è´¥ï¼Œè·³è¿‡: {params}")
        
        # å¦‚æœéªŒè¯åçš„å»ºè®®æ•°é‡ä¸è¶³ï¼Œå°è¯•ç”Ÿæˆæ›´å¤š
        if len(valid_suggestions) < num_suggestions:
            print(f"âš ï¸ åªç”Ÿæˆäº† {len(valid_suggestions)} ä¸ªæœ‰æ•ˆå»ºè®®ï¼ŒæœŸæœ› {num_suggestions} ä¸ª")
        
        # è®°å½•åˆ°å†å²
        for suggestion in valid_suggestions:
            self.optimization_history.append({
                "suggestion": suggestion,
                "timestamp": pd.Timestamp.now().isoformat()
            })
        
        return valid_suggestions[:num_suggestions]
    
    def add_experiment_result(
        self,
        parameters: Dict[str, Any],
        metrics: Dict[str, float],
        metadata: Optional[Dict[str, Any]] = None
    ):
        """æ·»åŠ å®éªŒç»“æœåˆ°å…ˆéªŒæ•°æ®"""
        experiment = PriorExperiment(
            parameters=parameters,
            metrics=metrics,
            metadata=metadata
        )
        self.prior_experiments.append(experiment)
    



def example_usage():
    """ä½¿ç”¨ç¤ºä¾‹"""
    # 1. å®šä¹‰é—®é¢˜èƒŒæ™¯
    problem_context = ProblemContext(
        problem_description="ä¼˜åŒ–æ¿€å…‰åˆ‡å‰²å·¥è‰ºå‚æ•°ï¼Œä»¥æé«˜åˆ‡å‰²è´¨é‡å’Œæ•ˆç‡",
        industry="åˆ¶é€ ä¸š - æ¿€å…‰åŠ å·¥",
        domain_knowledge="æ¿€å…‰åŠŸç‡ã€åˆ‡å‰²é€Ÿåº¦å’Œé¢‘ç‡å¯¹è¡¨é¢ç²—ç³™åº¦å’Œåˆ‡ç¼å®½åº¦æœ‰æ˜¾è‘—å½±å“",
        constraints=["åŠŸç‡ä¸èƒ½è¶…è¿‡è®¾å¤‡ä¸Šé™", "é€Ÿåº¦å¿…é¡»ä¿è¯åˆ‡å‰²è´¨é‡"],
        optimization_goals=["æœ€å°åŒ–è¡¨é¢ç²—ç³™åº¦", "æœ€å°åŒ–åˆ‡ç¼å®½åº¦"]
    )
    
    # 2. å®šä¹‰å‚æ•°ç©ºé—´
    parameter_space = [
        Parameter(
            name="power",
            type="range",
            bounds=[1000, 3000],
            value_type="int",
            description="æ¿€å…‰åŠŸç‡",
            unit="W"
        ),
        Parameter(
            name="speed",
            type="range",
            bounds=[10.0, 50.0],
            value_type="float",
            description="åˆ‡å‰²é€Ÿåº¦",
            unit="mm/s"
        ),
        Parameter(
            name="frequency",
            type="choice",
            values=[500, 1000, 1500, 2000],
            value_type="int",
            description="è„‰å†²é¢‘ç‡",
            unit="Hz"
        )
    ]
    
    # 3. å®šä¹‰ä¼˜åŒ–ç›®æ ‡
    # æ ¼å¼: {"metric_name": {"minimize": bool}}
    # minimize=True è¡¨ç¤ºæœ€å°åŒ–ï¼Œminimize=False è¡¨ç¤ºæœ€å¤§åŒ–
    objectives = {
        "roughness": {"minimize": True},  # æœ€å°åŒ–è¡¨é¢ç²—ç³™åº¦
        "kerf_width": {"minimize": True}  # æœ€å°åŒ–åˆ‡ç¼å®½åº¦
        # ç¤ºä¾‹ï¼šå¦‚æœè¦æœ€å¤§åŒ–æŸä¸ªæŒ‡æ ‡ï¼Œå¯ä»¥è®¾ç½®ï¼š
        # "efficiency": {"minimize": False}  # æœ€å¤§åŒ–æ•ˆç‡
    }
    
    # 4. å®šä¹‰å…ˆéªŒå®éªŒæ•°æ®ï¼ˆå¯é€‰ï¼‰
    prior_experiments = [
        PriorExperiment(
            parameters={"power": 2000, "speed": 30.0, "frequency": 1000},
            metrics={"roughness": 2.5, "kerf_width": 0.15}
        ),
        PriorExperiment(
            parameters={"power": 2500, "speed": 40.0, "frequency": 1500},
            metrics={"roughness": 1.8, "kerf_width": 0.18}
        )
    ]
    
    # 5. åˆ›å»º LLINBO Agent
    # æ³¨æ„ï¼šéœ€è¦è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡æˆ–æä¾› api_key
    llm_config = LLMConfig(
        model_name="gpt-5-mini",
        api_key=os.getenv("OPENAI_API_KEY"),
        base_url="https://api.openai.com/v1"
    )
    
    # ç¤ºä¾‹1: æœ‰å…ˆéªŒæ•°æ®çš„æƒ…å†µ
    agent_with_prior = LLINBOAgent(
        problem_context=problem_context,
        parameters=parameter_space,
        objectives=objectives,
        llm_config=llm_config,
        prior_experiments=prior_experiments
    )
    
    print("=" * 80)
    print("ç¤ºä¾‹1: æœ‰å…ˆéªŒæ•°æ®çš„æƒ…å†µ")
    print("=" * 80)
    suggestions = agent_with_prior.suggest_parameters(
        num_suggestions=3, 
        print_prompt=True, 
        print_response=True
    )
    print("\nğŸ“Š ç”Ÿæˆçš„ä¼˜åŒ–å»ºè®®:")
    print(suggestions)
    
    # ç¤ºä¾‹2: æ²¡æœ‰å…ˆéªŒæ•°æ®çš„æƒ…å†µ - è‡ªåŠ¨åˆå§‹é‡‡æ ·
    agent_no_prior = LLINBOAgent(
        problem_context=problem_context,
        parameters=parameter_space,
        objectives=objectives,
        llm_config=llm_config,
        prior_experiments=None  # æ²¡æœ‰å…ˆéªŒæ•°æ®
    )
    
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹2: æ²¡æœ‰å…ˆéªŒæ•°æ®çš„æƒ…å†µï¼ˆè‡ªåŠ¨åˆå§‹é‡‡æ ·æ¨¡å¼ï¼‰")
    print("=" * 80)
    suggestions = agent_no_prior.suggest_parameters(
        num_suggestions=5, 
        print_prompt=True, 
        print_response=True,
        auto_initial_sampling=True  # è‡ªåŠ¨åˆ‡æ¢åˆ°åˆå§‹é‡‡æ ·æ¨¡å¼
    )
    print("\nğŸ“Š ç”Ÿæˆçš„åˆå§‹é‡‡æ ·å»ºè®®:")
    print(suggestions)
    
    # ç¤ºä¾‹3: æ˜¾å¼è°ƒç”¨åˆå§‹é‡‡æ ·æ–¹æ³•
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹3: æ˜¾å¼è°ƒç”¨åˆå§‹é‡‡æ ·æ–¹æ³•")
    print("=" * 80)
    suggestions = agent_no_prior.suggest_initial_parameters(
        num_suggestions=5,
        print_prompt=True,
        print_response=True
    )
    print("\nğŸ“Š ç”Ÿæˆçš„åˆå§‹é‡‡æ ·å»ºè®®:")
    print(suggestions)
 


if __name__ == "__main__":
    example_usage()

