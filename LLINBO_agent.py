"""
LLINBO Agent: Large Language Model for Bayesian Optimization Agent
åŸºäºå¤§æ¨¡å‹çš„è´å¶æ–¯ä¼˜åŒ–æ™ºèƒ½ä½“

åŠŸèƒ½ï¼š
1. æ¥å—å¯é…ç½®çš„ä¼˜åŒ–é—®é¢˜èƒŒæ™¯å’Œè¡Œä¸šæè¿°
2. æ”¯æŒå¯é…ç½®çš„å‚æ•°ç©ºé—´èŒƒå›´
3. åˆ©ç”¨å†å²å…ˆéªŒå®éªŒæ•°æ®è¿›è¡Œä¼˜åŒ–å»ºè®®
4. ä½¿ç”¨å¤§æ¨¡å‹æ¨¡æ‹Ÿè´å¶æ–¯ä¼˜åŒ–è¿‡ç¨‹
"""

from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field
import json
import os
import pandas as pd
import numpy as np
from abc import ABC, abstractmethod


@dataclass
class ProblemContext:
    """ä¼˜åŒ–é—®é¢˜èƒŒæ™¯é…ç½®"""
    problem_description: str  # é—®é¢˜æè¿°
    industry: str  # è¡Œä¸šé¢†åŸŸ
    domain_knowledge: Optional[str] = None  # é¢†åŸŸçŸ¥è¯†
    constraints: Optional[List[str]] = None  # çº¦æŸæ¡ä»¶
    optimization_goals: Optional[List[str]] = None  # ä¼˜åŒ–ç›®æ ‡è¯´æ˜


@dataclass
class Parameter:
    """å‚æ•°ç©ºé—´å®šä¹‰"""
    name: str  # å‚æ•°åç§°
    type: str  # å‚æ•°ç±»å‹: "range" æˆ– "choice"
    bounds: Optional[List[float]] = None  # èŒƒå›´å‚æ•°: [min, max]
    values: Optional[List[Any]] = None  # é€‰æ‹©å‚æ•°: [value1, value2, ...]
    value_type: str = "float"  # å€¼ç±»å‹: "int", "float", "str"
    description: Optional[str] = None  # å‚æ•°æè¿°
    unit: Optional[str] = None  # å•ä½   


@dataclass
class PriorExperiment:
    """å…ˆéªŒå®éªŒæ•°æ®"""
    parameters: Dict[str, Any]  # å‚æ•°é…ç½®
    metrics: Dict[str, float]  # å®éªŒç»“æœæŒ‡æ ‡
    metadata: Optional[Dict[str, Any]] = None  # é¢å¤–å…ƒæ•°æ®


@dataclass
class LLMConfig:
    """å¤§æ¨¡å‹é…ç½®"""
    model_name: str = "gpt-4"  # æ¨¡å‹åç§°
    api_key: Optional[str] = None  # APIå¯†é’¥
    base_url: Optional[str] = None  # APIåŸºç¡€URL
    extra_body: Dict[str, Any] = field(default_factory=lambda: {
        "thinking": {
            "type": "enabled"  # æˆ– "disabled" / "auto"
        }
    })
    
    


class LLMProvider(ABC):
    """å¤§æ¨¡å‹æä¾›è€…æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    def generate(self, prompt: str, **kwargs) -> str:
        """ç”Ÿæˆæ–‡æœ¬"""
        pass


class OpenAIProvider(LLMProvider):
    """OpenAI API æä¾›è€…"""
    
    def __init__(self, config: LLMConfig, prompt_config: Optional[Dict[str, Any]] = None):
        self.config = config
        self.prompt_config = prompt_config
        try:
            import openai
            self.client = openai.OpenAI(
                api_key=config.api_key or None,
                base_url=config.base_url
            )
        except ImportError:
            raise ImportError("è¯·å®‰è£… openai åº“: pip install openai")
        except Exception as e:
            raise RuntimeError(f"åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯å¤±è´¥: {e}")
    
    def _get_config_value(self, config: Dict[str, Any], key: str, default: str = "") -> str:
        """ä»é…ç½®ä¸­è·å–å€¼ï¼Œæ”¯æŒæ•°ç»„å’Œå­—ç¬¦ä¸²æ ¼å¼"""
        value = config.get(key, default) if config else default
        if isinstance(value, list):
            return "\n".join(value)
        return str(value) if value else default
    
    def generate(self, prompt: str, **kwargs) -> str:
        """ä½¿ç”¨ OpenAI API ç”Ÿæˆæ–‡æœ¬"""
        try:
            # è·å–ç³»ç»Ÿæ¶ˆæ¯
            system_message = self._get_config_value(self.prompt_config, "system_message", "") if self.prompt_config else ""
            
            # æ„å»º API è°ƒç”¨å‚æ•°
            api_params = {
                "model": self.config.model_name,
                "messages": [
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": prompt}
                ]
            }
            
            # å¦‚æœé…ç½®äº† extra_bodyï¼Œåˆ™æ·»åŠ åˆ° API å‚æ•°ä¸­
            if self.config.extra_body:
                api_params["extra_body"] = self.config.extra_body
            
            # åˆå¹¶ kwargs ä¸­çš„é¢å¤–å‚æ•°
            api_params.update(kwargs)
            
            response = self.client.chat.completions.create(**api_params)
        except Exception as e:
            raise RuntimeError(f"è°ƒç”¨ OpenAI API å¤±è´¥: {e}")
        if response.choices[0].message.reasoning_content:
            return response.choices[0].message.reasoning_content + "\n" + response.choices[0].message.content
        else:
            return response.choices[0].message.content


class LLINBOAgent:
    """
    åŸºäºå¤§æ¨¡å‹çš„è´å¶æ–¯ä¼˜åŒ–æ™ºèƒ½ä½“
    
    ä½¿ç”¨å¤§æ¨¡å‹æ¥æ¨¡æ‹Ÿè´å¶æ–¯ä¼˜åŒ–è¿‡ç¨‹ï¼Œç»“åˆé—®é¢˜èƒŒæ™¯ã€å‚æ•°ç©ºé—´å’Œå…ˆéªŒæ•°æ®
    ç”Ÿæˆä¼˜åŒ–å»ºè®®ã€‚
    """
    
    # ç±»çº§åˆ«çš„æç¤ºè¯é…ç½®
    _prompt_config = None
    
    @classmethod
    def _load_prompt_config(cls, config_path: str = "promt_config.json"):
        """åŠ è½½æç¤ºè¯é…ç½®æ–‡ä»¶"""
        if cls._prompt_config is None:
            import os
            # å°è¯•ä»å½“å‰ç›®å½•æˆ–ä»£ç æ‰€åœ¨ç›®å½•åŠ è½½
            possible_paths = [
                config_path,
                os.path.join(os.path.dirname(__file__), config_path),
                os.path.join(os.getcwd(), config_path)
            ]
            
            for path in possible_paths:
                if os.path.exists(path):
                    with open(path, 'r', encoding='utf-8') as f:
                        cls._prompt_config = json.load(f)
                    break
            
            if cls._prompt_config is None:
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°æç¤ºè¯é…ç½®æ–‡ä»¶: {config_path}")
        
        return cls._prompt_config
    
    def __init__(
        self,
        problem_context: ProblemContext,
        parameters: List[Parameter],
        objectives: Dict[str, Dict[str, bool]],  # {"metric_name": {"minimize": bool}}
        llm_config: Optional[LLMConfig] = None,
        prior_experiments: Optional[List[PriorExperiment]] = None,
        random_seed: Optional[int] = None,
        prompt_config_path: Optional[str] = None
    ):
        """
        åˆå§‹åŒ– LLINBO Agent
        
        Args:
            problem_context: ä¼˜åŒ–é—®é¢˜èƒŒæ™¯
            parameters: å‚æ•°å®šä¹‰åˆ—è¡¨
            objectives: ä¼˜åŒ–ç›®æ ‡é…ç½®
            llm_config: å¤§æ¨¡å‹é…ç½®ï¼ˆå¯é€‰ï¼‰
            prior_experiments: å…ˆéªŒå®éªŒæ•°æ®ï¼ˆå¯é€‰ï¼‰
            random_seed: éšæœºç§å­ï¼ˆå¯é€‰ï¼‰
            prompt_config_path: æç¤ºè¯é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ promt_config.jsonï¼‰
        """
        self.problem_context = problem_context
        self.parameters = parameters
        self.objectives = objectives
        self.prior_experiments = prior_experiments or []
        self.random_seed = random_seed
        
        # åŠ è½½æç¤ºè¯é…ç½®
        if prompt_config_path:
            self._load_prompt_config(prompt_config_path)
        else:
            self._load_prompt_config()
        self.prompt_config = self._prompt_config
        
        # åˆå§‹åŒ–å¤§æ¨¡å‹æä¾›è€…
        if llm_config is None:
            llm_config = LLMConfig()
        self.llm_config = llm_config
        
        # æ ¹æ®é…ç½®é€‰æ‹©æä¾›è€…
        self.llm_provider = OpenAIProvider(llm_config, self.prompt_config)

        # ä¼˜åŒ–å†å²è®°å½•

        self.optimization_history: List[Dict[str, Any]] = []
    
    def _build_context_prompt(self) -> str:
        """æ„å»ºåŒ…å«é—®é¢˜èƒŒæ™¯çš„æç¤ºè¯"""
        prompt_parts = [
            "# Optimization Problem Context",
            f"**Problem Description**: {self.problem_context.problem_description}",
            f"**Industry Domain**: {self.problem_context.industry}",
        ]
        
        if self.problem_context.domain_knowledge:
            prompt_parts.append(f"**Domain Knowledge**: {self.problem_context.domain_knowledge}")
        
        if self.problem_context.constraints:
            prompt_parts.append(f"**Constraints**: {', '.join(self.problem_context.constraints)}")
        
        if self.problem_context.optimization_goals:
            prompt_parts.append(f"**Optimization Goals**: {', '.join(self.problem_context.optimization_goals)}")
        
        return "\n".join(prompt_parts)
    
    def _build_parameter_space_prompt(self) -> str:
        """æ„å»ºå‚æ•°ç©ºé—´æè¿°æç¤ºè¯"""
        prompt_parts = [
            "# Parameter Space Definition",
            "The following are the parameters to be optimized and their ranges:",
            "",
            "**Important Note**: If a parameter is discrete, you must select from the listed optional values and cannot choose other values; if a parameter is continuous, the value must be within the [minimum, maximum] range."
        ]
        
        for i, param in enumerate(self.parameters, 1):
            param_desc = [f"{i}. **{param.name}**"]
            
            if param.description:
                param_desc.append(f"   Description: {param.description}")
            
            if param.type == "range" and param.bounds:
                param_desc.append(f"   Type: Continuous parameter")
                param_desc.append(f"   Range: [{param.bounds[0]}, {param.bounds[1]}]")
                if param.unit:
                    param_desc.append(f"   Unit: {param.unit}")
            elif param.type == "choice" and param.values:
                param_desc.append(f"   Type: Discrete parameter (must select one from the following values)")
                # æ˜ç¡®åˆ—å‡ºæ‰€æœ‰å¯é€‰å€¼
                values_str = ", ".join([str(v) for v in param.values])
                param_desc.append(f"   Optional values: [{values_str}]")
                param_desc.append(f"   Number of optional values: {len(param.values)}")
                param_desc.append(f"   âš ï¸ Important: Only values from the list can be selected, no other values or intermediate values")
            
            if param.value_type:
                param_desc.append(f"   Value type: {param.value_type}")
            
            prompt_parts.append("\n".join(param_desc))
        
        return "\n".join(prompt_parts)
    
    def _build_objectives_prompt(self) -> str:
        """æ„å»ºä¼˜åŒ–ç›®æ ‡æè¿°æç¤ºè¯"""
        prompt_parts = [
            "# Optimization Objectives",
            "Metrics to be optimized and their directions:"
        ]
        
        for metric_name, config in self.objectives.items():
            minimize = config.get("minimize", True)
            direction = "minimize" if minimize else "maximize"
            prompt_parts.append(f"- **{metric_name}**: {direction}")
        
        # æ·»åŠ ä¼˜åŒ–æ–¹å‘è¯´æ˜
        if len(self.objectives) > 1:
            prompt_parts.append("\n**Note**: This is a multi-objective optimization problem that requires balancing multiple objectives.")
        
        return "\n".join(prompt_parts)
    
    def _build_optimization_direction_instruction(self) -> str:
        """æ„å»ºä¼˜åŒ–æ–¹å‘è¯´æ˜"""
        instructions = []
        
        for metric_name, config in self.objectives.items():
            minimize = config.get("minimize", True)
            if minimize:
                instructions.append(
                    f"- **{metric_name}**: Needs to be **minimized**, prioritize parameter combinations that can reduce this metric value"
                )
            else:
                instructions.append(
                    f"- **{metric_name}**: Needs to be **maximized**, prioritize parameter combinations that can increase this metric value"
                )
        
        return "\n".join(instructions)
    
    def _build_prior_data_prompt(self) -> str:
        """æ„å»ºå…ˆéªŒå®éªŒæ•°æ®æç¤ºè¯"""
        if not self.prior_experiments:
            return "# Prior Experimental Data\nNo prior experimental data available."
        
        prompt_parts = [
            "# Prior Experimental Data",
            f"The following are {len(self.prior_experiments)} historical experimental results:",
            ""
        ]
        
        # è½¬æ¢ä¸ºè¡¨æ ¼æ ¼å¼
        data_rows = []
        for i, exp in enumerate(self.prior_experiments, 1):
            row = {
                "Experiment_ID": i,
                **exp.parameters,
                **exp.metrics
            }
            data_rows.append(row)
        
        df = pd.DataFrame(data_rows)
        prompt_parts.append("```")
        prompt_parts.append(df.to_string(index=False))
        prompt_parts.append("```")
        
        
        return "\n".join(prompt_parts)
    
    def _build_initial_sampling_prompt(self, num_suggestions: int = 1) -> str:
        """æ„å»ºåˆå§‹é‡‡æ ·æç¤ºè¯ï¼ˆæ— å…ˆéªŒæ•°æ®æ—¶ä½¿ç”¨ï¼‰"""
        # ä»é…ç½®æ–‡ä»¶è¯»å–åˆå§‹é‡‡æ ·æç¤ºè¯
        init_config = self.prompt_config.get("initial_sampling", "")
        
        # å¦‚æœæ˜¯æ•°ç»„ï¼Œç”¨æ¢è¡Œç¬¦è¿æ¥
        if isinstance(init_config, list):
            init_template = "\n".join(init_config)
        else:
            init_template = init_config
        
        # æ›¿æ¢å ä½ç¬¦
        init_content = init_template.format(num_suggestions=num_suggestions)
        
        prompt_parts = [
            self._build_context_prompt(),
            "",
            self._build_parameter_space_prompt(),
            "",
            self._build_objectives_prompt(),
            "",
            init_content
        ]
        
        return "\n".join(prompt_parts)
    
    def _build_optimization_prompt(self, num_suggestions: int = 1) -> str:
        """æ„å»ºå®Œæ•´çš„ä¼˜åŒ–æç¤ºè¯"""
        # ä»é…ç½®æ–‡ä»¶è¯»å–ä¼˜åŒ–æç¤ºè¯
        opt_config = self.prompt_config.get("optimization", "")
        
        # å¦‚æœæ˜¯æ•°ç»„ï¼Œç”¨æ¢è¡Œç¬¦è¿æ¥
        if isinstance(opt_config, list):
            opt_template = "\n".join(opt_config)
        else:
            opt_template = opt_config
        
        # æ›¿æ¢å ä½ç¬¦
        optimization_direction = self._build_optimization_direction_instruction()
        opt_content = opt_template.format(
            num_suggestions=num_suggestions,
            optimization_direction=optimization_direction
        )
        
        prompt_parts = [
            self._build_context_prompt(),
            "",
            self._build_parameter_space_prompt(),
            "",
            self._build_objectives_prompt(),
            "",
            self._build_prior_data_prompt(),
            "",
            opt_content
        ]
        
        return "\n".join(prompt_parts)
    
    def _parse_llm_response(self, response: str) -> List[Dict[str, Any]]:
        """è§£æå¤§æ¨¡å‹è¿”å›çš„JSONæ ¼å¼å“åº”"""
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†
            json_str = None
            
            # æ–¹æ³•1: æŸ¥æ‰¾ ```json ... ```
            if "```json" in response:
                json_start = response.find("```json") + 7
                json_end = response.find("```", json_start)
                if json_end > json_start:
                    json_str = response[json_start:json_end].strip()
            
            # æ–¹æ³•2: æŸ¥æ‰¾ ``` ... ```
            if json_str is None and "```" in response:
                parts = response.split("```")
                for i in range(1, len(parts), 2):
                    candidate = parts[i].strip()
                    if candidate.startswith("json"):
                        candidate = candidate[4:].strip()
                    if candidate.startswith("{") or candidate.startswith("["):
                        json_str = candidate
                        break
            
            # æ–¹æ³•3: æŸ¥æ‰¾ç¬¬ä¸€ä¸ª { æˆ– [
            if json_str is None:
                for start_char in ["{", "["]:
                    start_idx = response.find(start_char)
                    if start_idx >= 0:
                        # æ‰¾åˆ°åŒ¹é…çš„ç»“æŸå­—ç¬¦
                        end_char = "}" if start_char == "{" else "]"
                        depth = 0
                        for i in range(start_idx, len(response)):
                            if response[i] == start_char:
                                depth += 1
                            elif response[i] == end_char:
                                depth -= 1
                                if depth == 0:
                                    json_str = response[start_idx:i+1]
                                    break
                        if json_str:
                            break
            
            # æ–¹æ³•4: ç›´æ¥è§£ææ•´ä¸ªå“åº”
            if json_str is None:
                json_str = response.strip()
            
            result = json.loads(json_str)
            
            if "suggestions" in result:
                return result["suggestions"]
            elif isinstance(result, list):
                return result
            elif isinstance(result, dict):
                # å¦‚æœç»“æœæ˜¯å•ä¸ªå­—å…¸ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«å‚æ•°
                if any(key in result for key in [p.name for p in self.parameters]):
                    return [result]
                else:
                    return []
            else:
                return []
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
            print(f"å“åº”å†…å®¹ï¼ˆå‰500å­—ç¬¦ï¼‰: {response[:500]}")
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
            return []
        except Exception as e:
            print(f"âš ï¸ è§£æå“åº”æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return []
    
    def _validate_parameters(self, params: Dict[str, Any]) -> bool:
        """éªŒè¯å‚æ•°æ˜¯å¦åœ¨å®šä¹‰çš„ç©ºé—´å†…"""
        for param_def in self.parameters:
            param_name = param_def.name
            if param_name not in params:
                continue  # å…è®¸ç¼ºå°‘æŸäº›å‚æ•°
            
            value = params[param_name]
            
            if param_def.type == "range":
                if param_def.bounds is None:
                    continue
                min_val, max_val = param_def.bounds
                if not (min_val <= value <= max_val):
                    return False
                
                # ç±»å‹è½¬æ¢æ£€æŸ¥
                if param_def.value_type == "int":
                    if not isinstance(value, (int, float)) or int(value) != value:
                        return False
            elif param_def.type == "choice":
                if param_def.values is None:
                    continue
                if value not in param_def.values:
                    return False
        
        return True
    
    def _normalize_parameters(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """è§„èŒƒåŒ–å‚æ•°å€¼ï¼ˆç±»å‹è½¬æ¢ç­‰ï¼‰"""
        normalized = {}
        
        for param_def in self.parameters:
            param_name = param_def.name
            if param_name not in params:
                continue
            
            value = params[param_name]
            
            # ç±»å‹è½¬æ¢
            if param_def.value_type == "int":
                value = int(float(value))
            elif param_def.value_type == "float":
                value = float(value)
            elif param_def.value_type == "str":
                value = str(value)
            
            normalized[param_name] = value
        
        return normalized
    
    def suggest_initial_parameters(
        self, 
        num_suggestions: int = 1, 
        print_prompt: bool = False, 
        print_response: bool = False
    ) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆåˆå§‹é‡‡æ ·å‚æ•°å»ºè®®ï¼ˆæ— å…ˆéªŒæ•°æ®æ—¶ä½¿ç”¨ï¼‰
        
        è¯¥æ–¹æ³•ä¸“é—¨ç”¨äºæ²¡æœ‰å…ˆéªŒå®éªŒæ•°æ®çš„æƒ…å†µï¼ŒåŸºäºé¢†åŸŸçŸ¥è¯†æ¨èæœ€æœ‰å¸Œæœ›è¾¾åˆ°æœ€ä¼˜è§£é™„è¿‘çš„å‚æ•°ç»„åˆã€‚
        ä¸éœ€è¦å‡åŒ€è¦†ç›–å‚æ•°ç©ºé—´ï¼Œåªéœ€è¦æ¨èè¶³å¤Ÿå¥½çš„å‚æ•°ç»„åˆå³å¯ã€‚
        
        Args:
            num_suggestions: éœ€è¦ç”Ÿæˆçš„å»ºè®®æ•°é‡
            print_prompt: æ˜¯å¦æ‰“å°è¾“å…¥å¤§æ¨¡å‹çš„å®Œæ•´æç¤ºè¯
            print_response: æ˜¯å¦æ‰“å°å¤§æ¨¡å‹çš„åŸå§‹å›ç­”
            
        Returns:
            æ¨èçš„å‚æ•°é…ç½®åˆ—è¡¨
        """
        # æ„å»ºåˆå§‹é‡‡æ ·æç¤ºè¯
        prompt = self._build_initial_sampling_prompt(num_suggestions=num_suggestions)
        
        # æ ¹æ® print_prompt å‚æ•°å†³å®šæ˜¯å¦æ‰“å°å®Œæ•´æç¤ºè¯
        if print_prompt:
            print("\n" + "=" * 80)
            print("ğŸ“ è¾“å…¥å¤§æ¨¡å‹çš„å®Œæ•´æç¤ºè¯ï¼ˆåˆå§‹é‡‡æ ·æ¨¡å¼ï¼‰:")
            print("=" * 80)
            print(prompt)
            print("=" * 80 + "\n")
        
        # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå»ºè®®
        print("ğŸ¤– æ­£åœ¨ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆåˆå§‹é‡‡æ ·å»ºè®®...")
        response = self.llm_provider.generate(prompt)
        
        # æ ¹æ® print_response å‚æ•°å†³å®šæ˜¯å¦æ‰“å°å¤§æ¨¡å‹çš„åŸå§‹å›ç­”
        if print_response:
            print("\n" + "=" * 80)
            print("ğŸ“¤ å¤§æ¨¡å‹çš„åŸå§‹å›ç­”:")
            print("=" * 80)
            print(response)
            print("=" * 80 + "\n")
        
        # è§£æå“åº”
        suggestions = self._parse_llm_response(response)
        
        # éªŒè¯å’Œè§„èŒƒåŒ–å‚æ•°
        valid_suggestions = []
        for suggestion in suggestions:
            params = {k: v for k, v in suggestion.items() if k != "reason"}
            
            if self._validate_parameters(params):
                normalized = self._normalize_parameters(params)
                valid_suggestions.append(normalized)
            else:
                print(f"âš ï¸ å‚æ•°éªŒè¯å¤±è´¥ï¼Œè·³è¿‡: {params}")
        
        # å¦‚æœéªŒè¯åçš„å»ºè®®æ•°é‡ä¸è¶³ï¼Œå°è¯•ç”Ÿæˆæ›´å¤š
        if len(valid_suggestions) < num_suggestions:
            print(f"âš ï¸ åªç”Ÿæˆäº† {len(valid_suggestions)} ä¸ªæœ‰æ•ˆå»ºè®®ï¼ŒæœŸæœ› {num_suggestions} ä¸ª")
        
        # è®°å½•åˆ°å†å²
        for suggestion in valid_suggestions:
            self.optimization_history.append({
                "suggestion": suggestion,
                "timestamp": pd.Timestamp.now().isoformat(),
                "type": "initial_sampling"
            })
        
        return valid_suggestions[:num_suggestions]
    
    def suggest_parameters(
        self, 
        num_suggestions: int = 1, 
        print_prompt: bool = False, 
        print_response: bool = False,
        auto_initial_sampling: bool = True
    ) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆå‚æ•°ä¼˜åŒ–å»ºè®®
        
        Args:
            num_suggestions: éœ€è¦ç”Ÿæˆçš„å»ºè®®æ•°é‡
            print_prompt: æ˜¯å¦æ‰“å°è¾“å…¥å¤§æ¨¡å‹çš„å®Œæ•´æç¤ºè¯
            print_response: æ˜¯å¦æ‰“å°å¤§æ¨¡å‹çš„åŸå§‹å›ç­”
            auto_initial_sampling: å¦‚æœæ²¡æœ‰å…ˆéªŒæ•°æ®ï¼Œæ˜¯å¦è‡ªåŠ¨åˆ‡æ¢åˆ°åˆå§‹é‡‡æ ·æ¨¡å¼ï¼ˆé»˜è®¤Trueï¼‰
            
        Returns:
            æ¨èçš„å‚æ•°é…ç½®åˆ—è¡¨
        """
        # å¦‚æœæ²¡æœ‰å…ˆéªŒæ•°æ®ä¸”å¯ç”¨äº†è‡ªåŠ¨åˆå§‹é‡‡æ ·ï¼Œåˆ™ä½¿ç”¨åˆå§‹é‡‡æ ·æ¨¡å¼
        if not self.prior_experiments and auto_initial_sampling:
            print("ğŸ“Š æ£€æµ‹åˆ°æ²¡æœ‰å…ˆéªŒå®éªŒæ•°æ®ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°åˆå§‹é‡‡æ ·æ¨¡å¼...")
            return self.suggest_initial_parameters(
                num_suggestions=num_suggestions,
                print_prompt=print_prompt,
                print_response=print_response
            )
        
        # æ„å»ºæç¤ºè¯
        prompt = self._build_optimization_prompt(num_suggestions=num_suggestions)
        
        # æ ¹æ® print_prompt å‚æ•°å†³å®šæ˜¯å¦æ‰“å°å®Œæ•´æç¤ºè¯
        if print_prompt:
            print("\n" + "=" * 80)
            print("ğŸ“ è¾“å…¥å¤§æ¨¡å‹çš„å®Œæ•´æç¤ºè¯:")
            print("=" * 80)
            print(prompt)
            print("=" * 80 + "\n")
        
        # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå»ºè®®
        print("ğŸ¤– æ­£åœ¨ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆä¼˜åŒ–å»ºè®®...")
        response = self.llm_provider.generate(prompt)
        
        # æ ¹æ® print_response å‚æ•°å†³å®šæ˜¯å¦æ‰“å°å¤§æ¨¡å‹çš„åŸå§‹å›ç­”
        if print_response:
            print("\n" + "=" * 80)
            print("ğŸ“¤ å¤§æ¨¡å‹çš„åŸå§‹å›ç­”:")
            print("=" * 80)
            print(response)
            print("=" * 80 + "\n")
        
        # è§£æå“åº”
        suggestions = self._parse_llm_response(response)
        
        # éªŒè¯å’Œè§„èŒƒåŒ–å‚æ•°
        valid_suggestions = []
        for suggestion in suggestions:
            params = {k: v for k, v in suggestion.items() if k != "reason"}
            
            if self._validate_parameters(params):
                normalized = self._normalize_parameters(params)
                valid_suggestions.append(normalized)
            else:
                print(f"âš ï¸ å‚æ•°éªŒè¯å¤±è´¥ï¼Œè·³è¿‡: {params}")
        
        # å¦‚æœéªŒè¯åçš„å»ºè®®æ•°é‡ä¸è¶³ï¼Œå°è¯•ç”Ÿæˆæ›´å¤š
        if len(valid_suggestions) < num_suggestions:
            print(f"âš ï¸ åªç”Ÿæˆäº† {len(valid_suggestions)} ä¸ªæœ‰æ•ˆå»ºè®®ï¼ŒæœŸæœ› {num_suggestions} ä¸ª")
        
        # è®°å½•åˆ°å†å²
        for suggestion in valid_suggestions:
            self.optimization_history.append({
                "suggestion": suggestion,
                "timestamp": pd.Timestamp.now().isoformat()
            })
        
        return valid_suggestions[:num_suggestions]
    
    def add_experiment_result(
        self,
        parameters: Dict[str, Any],
        metrics: Dict[str, float],
        metadata: Optional[Dict[str, Any]] = None
    ):
        """æ·»åŠ å®éªŒç»“æœåˆ°å…ˆéªŒæ•°æ®"""
        experiment = PriorExperiment(
            parameters=parameters,
            metrics=metrics,
            metadata=metadata
        )
        self.prior_experiments.append(experiment)

