from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.responses import HTMLResponse
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional, Union, Literal
import uvicorn
import pandas as pd
import tempfile
import os
import json
import uuid
from pathlib import Path
from datetime import datetime
from doe_init import generate_sobol_parameters, generate_lhs_parameters, generate_uniform_parameters
from ax_optimizer import BayesianOptimizer, ExperimentResult
from analysis import ParameterOptimizationAnalysis
from __init__ import get_class_from_string

app = FastAPI(
    title="å‚æ•°ä¼˜åŒ–API v3",
    description="æ”¯æŒå…ˆéªŒå®éªŒæ•°æ®çš„å‚æ•°ä¼˜åŒ–APIï¼Œé»˜è®¤sobolé‡‡æ ·ï¼Œæ”¯æŒå¤šç§é‡‡æ ·æ–¹å¼ï¼Œæ–°å¢è´å¶æ–¯ä¼˜åŒ–æ”¯æŒ",
    version="3.0.0"
)

# æŒä¹…åŒ–å­˜å‚¨é…ç½® - ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•ï¼Œå…¼å®¹érootç”¨æˆ·å’ŒWindows
PERSISTENT_OUTPUT_DIR = Path.cwd() / "analysis_output"
CHART_FILES_METADATA = PERSISTENT_OUTPUT_DIR / "chart_files.json"

# ç¡®ä¿æŒä¹…åŒ–ç›®å½•å­˜åœ¨
PERSISTENT_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# å­˜å‚¨å›¾è¡¨æ–‡ä»¶æ˜ å°„çš„å…¨å±€å˜é‡
chart_files = {}

# å¯åŠ¨æ—¶åŠ è½½å·²å­˜åœ¨çš„å›¾è¡¨æ˜ å°„
def load_chart_files():
    """ä»æŒä¹…åŒ–å­˜å‚¨åŠ è½½å›¾è¡¨æ–‡ä»¶æ˜ å°„"""
    global chart_files
    if CHART_FILES_METADATA.exists():
        try:
            with open(CHART_FILES_METADATA, 'r', encoding='utf-8') as f:
                chart_files = json.load(f)
            print(f"âœ… åŠ è½½äº† {len(chart_files)} ä¸ªå·²å­˜åœ¨çš„å›¾è¡¨æ–‡ä»¶æ˜ å°„")
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å›¾è¡¨æ–‡ä»¶æ˜ å°„å¤±è´¥: {e}")
            chart_files = {}
    else:
        chart_files = {}

def save_chart_files():
    """ä¿å­˜å›¾è¡¨æ–‡ä»¶æ˜ å°„åˆ°æŒä¹…åŒ–å­˜å‚¨"""
    try:
        with open(CHART_FILES_METADATA, 'w', encoding='utf-8') as f:
            json.dump(chart_files, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜å›¾è¡¨æ–‡ä»¶æ˜ å°„å¤±è´¥: {e}")

# å¯åŠ¨æ—¶åŠ è½½
load_chart_files()

def cleanup_expired_files(days=30):
    """æ¸…ç†è¶…è¿‡æŒ‡å®šå¤©æ•°çš„è¿‡æœŸæ–‡ä»¶"""
    try:
        from datetime import datetime, timedelta
        cutoff_date = datetime.now() - timedelta(days=days)
        
        # æ¸…ç†è¿‡æœŸçš„å›¾è¡¨æ–‡ä»¶
        expired_files = []
        for file_id, file_info in list(chart_files.items()):
            if 'created_at' in file_info:
                created_at = datetime.fromisoformat(file_info['created_at'])
                if created_at < cutoff_date:
                    expired_files.append(file_id)
        
        # åˆ é™¤è¿‡æœŸçš„æ–‡ä»¶æ˜ å°„å’Œå®é™…æ–‡ä»¶
        for file_id in expired_files:
            file_info = chart_files[file_id]
            file_path = file_info['path']
            
            # åˆ é™¤å®é™…æ–‡ä»¶
            if os.path.exists(file_path):
                try:
                    os.unlink(file_path)
                    print(f"ğŸ—‘ï¸ åˆ é™¤è¿‡æœŸæ–‡ä»¶: {file_path}")
                except Exception as e:
                    print(f"âš ï¸ åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            
            # åˆ é™¤æ˜ å°„
            del chart_files[file_id]
        
        if expired_files:
            save_chart_files()
            print(f"âœ… æ¸…ç†äº† {len(expired_files)} ä¸ªè¿‡æœŸæ–‡ä»¶")
        
        # æ¸…ç†ç©ºçš„è¾“å‡ºç›®å½•
        for output_dir in PERSISTENT_OUTPUT_DIR.iterdir():
            if output_dir.is_dir() and not any(output_dir.iterdir()):
                try:
                    output_dir.rmdir()
                    print(f"ğŸ—‘ï¸ åˆ é™¤ç©ºç›®å½•: {output_dir}")
                except Exception as e:
                    print(f"âš ï¸ åˆ é™¤ç›®å½•å¤±è´¥ {output_dir}: {e}")
                    
    except Exception as e:
        print(f"âš ï¸ æ¸…ç†è¿‡æœŸæ–‡ä»¶å¤±è´¥: {e}")

# å¯åŠ¨æ—¶æ¸…ç†è¿‡æœŸæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
# cleanup_expired_files(days=30)



# å®šä¹‰å‚æ•°ç©ºé—´æ¨¡å‹
class ParameterSpace(BaseModel):
    name: str = Field(..., description="å‚æ•°åç§°")
    type: Literal["choice", "range"] = Field(..., description="å‚æ•°ç±»å‹ï¼šchoiceï¼ˆç¦»æ•£é€‰æ‹©ï¼‰æˆ–rangeï¼ˆè¿ç»­èŒƒå›´ï¼‰")
    values: Union[List[Union[str, int, float]], List[float]] = Field(..., description="å½“typeä¸ºchoiceæ—¶è¡¨ç¤ºå¯é€‰å€¼åˆ—è¡¨ï¼Œå½“typeä¸ºrangeæ—¶è¡¨ç¤º[æœ€å°å€¼, æœ€å¤§å€¼]")
    step: Optional[Union[int, float]] = Field(None, description="æ­¥é•¿ï¼Œç”¨äºå°†rangeå‚æ•°è½¬æ¢ä¸ºchoiceå‚æ•°")

# å®šä¹‰å…ˆéªŒå®éªŒæ•°æ®æ¨¡å‹
class PriorExperiment(BaseModel):
    parameters: Dict[str, Union[str, int, float]] = Field(..., description="å‚æ•°ç»„åˆ")
    metrics: Dict[str, Union[int, float]] = Field(..., description="å®éªŒç»“æœæŒ‡æ ‡")

# å®šä¹‰åˆå§‹åŒ–è¯·æ±‚æ¨¡å‹
class InitRequest(BaseModel):
    parameter_space: List[ParameterSpace] = Field(..., description="å‚æ•°ç©ºé—´å®šä¹‰")
    objectives: List[str] = Field(..., description="ä¼˜åŒ–ç›®æ ‡åˆ—è¡¨")
    batch: int = Field(..., description="æ¯æ‰¹æ¬¡å‚æ•°æ•°é‡", ge=1, le=20)
    seed: Optional[int] = Field(None, description="éšæœºç§å­")
    prior_experiments: Optional[List[PriorExperiment]] = Field(None, description="å…ˆéªŒå®éªŒæ•°æ®")
    sampling_method: Optional[Literal["sobol", "lhs", "uniform"]] = Field("sobol", description="é‡‡æ ·æ–¹æ³•ï¼ˆä»…åœ¨æ²¡æœ‰å…ˆéªŒæ•°æ®æ—¶ç”Ÿæ•ˆï¼‰")

# å®šä¹‰å“åº”æ¨¡å‹
class InitResponse(BaseModel):
    success: bool
    sampling_method: str
    results: List[Dict[str, Any]]
    message: str

# å®šä¹‰æ›´æ–°è¯·æ±‚æ¨¡å‹
class UpdateRequest(BaseModel):
    parameter_space: List[ParameterSpace] = Field(..., description="å‚æ•°ç©ºé—´å®šä¹‰")
    objectives: Dict[str, Dict[str, bool]] = Field(..., description="ä¼˜åŒ–ç›®æ ‡é…ç½®ï¼Œæ ¼å¼ä¸º{'metric_name': {'minimize': bool}}")
    completed_experiments: List[PriorExperiment] = Field(..., description="å·²å®Œæˆçš„å®éªŒç»“æœ")
    batch: int = Field(1, description="ä¸‹ä¸€æ‰¹æ¬¡å‚æ•°æ•°é‡", ge=1, le=10)
    use_weights: Optional[bool] = Field(False, description="æ˜¯å¦ä½¿ç”¨æƒé‡ä¼˜åŒ–")
    objective_weights: Optional[Dict[str, float]] = Field(None, description="ç›®æ ‡æƒé‡")
    additional_metrics: Optional[List[str]] = Field(None, description="é¢å¤–è·Ÿè¸ªæŒ‡æ ‡")
    seed: Optional[int] = Field(None, description="éšæœºç§å­")
    # æ–°å¢è‡ªå®šä¹‰æ¨¡å‹é…ç½®
    surrogate_model_class: Optional[str] = Field(None, description="ä»£ç†æ¨¡å‹ç±»åï¼Œå¦‚ 'SingleTaskGP', 'MultiTaskGP' ç­‰")
    kernel_class: Optional[str] = Field(None, description="æ ¸å‡½æ•°ç±»åï¼Œå¦‚ 'MaternKernel', 'RBFKernel' ç­‰")
    kernel_options: Optional[Dict[str, Any]] = Field(None, description="æ ¸å‡½æ•°å‚æ•°ï¼Œå¦‚ {'nu': 2.5} for MaternKernel")
    # æ–°å¢é‡‡é›†å‡½æ•°é…ç½®
    acquisition_function_class: Optional[str] = Field(None, description="é‡‡é›†å‡½æ•°ç±»å")
    acquisition_function_options: Optional[Dict[str, Any]] = Field(None, description="é‡‡é›†å‡½æ•°å‚æ•°ï¼Œå¦‚ {'beta': 0.1} for UCB")

# å®šä¹‰æ›´æ–°å“åº”æ¨¡å‹
class UpdateResponse(BaseModel):
    success: bool
    results: List[Dict[str, Any]]
    message: str

# å®šä¹‰åˆ†æè¯·æ±‚æ¨¡å‹
class AnalysisRequest(BaseModel):
    parameter_space: List[ParameterSpace] = Field(..., description="å‚æ•°ç©ºé—´å®šä¹‰")
    objectives: Union[List[str], Dict[str, Dict[str, bool]]] = Field(..., description="ä¼˜åŒ–ç›®æ ‡é…ç½®ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨æˆ–å­—å…¸æ ¼å¼")
    completed_experiments: List[PriorExperiment] = Field(..., description="å·²å®Œæˆçš„å®éªŒç»“æœ")
    # å¯é€‰çš„è‡ªå®šä¹‰ä»£ç†æ¨¡å‹é…ç½®
    surrogate_model_class: Optional[str] = Field(None, description="ä»£ç†æ¨¡å‹ç±»åï¼Œå¦‚ 'SingleTaskGP', 'MultiTaskGP' ç­‰")
    kernel_class: Optional[str] = Field(None, description="æ ¸å‡½æ•°ç±»åï¼Œå¦‚ 'MaternKernel', 'RBFKernel' ç­‰")
    kernel_options: Optional[Dict[str, Any]] = Field(None, description="æ ¸å‡½æ•°å‚æ•°ï¼Œå¦‚ {'nu': 2.5} for MaternKernel")

# å®šä¹‰åˆ†æå“åº”æ¨¡å‹
class AnalysisResponse(BaseModel):
    success: bool
    message: str
    generated_plots: List[str] = Field(..., description="ç”Ÿæˆçš„å›¾è¡¨åˆ—è¡¨")
    output_directory: str = Field(..., description="è¾“å‡ºç›®å½•è·¯å¾„")
    has_categorical_data: bool = Field(..., description="æ˜¯å¦åŒ…å«ç±»åˆ«æ•°æ®")
    view_links: List[Dict[str, str]] = Field(default=[], description="å›¾è¡¨æŸ¥çœ‹é“¾æ¥åˆ—è¡¨ï¼ŒåŒ…å«nameã€urlã€typeå­—æ®µ")

# å®šä¹‰åˆ‡ç‰‡å›¾è¯·æ±‚æ¨¡å‹
class SliceAnalysisRequest(BaseModel):
    parameter_space: List[ParameterSpace] = Field(..., description="å‚æ•°ç©ºé—´å®šä¹‰")
    objectives: Union[List[str], Dict[str, Dict[str, bool]]] = Field(..., description="ä¼˜åŒ–ç›®æ ‡é…ç½®ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨æˆ–å­—å…¸æ ¼å¼")
    completed_experiments: List[PriorExperiment] = Field(..., description="å·²å®Œæˆçš„å®éªŒç»“æœ")
    parameter: str = Field(..., description="è¦åˆ†æçš„å‚æ•°åç§°")
    objective: str = Field(..., description="è¦åˆ†æçš„ç›®æ ‡åç§°")
    surrogate_model_class: Optional[str] = Field(None, description="ä»£ç†æ¨¡å‹ç±»å")
    kernel_class: Optional[str] = Field(None, description="æ ¸å‡½æ•°ç±»å")
    kernel_options: Optional[Dict[str, Any]] = Field(None, description="æ ¸å‡½æ•°å‚æ•°")

# å®šä¹‰ç­‰é«˜çº¿å›¾è¯·æ±‚æ¨¡å‹
class ContourAnalysisRequest(BaseModel):
    parameter_space: List[ParameterSpace] = Field(..., description="å‚æ•°ç©ºé—´å®šä¹‰")
    objectives: Union[List[str], Dict[str, Dict[str, bool]]] = Field(..., description="ä¼˜åŒ–ç›®æ ‡é…ç½®ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨æˆ–å­—å…¸æ ¼å¼")
    completed_experiments: List[PriorExperiment] = Field(..., description="å·²å®Œæˆçš„å®éªŒç»“æœ")
    parameter1: str = Field(..., description="ç¬¬ä¸€ä¸ªå‚æ•°åç§°")
    parameter2: str = Field(..., description="ç¬¬äºŒä¸ªå‚æ•°åç§°")
    objective: str = Field(..., description="è¦åˆ†æçš„ç›®æ ‡åç§°")
    surrogate_model_class: Optional[str] = Field(None, description="ä»£ç†æ¨¡å‹ç±»å")
    kernel_class: Optional[str] = Field(None, description="æ ¸å‡½æ•°ç±»å")
    kernel_options: Optional[Dict[str, Any]] = Field(None, description="æ ¸å‡½æ•°å‚æ•°")

# å®šä¹‰å•ä¸ªå›¾è¡¨å“åº”æ¨¡å‹
class SinglePlotResponse(BaseModel):
    success: bool
    message: str
    plot_name: str = Field(..., description="ç”Ÿæˆçš„å›¾è¡¨åç§°")
    view_link: Dict[str, str] = Field(..., description="å›¾è¡¨æŸ¥çœ‹é“¾æ¥ï¼ŒåŒ…å«nameã€urlã€typeå­—æ®µ")

def convert_parameter_space_to_ax_format(parameter_space: List[ParameterSpace]) -> List[Dict[str, Any]]:
    """å°†å‚æ•°ç©ºé—´è½¬æ¢ä¸ºAxæ ¼å¼"""
    search_space = []
    for param in parameter_space:
        if param.type == "choice":
            # ç¡®å®švalue_typeï¼šå­—ç¬¦ä¸²ã€æµ®ç‚¹æ•°ã€æ•´æ•°
            if all(isinstance(x, str) for x in param.values):
                value_type = "str"
            elif any(isinstance(x, float) for x in param.values):
                value_type = "float"
            else:
                value_type = "int"
            
            # å¯¹äºæµ®ç‚¹æ•°choiceå‚æ•°ï¼Œç¡®ä¿å€¼éƒ½æ˜¯æµ®ç‚¹æ•°ç±»å‹
            if value_type == "float":
                values = [float(v) for v in param.values]
            else:
                values = param.values
            
            search_space.append({
                "name": param.name,
                "type": "choice",
                "values": values,
                "value_type": value_type,
                "is_ordered": True,
                "sort_values": True
            })
        else:  # rangeç±»å‹
            if len(param.values) != 2:
                raise ValueError(f"å‚æ•° {param.name} çš„rangeç±»å‹å¿…é¡»æä¾›[æœ€å°å€¼, æœ€å¤§å€¼]")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰stepå‚æ•°ï¼Œå¦‚æœæœ‰åˆ™è½¬æ¢ä¸ºchoice
            if param.step is not None:
                min_val, max_val = param.values
                step = param.step
                
                # è®¡ç®—å°æ•°ä½æ•°ç”¨äºç²¾ç¡®å¤„ç†æµ®ç‚¹æ•°
                decimal_places = 0
                if isinstance(step, float):
                    step_str = f"{step:.10f}".rstrip('0').rstrip('.')
                    if '.' in step_str:
                        decimal_places = len(step_str.split('.')[1])
                
                # ç”Ÿæˆæ­¥é•¿åºåˆ—ï¼Œä½¿ç”¨roundé¿å…æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜
                values = []
                current_val = min_val
                tolerance = step * 0.0001  # æ·»åŠ å°çš„å®¹å·®
                
                while current_val <= max_val + tolerance:
                    rounded_val = round(current_val, decimal_places)
                    if rounded_val <= max_val:
                        values.append(rounded_val)
                    current_val += step
                
                # ç¡®ä¿åŒ…å«æœ€å¤§å€¼ï¼ˆå¦‚æœå®ƒåº”è¯¥åœ¨åºåˆ—ä¸­ï¼‰
                max_val_rounded = round(max_val, decimal_places)
                if max_val_rounded not in values:
                    # æ£€æŸ¥max_valæ˜¯å¦åº”è¯¥åœ¨åºåˆ—ä¸­
                    expected_count = round((max_val - min_val) / step) + 1
                    if len(values) < expected_count:
                        values.append(max_val_rounded)
                
                # å»é‡å¹¶æ’åº
                values = sorted(list(set(values)))
                
                # ç¡®å®švalue_type
                if any(isinstance(x, float) for x in [min_val, max_val, step]) or decimal_places > 0:
                    value_type = "float"
                    values = [float(v) for v in values]
                else:
                    value_type = "int"
                    values = [int(v) for v in values]
                
                search_space.append({
                    "name": param.name,
                    "type": "choice",
                    "values": values,
                    "value_type": value_type,
                    "is_ordered": True,
                    "sort_values": True
                })
            else:
                # æ²¡æœ‰stepå‚æ•°ï¼Œä¿æŒä¸ºrangeç±»å‹
                search_space.append({
                    "name": param.name,
                    "type": "range",
                    "bounds": param.values,
                    "value_type": "float" if any(isinstance(x, float) for x in param.values) else "int"
                })
    return search_space

def convert_parameter_space_to_ax_format_for_analysis(parameter_space: List[ParameterSpace]) -> List[Dict[str, Any]]:
    """å°†å‚æ•°ç©ºé—´è½¬æ¢ä¸ºAxæ ¼å¼ï¼ˆä¸“é—¨ç”¨äºanalysisæ¥å£ï¼Œå¿½ç•¥stepå‚æ•°ï¼‰"""
    search_space = []
    for param in parameter_space:
        if param.type == "choice":
            # ç¡®å®švalue_typeï¼šå­—ç¬¦ä¸²ã€æµ®ç‚¹æ•°ã€æ•´æ•°
            if all(isinstance(x, str) for x in param.values):
                value_type = "str"
                values = param.values
            else:
                # å¯¹äºæ•°å€¼ç±»å‹ï¼Œç»Ÿä¸€ä½¿ç”¨floatä»¥é¿å…ç±»å‹è½¬æ¢é—®é¢˜
                value_type = "float"
                values = [float(v) for v in param.values]
            
            search_space.append({
                "name": param.name,
                "type": "choice",
                "values": values,
                "value_type": value_type,
                "is_ordered": True,
                "sort_values": True
            })
        else:  # rangeç±»å‹
            if len(param.values) != 2:
                raise ValueError(f"å‚æ•° {param.name} çš„rangeç±»å‹å¿…é¡»æä¾›[æœ€å°å€¼, æœ€å¤§å€¼]")
            
            # åœ¨analysisæ¥å£ä¸­ï¼Œå¿½ç•¥stepå‚æ•°ï¼Œå§‹ç»ˆä¿æŒä¸ºrangeç±»å‹
            # ä¸ºäº†å…¼å®¹CSVæ•°æ®ä¸­çš„numpy.float64ç±»å‹ï¼Œç»Ÿä¸€ä½¿ç”¨floatç±»å‹
            value_type = "float"
            
            # ç¡®ä¿boundsä¸­çš„å€¼ä¹Ÿæ˜¯æµ®ç‚¹æ•°ç±»å‹
            float_bounds = [float(val) for val in param.values]
            
            search_space.append({
                "name": param.name,
                "type": "range",
                "bounds": float_bounds,
                "value_type": value_type
            })
    return search_space

def convert_prior_experiments_to_dict(prior_experiments: List[PriorExperiment]) -> List[Dict[str, Any]]:
    """å°†å…ˆéªŒå®éªŒæ•°æ®è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
    experiments = []
    for exp in prior_experiments:
        # åˆå¹¶å‚æ•°å’ŒæŒ‡æ ‡
        combined_data = {}
        combined_data.update(exp.parameters)
        combined_data.update(exp.metrics)
        experiments.append(combined_data)
    return experiments

def fix_float_precision(params_list: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """ä¿®å¤æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜"""
    fixed_params_list = []
    for params in params_list:
        fixed_params = {}
        for key, value in params.items():
            if isinstance(value, float):
                # å¯¹äºæµ®ç‚¹æ•°ï¼Œè¿›è¡Œå››èˆäº”å…¥åˆ°åˆç†çš„å°æ•°ä½æ•°
                # å¦‚æœçœ‹èµ·æ¥åƒæ˜¯æ•´æ•°ï¼ˆå¦‚8.0ï¼‰ï¼Œåˆ™è½¬æ¢ä¸ºæ•´æ•°
                if abs(value - round(value)) < 1e-10:
                    fixed_params[key] = int(round(value))
                else:
                    # å¯¹äºå°æ•°ï¼Œè¿›è¡Œæ›´ç²¾ç¡®çš„å¤„ç†
                    # å°è¯•æ‰¾åˆ°æœ€æ¥è¿‘çš„"å¹²å‡€"çš„å°æ•°å€¼
                    rounded = round(value, 10)
                    # å¦‚æœå››èˆäº”å…¥åçš„å°æ•°ä½æ•°å¾ˆå°‘ï¼Œç›´æ¥ä½¿ç”¨
                    if len(str(rounded).split('.')[-1]) <= 2:
                        fixed_params[key] = rounded
                    else:
                        # å¦åˆ™å°è¯•æ‰¾åˆ°æœ€æ¥è¿‘çš„ç®€å•åˆ†æ•°
                        # ä¾‹å¦‚ 0.7999999999999999 -> 0.8
                        for precision in [1, 2, 3, 4, 5]:
                            test_value = round(value, precision)
                            if abs(value - test_value) < 1e-10:
                                fixed_params[key] = test_value
                                break
                        else:
                            # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œä½¿ç”¨åŸå§‹å€¼
                            fixed_params[key] = value
            else:
                fixed_params[key] = value
        fixed_params_list.append(fixed_params)
    return fixed_params_list







@app.get("/")
async def root():
    """APIæ ¹è·¯å¾„"""
    return {
        "message": "å‚æ•°ä¼˜åŒ–API v3.0",
        "version": "3.0.0",
        "features": {
            "prior_experiments": "æ”¯æŒå…ˆéªŒå®éªŒæ•°æ®",
            "sampling_methods": "æ”¯æŒsobol/lhs/uniformä¸‰ç§é‡‡æ ·æ–¹å¼",
            "smart_sampling": "æœ‰å…ˆéªŒæ•°æ®æ—¶é»˜è®¤sobolï¼Œæ— å…ˆéªŒæ•°æ®æ—¶å¯é€‰æ‹©é‡‡æ ·æ–¹å¼",
            "bayesian_optimization": "æ”¯æŒè´å¶æ–¯ä¼˜åŒ–ï¼ŒåŸºäºå†å²æ•°æ®æ¨èå‚æ•°",
            "custom_surrogate_models": "æ”¯æŒè‡ªå®šä¹‰ä»£ç†æ¨¡å‹ï¼Œå¦‚ SingleTaskGP, MultiTaskGP ç­‰",
            "custom_kernels": "æ”¯æŒè‡ªå®šä¹‰æ ¸å‡½æ•°ï¼Œå¦‚ MaternKernel, RBFKernel ç­‰",
            "custom_acquisition_functions": "æ”¯æŒè‡ªå®šä¹‰é‡‡é›†å‡½æ•°ï¼ŒåŒ…æ‹¬å•ç›®æ ‡å’Œå¤šç›®æ ‡é‡‡é›†å‡½æ•°",
            "experiment_analysis": "æ”¯æŒå®éªŒæ•°æ®åˆ†æï¼Œç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"
        },
        "endpoints": {
            "POST /init": "åˆå§‹åŒ–ä¼˜åŒ–ï¼Œæ”¯æŒä¼ ç»Ÿé‡‡æ ·",
            "POST /update": "è´å¶æ–¯ä¼˜åŒ–æ¥å£ï¼Œæ”¯æŒè‡ªå®šä¹‰ä»£ç†æ¨¡å‹ã€æ ¸å‡½æ•°å’Œé‡‡é›†å‡½æ•°",
            "POST /analysis": "å®éªŒæ•°æ®åˆ†ææ¥å£ï¼Œç”Ÿæˆå¹¶è¡Œåæ ‡å›¾ã€ç‰¹å¾é‡è¦æ€§å›¾ã€äº¤å‰éªŒè¯å›¾",
            "POST /analysis/slice": "ç”Ÿæˆå•ä¸ªåˆ‡ç‰‡å›¾ï¼Œç”¨æˆ·æŒ‡å®šå‚æ•°å’Œç›®æ ‡",
            "POST /analysis/contour": "ç”Ÿæˆå•ä¸ªç­‰é«˜çº¿å›¾ï¼Œç”¨æˆ·æŒ‡å®šå‚æ•°å¯¹å’Œç›®æ ‡",
            "GET /available_classes": "è·å–å¯ç”¨çš„ä»£ç†æ¨¡å‹ã€æ ¸å‡½æ•°å’Œé‡‡é›†å‡½æ•°åˆ—è¡¨"
        }
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {"status": "healthy", "service": "parameter_optimization_v3"}

@app.get("/chart/{file_id}", response_class=HTMLResponse)
async def view_chart(file_id: str):
    """æŸ¥çœ‹å›¾è¡¨ï¼ˆåœ¨æµè§ˆå™¨ä¸­æ¸²æŸ“ï¼‰"""
    # æ¯æ¬¡è¯·æ±‚æ—¶ä»æ–‡ä»¶é‡æ–°åŠ è½½ï¼Œç¡®ä¿å¤šè¿›ç¨‹ç¯å¢ƒä¸‹æ•°æ®ä¸€è‡´
    current_chart_files = {}
    if CHART_FILES_METADATA.exists():
        try:
            with open(CHART_FILES_METADATA, 'r', encoding='utf-8') as f:
                current_chart_files = json.load(f)
        except Exception as e:
            print(f"âš ï¸ è¯»å–å›¾è¡¨æ–‡ä»¶æ˜ å°„å¤±è´¥: {e}")
            raise HTTPException(status_code=500, detail=f"è¯»å–å›¾è¡¨æ˜ å°„å¤±è´¥: {str(e)}")
    
    if file_id not in current_chart_files:
        raise HTTPException(status_code=404, detail="å›¾è¡¨ä¸å­˜åœ¨")
    
    file_path = current_chart_files[file_id]["path"]
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="å›¾è¡¨æ–‡ä»¶å·²è¢«åˆ é™¤")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            html_content = f.read()
        response = HTMLResponse(content=html_content)
        response.headers["Access-Control-Allow-Origin"] = "*"  # å…è®¸æ‰€æœ‰åŸŸè®¿é—®
        response.headers["Access-Control-Allow-Methods"] = "GET"  # å…è®¸çš„HTTPæ–¹æ³•
        response.headers["Access-Control-Allow-Headers"] = "Content-Type"  # å…è®¸çš„è¯·æ±‚å¤´
        return response
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è¯»å–å›¾è¡¨æ–‡ä»¶å¤±è´¥: {str(e)}")

@app.get("/charts")
async def list_charts():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å›¾è¡¨æ–‡ä»¶"""
    try:
        # æ¯æ¬¡è¯·æ±‚æ—¶ä»æ–‡ä»¶é‡æ–°åŠ è½½ï¼Œç¡®ä¿å¤šè¿›ç¨‹ç¯å¢ƒä¸‹æ•°æ®ä¸€è‡´
        current_chart_files = {}
        if CHART_FILES_METADATA.exists():
            try:
                with open(CHART_FILES_METADATA, 'r', encoding='utf-8') as f:
                    current_chart_files = json.load(f)
            except Exception as e:
                print(f"âš ï¸ è¯»å–å›¾è¡¨æ–‡ä»¶æ˜ å°„å¤±è´¥: {e}")
                current_chart_files = {}
        
        charts_info = []
        for file_id, file_info in current_chart_files.items():
            chart_info = {
                "file_id": file_id,
                "filename": file_info.get("filename", "unknown"),
                "type": file_info.get("type", "unknown"),
                "created_at": file_info.get("created_at", "unknown"),
                "url": f"/chart/{file_id}",
                "exists": os.path.exists(file_info.get("path", ""))
            }
            charts_info.append(chart_info)
        
        # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        charts_info.sort(key=lambda x: x.get("created_at", ""), reverse=True)
        
        return {
            "success": True,
            "total_charts": len(charts_info),
            "charts": charts_info,
            "output_directory": str(PERSISTENT_OUTPUT_DIR)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å›¾è¡¨åˆ—è¡¨å¤±è´¥: {str(e)}")

@app.delete("/charts/{file_id}")
async def delete_chart(file_id: str):
    """åˆ é™¤æŒ‡å®šçš„å›¾è¡¨æ–‡ä»¶"""
    if file_id not in chart_files:
        raise HTTPException(status_code=404, detail="å›¾è¡¨ä¸å­˜åœ¨")
    
    try:
        file_info = chart_files[file_id]
        file_path = file_info["path"]
        
        # åˆ é™¤å®é™…æ–‡ä»¶
        if os.path.exists(file_path):
            os.unlink(file_path)
        
        # åˆ é™¤æ˜ å°„
        del chart_files[file_id]
        save_chart_files()
        
        return {
            "success": True,
            "message": f"æˆåŠŸåˆ é™¤å›¾è¡¨æ–‡ä»¶: {file_info.get('filename', 'unknown')}"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ é™¤å›¾è¡¨æ–‡ä»¶å¤±è´¥: {str(e)}")

@app.post("/charts/cleanup")
async def cleanup_charts(days: int = 30):
    """æ¸…ç†è¶…è¿‡æŒ‡å®šå¤©æ•°çš„è¿‡æœŸå›¾è¡¨æ–‡ä»¶"""
    try:
        cleanup_expired_files(days)
        return {
            "success": True,
            "message": f"æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº†è¶…è¿‡ {days} å¤©çš„è¿‡æœŸæ–‡ä»¶"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ¸…ç†æ–‡ä»¶å¤±è´¥: {str(e)}")




@app.post("/init", response_model=InitResponse)
async def initialize_optimization(request: InitRequest):
    """åˆå§‹åŒ–ä¼˜åŒ–ï¼Œæ”¯æŒå…ˆéªŒå®éªŒæ•°æ®"""
    try:
        # è½¬æ¢å‚æ•°ç©ºé—´æ ¼å¼
        search_space = convert_parameter_space_to_ax_format(request.parameter_space)
        
        # ç¡®å®šé‡‡æ ·æ–¹æ³•
        if request.prior_experiments:
            # æœ‰å…ˆéªŒæ•°æ®æ—¶ï¼Œå¼ºåˆ¶ä½¿ç”¨sobolé‡‡æ ·
            sampling_method = "sobol"
            
            # è½¬æ¢å…ˆéªŒå®éªŒæ•°æ®
            prior_experiments = convert_prior_experiments_to_dict(request.prior_experiments)
            
            # ä½¿ç”¨sobolé‡‡æ ·ï¼ˆå¸¦å…ˆéªŒæ•°æ®ï¼‰
            params_list = generate_sobol_parameters(
                search_space, 
                num_points=request.batch, 
                seed=request.seed,
                prior_experiments=prior_experiments
            )
        else:
            # æ²¡æœ‰å…ˆéªŒæ•°æ®æ—¶ï¼Œä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„é‡‡æ ·æ–¹æ³•
            sampling_method = request.sampling_method or "sobol"
            
            if sampling_method == "sobol":
                params_list = generate_sobol_parameters(search_space, num_points=request.batch, seed=request.seed)
            elif sampling_method == "lhs":
                params_list = generate_lhs_parameters(search_space, num_points=request.batch, seed=request.seed)
            elif sampling_method == "uniform":
                params_list = generate_uniform_parameters(search_space, num_points=request.batch, seed=request.seed)
            else:
                raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„é‡‡æ ·æ–¹æ³•: {sampling_method}")
        
        # æ£€æŸ¥ç”Ÿæˆçš„å‚æ•°åˆ—è¡¨
        if not params_list:
            raise HTTPException(status_code=500, detail="é‡‡æ ·å‡½æ•°æœªç”Ÿæˆä»»ä½•å‚æ•°ç»„åˆ")
        
        # ä¿®å¤æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜
        results = fix_float_precision(params_list)
        
        return InitResponse(
            success=True,
            sampling_method=sampling_method,
            results=results,
            message=f"åˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨{sampling_method}é‡‡æ ·ç”Ÿæˆ{len(results)}ä¸ªå‚æ•°ç»„åˆ"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆå§‹åŒ–å¤±è´¥: {str(e)}")

@app.post("/update", response_model=UpdateResponse)
async def update_optimization(request: UpdateRequest):
    """è´å¶æ–¯ä¼˜åŒ–æ¥å£ï¼šåŸºäºå†å²æ•°æ®æ¨èä¸‹ä¸€ç»„å‚æ•°"""
    try:
        # è½¬æ¢å‚æ•°ç©ºé—´æ ¼å¼
        search_space = convert_parameter_space_to_ax_format(request.parameter_space)
        
        # æ„å»ºä¼˜åŒ–é…ç½®
        optimization_config = {
            "objectives": request.objectives,
            "use_weights": request.use_weights or False,
            "objective_weights": request.objective_weights or {},
            "additional_metrics": request.additional_metrics or []
        }
        
        # åˆ›å»ºè´å¶æ–¯ä¼˜åŒ–å™¨
        optimizer = BayesianOptimizer(
            search_space=search_space,
            optimization_config=optimization_config,
            random_seed=request.seed,
            surrogate_model_class=request.surrogate_model_class,
            kernel_class=request.kernel_class,
            kernel_options=request.kernel_options,
            acquisition_function_class=request.acquisition_function_class,
            acquisition_function_options=request.acquisition_function_options
        )
        
        # æ·»åŠ å†å²å®éªŒæ•°æ®
        for exp in request.completed_experiments:
            experiment_result = ExperimentResult(
                parameters=exp.parameters,
                metrics=exp.metrics
            )
            optimizer.add_prior_experiments([experiment_result])
        
        # è·å–ä¸‹ä¸€ç»„æ¨èå‚æ•°
        next_trials = optimizer.get_next_parameters(n=request.batch)
        next_parameters = [params for params, _ in next_trials]
        
        # ä¿®å¤æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜
        next_parameters = fix_float_precision(next_parameters)
        
        # æ„å»ºå“åº”æ¶ˆæ¯
        message = f"æˆåŠŸæ¨è{len(next_parameters)}ä¸ªå‚æ•°ç»„åˆ"
        
        custom_components = []
        if request.surrogate_model_class:
            custom_components.append("ä»£ç†æ¨¡å‹:"+request.surrogate_model_class)
        if request.kernel_class:
            custom_components.append("æ ¸å‡½æ•°:"+request.kernel_class)
        if request.acquisition_function_class:
            custom_components.append("é‡‡é›†å‡½æ•°:"+request.acquisition_function_class)
        
        if custom_components:
            message += f"ï¼Œä½¿ç”¨{'+'.join(custom_components)}"
            
        parameter_info = []
        if request.kernel_options:
            parameter_info.append(f"æ ¸å‡½æ•°å‚æ•°: {request.kernel_options}")
        if request.acquisition_function_options:
            parameter_info.append(f"é‡‡é›†å‡½æ•°å‚æ•°: {request.acquisition_function_options}")     
        if parameter_info:
            message += f"ï¼Œ{', '.join(parameter_info)}"
        else:
            message += "ï¼Œä½¿ç”¨é»˜è®¤é…ç½®"
        
        return UpdateResponse(
            success=True,
            results=next_parameters,
            message=message
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¼˜åŒ–å¤±è´¥: {str(e)}")

def check_categorical_data(data: pd.DataFrame, parameters: List[str]) -> bool:
    """æ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦åŒ…å«ç±»åˆ«æ•°æ®"""
    for param in parameters:
        if param in data.columns:
            # æ£€æŸ¥æ˜¯å¦ä¸ºéæ•°å€¼ç±»å‹
            if not pd.api.types.is_numeric_dtype(data[param]):
                return True
            # æ£€æŸ¥æ•°å€¼ç±»å‹ä½†å”¯ä¸€å€¼æ•°é‡è¾ƒå°‘ï¼ˆå¯èƒ½æ˜¯ç¦»æ•£æ•°å€¼ï¼‰
            unique_count = data[param].nunique()
            if unique_count <= 10:  # å¦‚æœå”¯ä¸€å€¼æ•°é‡å°‘äºç­‰äº10ï¼Œè®¤ä¸ºæ˜¯ç±»åˆ«æ•°æ®
                return True
    return False



@app.post("/analysis", response_model=AnalysisResponse)
async def analyze_experiment_data(request: AnalysisRequest):
    """åˆ†æå®éªŒæ•°æ®ï¼Œç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
    try:
        # ä»è¯·æ±‚ä¸­æå–å‚æ•°å’Œç›®æ ‡
        param_list = [param.name for param in request.parameter_space]
        
        # å¤„ç†ä¸¤ç§æ ¼å¼çš„objectives
        if isinstance(request.objectives, list):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²åˆ—è¡¨æ ¼å¼
            objective_list = request.objectives
        else:
            # å¦‚æœæ˜¯å­—å…¸æ ¼å¼
            objective_list = list(request.objectives.keys())
        
        # è½¬æ¢å‚æ•°ç©ºé—´ä¸ºAxæ ¼å¼
        search_space_dict = convert_parameter_space_to_ax_format(request.parameter_space)
        
        # è·å–æ¨¡å‹ç±»
        surrogate_model_cls = None
        kernel_cls = None
        if request.surrogate_model_class:
            surrogate_model_cls = get_class_from_string(request.surrogate_model_class)
        if request.kernel_class:
            kernel_cls = get_class_from_string(request.kernel_class)
        
        # å°†å®éªŒæ•°æ®è½¬æ¢ä¸ºDataFrameæ ¼å¼ï¼ˆç”¨äºæ£€æŸ¥ç±»åˆ«æ•°æ®ï¼‰
        data_rows = []
        for exp in request.completed_experiments:
            row = {}
            # æ·»åŠ å‚æ•°
            for param_name, param_value in exp.parameters.items():
                row[param_name] = param_value
            # æ·»åŠ ç›®æ ‡
            for obj_name, obj_value in exp.metrics.items():
                row[obj_name] = obj_value
            data_rows.append(row)
        
        data = pd.DataFrame(data_rows)
        
        # æ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦åŒ…å«ç±»åˆ«æ•°æ®
        has_categorical = check_categorical_data(data, param_list)
        
        # åˆ›å»ºæŒä¹…åŒ–è¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = PERSISTENT_OUTPUT_DIR / f"analysis_{timestamp}"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # å°†å®éªŒæ•°æ®è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        completed_experiments_dict = []
        for exp in request.completed_experiments:
            exp_dict = {
                "parameters": exp.parameters,
                "metrics": exp.metrics
            }
            completed_experiments_dict.append(exp_dict)
        
        # åˆ›å»ºåˆ†æå™¨ï¼Œç›´æ¥ä½¿ç”¨JSONæ•°æ®
        analyzer = ParameterOptimizationAnalysis(
            completed_experiments=completed_experiments_dict,
            output_dir=output_dir
        )
        
        generated_plots = []
        view_links = []  # å­˜å‚¨æŸ¥çœ‹é“¾æ¥ä¿¡æ¯
        
        # ç”Ÿæˆå¹¶è¡Œåæ ‡å›¾
        print("ğŸ“Š ç”Ÿæˆå¹¶è¡Œåæ ‡å›¾...")
        parallel_plots = analyzer.create_parallel_coordinates_plots(
            parameters=param_list,
            objectives=objective_list
        )
        # ç«‹å³ä¿å­˜å¹¶è¡Œåæ ‡å›¾
        if "parallel_coords_combined" in analyzer.plots:
            saved_path = analyzer.save_single_plot("parallel_coords_combined", analyzer.plots["parallel_coords_combined"])
            
            # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶ID
            file_id = str(uuid.uuid4())
            filename = f"parallel_coords_combined.html"
            
            # å­˜å‚¨æ–‡ä»¶æ˜ å°„
            chart_files[file_id] = {
                "path": str(saved_path),
                "filename": filename,
                "type": "parallel_coordinates",
                "created_at": datetime.now().isoformat()
            }
            # ç«‹å³ä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨
            save_chart_files()
            
            # æ·»åŠ æŸ¥çœ‹é“¾æ¥
            view_links.append({
                "name": "parallel_coords_combined",
                "url": f"/chart/{file_id}",
                "type": "parallel_coordinates"
            })
            
        generated_plots.append("parallel_coords_combined")
        
        # ç”Ÿæˆç‰¹å¾é‡è¦æ€§å›¾
        print("ğŸ“Š ç”Ÿæˆç‰¹å¾é‡è¦æ€§å›¾...")
        shap_plots = analyzer.create_feature_importance_analysis(
            parameters=param_list,
            objectives=objective_list
        )
        # ç«‹å³ä¿å­˜ç‰¹å¾é‡è¦æ€§å›¾
        for obj in objective_list:
            plot_name = f"feature_importance_{obj}"
            if plot_name in analyzer.plots:
                saved_path = analyzer.save_single_plot(plot_name, analyzer.plots[plot_name])
                
                # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶ID
                file_id = str(uuid.uuid4())
                filename = f"{plot_name}.html"
                
                # å­˜å‚¨æ–‡ä»¶æ˜ å°„
                chart_files[file_id] = {
                    "path": str(saved_path),
                    "filename": filename,
                    "type": "feature_importance",
                    "created_at": datetime.now().isoformat()
                }
                # ç«‹å³ä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨
                save_chart_files()
                
                # æ·»åŠ æŸ¥çœ‹é“¾æ¥
                view_links.append({
                    "name": plot_name,
                    "url": f"/chart/{file_id}",
                    "type": "feature_importance"
                })
                
        generated_plots.extend([f"feature_importance_{obj}" for obj in objective_list])
        
        # ç”Ÿæˆäº¤å‰éªŒè¯å›¾
        print("ğŸ“Š ç”Ÿæˆäº¤å‰éªŒè¯å›¾...")
        cv_plots = analyzer.create_cross_validation_plots(
            parameters=param_list,
            objectives=objective_list,
            search_space=search_space_dict,
            untransform=True,
            surrogate_model_class=surrogate_model_cls,
            kernel_class=kernel_cls,
            kernel_options=request.kernel_options
        )
        # ç«‹å³ä¿å­˜äº¤å‰éªŒè¯å›¾
        for obj in objective_list:
            plot_name = f"cross_validation_{obj}"
            if plot_name in analyzer.plots:
                saved_path = analyzer.save_single_plot(plot_name, analyzer.plots[plot_name])
                
                # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶ID
                file_id = str(uuid.uuid4())
                filename = f"{plot_name}.html"
                
                # å­˜å‚¨æ–‡ä»¶æ˜ å°„
                chart_files[file_id] = {
                    "path": str(saved_path),
                    "filename": filename,
                    "type": "cross_validation",
                    "created_at": datetime.now().isoformat()
                }
                # ç«‹å³ä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨
                save_chart_files()
                
                # æ·»åŠ æŸ¥çœ‹é“¾æ¥
                view_links.append({
                    "name": plot_name,
                    "url": f"/chart/{file_id}",
                    "type": "cross_validation"
                })
                
        generated_plots.extend([f"cross_validation_{obj}" for obj in objective_list])
        
        # æ³¨æ„ï¼šsliceå›¾å’Œcontourå›¾å·²ç§»è‡³å•ç‹¬çš„æ¥å£
        # ä½¿ç”¨ /analysis/slice æ¥å£ç”Ÿæˆå•ä¸ªåˆ‡ç‰‡å›¾
        # ä½¿ç”¨ /analysis/contour æ¥å£ç”Ÿæˆå•ä¸ªç­‰é«˜çº¿å›¾
        
        # æ„å»ºå“åº”æ¶ˆæ¯
        plot_count = len(generated_plots)
        message = f"ç”Ÿæˆäº†3ç§ç±»å‹å…±{plot_count}ä¸ªå›¾è¡¨ï¼šå¹¶è¡Œåæ ‡å›¾ï¼ˆ1ä¸ªï¼‰ã€ç‰¹å¾é‡è¦æ€§å›¾ï¼ˆ{len(objective_list)}ä¸ªï¼‰ã€äº¤å‰éªŒè¯å›¾ï¼ˆ{len(objective_list)}ä¸ªï¼‰"
        
        if request.surrogate_model_class or request.kernel_class:
            custom_components = []
            if request.surrogate_model_class:
                custom_components.append(f"ä»£ç†æ¨¡å‹:{request.surrogate_model_class}")
            if request.kernel_class:
                custom_components.append(f"æ ¸å‡½æ•°:{request.kernel_class}")
            message += f"ï¼Œä½¿ç”¨{'+'.join(custom_components)}"
        
        return AnalysisResponse(
            success=True,
            message=message,
            generated_plots=generated_plots,
            output_directory=str(output_dir),
            has_categorical_data=has_categorical,
            view_links=view_links
        )
                
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±è´¥: {str(e)}")

@app.post("/analysis/slice", response_model=SinglePlotResponse)
async def analyze_slice_plot(request: SliceAnalysisRequest):
    """ç”Ÿæˆå•ä¸ªåˆ‡ç‰‡å›¾"""
    try:
        # è½¬æ¢å‚æ•°ç©ºé—´ä¸ºAxæ ¼å¼ï¼ˆåˆ†ææ¥å£å¿½ç•¥stepå‚æ•°ï¼‰
        search_space_dict = convert_parameter_space_to_ax_format_for_analysis(request.parameter_space)
        
        # è·å–æ¨¡å‹ç±»
        surrogate_model_cls = None
        kernel_cls = None
        if request.surrogate_model_class:
            surrogate_model_cls = get_class_from_string(request.surrogate_model_class)
        if request.kernel_class:
            kernel_cls = get_class_from_string(request.kernel_class)
        
        # åˆ›å»ºæŒä¹…åŒ–è¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = PERSISTENT_OUTPUT_DIR / f"slice_{timestamp}"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # å°†å®éªŒæ•°æ®è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        completed_experiments_dict = []
        for exp in request.completed_experiments:
            exp_dict = {
                "parameters": exp.parameters,
                "metrics": exp.metrics
            }
            completed_experiments_dict.append(exp_dict)
        
        # åˆ›å»ºåˆ†æå™¨ï¼Œç›´æ¥ä½¿ç”¨JSONæ•°æ®
        analyzer = ParameterOptimizationAnalysis(
            completed_experiments=completed_experiments_dict,
            output_dir=output_dir
        )
        
        # ç”Ÿæˆå•ä¸ªåˆ‡ç‰‡å›¾
        print(f"ğŸ“Š ç”Ÿæˆåˆ‡ç‰‡å›¾: {request.parameter} vs {request.objective}")
        # ä¼ å…¥å®Œæ•´çš„å‚æ•°åˆ—è¡¨æ„å»ºä¼˜åŒ–å™¨ï¼Œä½†åªç”Ÿæˆç”¨æˆ·æŒ‡å®šå‚æ•°çš„åˆ‡ç‰‡å›¾
        all_parameters = [param["name"] for param in search_space_dict]
        slice_plots = analyzer.create_slice_plots(
            parameters=all_parameters,  # ä¼ å…¥æ‰€æœ‰å‚æ•°ï¼Œç¡®ä¿ä¼˜åŒ–å™¨æœ‰å®Œæ•´æ•°æ®
            objectives=[request.objective],
            search_space=search_space_dict,
            surrogate_model_class=surrogate_model_cls,
            kernel_class=kernel_cls,
            kernel_options=request.kernel_options,
            target_parameters=[request.parameter],  # åªç”Ÿæˆç”¨æˆ·æŒ‡å®šå‚æ•°çš„åˆ‡ç‰‡å›¾
            target_objectives=[request.objective]   # åªç”Ÿæˆç”¨æˆ·æŒ‡å®šç›®æ ‡çš„åˆ‡ç‰‡å›¾
        )
        
        # ä½¿ç”¨JSONæ•°ç»„æ ¼å¼å‘½åï¼šslice_["ç›®æ ‡","å‚æ•°"]
        plot_name = f'slice_["{request.objective}","{request.parameter}"]'
        # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†ç”¨æˆ·æŒ‡å®šçš„åˆ‡ç‰‡å›¾
        if plot_name in analyzer.plots:
            # ä¿å­˜å›¾è¡¨å¹¶è·å–å®é™…ä¿å­˜è·¯å¾„
            # æ³¨ï¼šanalysis.pyå†…éƒ¨å·²ä¿å­˜ä¸€æ¬¡ï¼Œè¿™é‡Œå†æ¬¡ä¿å­˜ä»¥ç¡®ä¿è·å¾—å‡†ç¡®çš„æ–‡ä»¶è·¯å¾„
            saved_path = analyzer.save_single_plot(plot_name, analyzer.plots[plot_name])
            
            # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶ID
            file_id = str(uuid.uuid4())
            filename = f"{plot_name}.html"
            
            # å­˜å‚¨æ–‡ä»¶æ˜ å°„
            chart_files[file_id] = {
                "path": str(saved_path),
                "filename": filename,
                "type": "slice",
                "created_at": datetime.now().isoformat()
            }
            # ç«‹å³ä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨
            save_chart_files()
            
            # æ„å»ºæŸ¥çœ‹é“¾æ¥
            view_link = {
                "name": plot_name,
                "url": f"/chart/{file_id}",
                "type": "slice"
            }
            
            # æ„å»ºå“åº”æ¶ˆæ¯
            message = f"æˆåŠŸç”Ÿæˆåˆ‡ç‰‡å›¾: {request.parameter} vs {request.objective}"
            if request.surrogate_model_class or request.kernel_class:
                custom_components = []
                if request.surrogate_model_class:
                    custom_components.append(f"ä»£ç†æ¨¡å‹:{request.surrogate_model_class}")
                if request.kernel_class:
                    custom_components.append(f"æ ¸å‡½æ•°:{request.kernel_class}")
                message += f"ï¼Œä½¿ç”¨{'+'.join(custom_components)}"
            
            return SinglePlotResponse(
                success=True,
                message=message,
                plot_name=plot_name,
                view_link=view_link
            )
        else:
            return SinglePlotResponse(
                success=False,
                message=f"æœªèƒ½ç”ŸæˆæŒ‡å®šçš„åˆ‡ç‰‡å›¾: {request.parameter} vs {request.objective}",
                plot_name="",
                view_link={}
            )
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ‡ç‰‡å›¾åˆ†æå¤±è´¥: {str(e)}")

@app.post("/analysis/contour", response_model=SinglePlotResponse)
async def analyze_contour_plot(request: ContourAnalysisRequest):
    """ç”Ÿæˆå•ä¸ªç­‰é«˜çº¿å›¾"""
    try:
        # éªŒè¯å‚æ•°
        if request.parameter1 == request.parameter2:
            raise HTTPException(status_code=400, detail="ä¸¤ä¸ªå‚æ•°ä¸èƒ½ç›¸åŒ")
        
        # è½¬æ¢å‚æ•°ç©ºé—´ä¸ºAxæ ¼å¼ï¼ˆåˆ†ææ¥å£å¿½ç•¥stepå‚æ•°ï¼‰
        search_space_dict = convert_parameter_space_to_ax_format_for_analysis(request.parameter_space)
        
        # è·å–æ¨¡å‹ç±»
        surrogate_model_cls = None
        kernel_cls = None
        if request.surrogate_model_class:
            surrogate_model_cls = get_class_from_string(request.surrogate_model_class)
        if request.kernel_class:
            kernel_cls = get_class_from_string(request.kernel_class)
        
        # åˆ›å»ºæŒä¹…åŒ–è¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = PERSISTENT_OUTPUT_DIR / f"contour_{timestamp}"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # å°†å®éªŒæ•°æ®è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        completed_experiments_dict = []
        for exp in request.completed_experiments:
            exp_dict = {
                "parameters": exp.parameters,
                "metrics": exp.metrics
            }
            completed_experiments_dict.append(exp_dict)
        
        # åˆ›å»ºåˆ†æå™¨ï¼Œç›´æ¥ä½¿ç”¨JSONæ•°æ®
        analyzer = ParameterOptimizationAnalysis(
            completed_experiments=completed_experiments_dict,
            output_dir=output_dir
        )
        
        # ç”Ÿæˆå•ä¸ªç­‰é«˜çº¿å›¾
        print(f"ğŸ“Š ç”Ÿæˆç­‰é«˜çº¿å›¾: {request.parameter1} vs {request.parameter2} for {request.objective}")
        # ä¼ å…¥å®Œæ•´çš„å‚æ•°åˆ—è¡¨æ„å»ºä¼˜åŒ–å™¨ï¼Œä½†åªç”Ÿæˆç”¨æˆ·æŒ‡å®šå‚æ•°å¯¹çš„ç­‰é«˜çº¿å›¾
        all_parameters = [param["name"] for param in search_space_dict]
        contour_plots = analyzer.create_contour_plots(
            parameters=all_parameters,  # ä¼ å…¥æ‰€æœ‰å‚æ•°ï¼Œç¡®ä¿ä¼˜åŒ–å™¨æœ‰å®Œæ•´æ•°æ®
            objectives=[request.objective],
            search_space=search_space_dict,
            surrogate_model_class=surrogate_model_cls,
            kernel_class=kernel_cls,
            kernel_options=request.kernel_options,
            target_parameter_pairs=[(request.parameter1, request.parameter2)],  # åªç”Ÿæˆç”¨æˆ·æŒ‡å®šå‚æ•°å¯¹çš„ç­‰é«˜çº¿å›¾
            target_objectives=[request.objective]  # åªç”Ÿæˆç”¨æˆ·æŒ‡å®šç›®æ ‡çš„ç­‰é«˜çº¿å›¾
        )
        
        # ä½¿ç”¨JSONæ•°ç»„æ ¼å¼å‘½åï¼šcontour_["ç›®æ ‡","å‚æ•°1","å‚æ•°2"]
        plot_name = f'contour_["{request.objective}","{request.parameter1}","{request.parameter2}"]'
        # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†ç”¨æˆ·æŒ‡å®šçš„ç­‰é«˜çº¿å›¾
        if plot_name in analyzer.plots:
            # ä¿å­˜å›¾è¡¨å¹¶è·å–å®é™…ä¿å­˜è·¯å¾„
            # æ³¨ï¼šanalysis.pyå†…éƒ¨å·²ä¿å­˜ä¸€æ¬¡ï¼Œè¿™é‡Œå†æ¬¡ä¿å­˜ä»¥ç¡®ä¿è·å¾—å‡†ç¡®çš„æ–‡ä»¶è·¯å¾„
            saved_path = analyzer.save_single_plot(plot_name, analyzer.plots[plot_name])
            
            # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶ID
            file_id = str(uuid.uuid4())
            filename = f"{plot_name}.html"
            
            # å­˜å‚¨æ–‡ä»¶æ˜ å°„
            chart_files[file_id] = {
                "path": str(saved_path),
                "filename": filename,
                "type": "contour",
                "created_at": datetime.now().isoformat()
            }
            # ç«‹å³ä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨
            save_chart_files()
            
            # æ„å»ºæŸ¥çœ‹é“¾æ¥
            view_link = {
                "name": plot_name,
                "url": f"/chart/{file_id}",
                "type": "contour"
            }
            
            # æ„å»ºå“åº”æ¶ˆæ¯
            message = f"æˆåŠŸç”Ÿæˆç­‰é«˜çº¿å›¾: {request.parameter1} vs {request.parameter2} for {request.objective}"
            if request.surrogate_model_class or request.kernel_class:
                custom_components = []
                if request.surrogate_model_class:
                    custom_components.append(f"ä»£ç†æ¨¡å‹:{request.surrogate_model_class}")
                if request.kernel_class:
                    custom_components.append(f"æ ¸å‡½æ•°:{request.kernel_class}")
                message += f"ï¼Œä½¿ç”¨{'+'.join(custom_components)}"
            
            return SinglePlotResponse(
                success=True,
                message=message,
                plot_name=plot_name,
                view_link=view_link
            )
        else:
            return SinglePlotResponse(
                success=False,
                message=f"æœªèƒ½ç”ŸæˆæŒ‡å®šçš„ç­‰é«˜çº¿å›¾: {request.parameter1} vs {request.parameter2} for {request.objective}",
                plot_name="",
                view_link={}
            )
            
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"âŒ ç­‰é«˜çº¿å›¾åˆ†æå¤±è´¥è¯¦ç»†é”™è¯¯:\n{error_details}")
        raise HTTPException(status_code=500, detail=f"ç­‰é«˜çº¿å›¾åˆ†æå¤±è´¥: {str(e)}")

if __name__ == "__main__":
    # å•è¿›ç¨‹å¯åŠ¨ï¼ˆç”¨äºå¼€å‘æµ‹è¯•ï¼‰
    # ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨å‘½ä»¤è¡Œå¯åŠ¨å¤šè¿›ç¨‹ï¼šuvicorn api_parameter_optimizer_v3:app --host 0.0.0.0 --port 3320 --workers 4
    print("ğŸš€ å¯åŠ¨APIæœåŠ¡ï¼ˆå•è¿›ç¨‹æ¨¡å¼ï¼‰")
    print("ğŸ’¡ æç¤ºï¼šç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨å¤šè¿›ç¨‹ï¼š")
    print("   uvicorn api_parameter_optimizer_v3:app --host 0.0.0.0 --port 3320 --workers 4")
    uvicorn.run(app, host="0.0.0.0", port=3320)
