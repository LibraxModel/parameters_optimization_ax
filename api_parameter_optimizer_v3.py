from fastapi import FastAPI, HTTPException, UploadFile, File
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional, Union, Literal
import uvicorn
import pandas as pd
import tempfile
import os
import json
from doe_init import generate_sobol_parameters, generate_lhs_parameters, generate_uniform_parameters
from ax_optimizer import BayesianOptimizer, ExperimentResult
from analysis import ParameterOptimizationAnalysis
from __init__ import get_class_from_string

app = FastAPI(
    title="å‚æ•°ä¼˜åŒ–API v3",
    description="æ”¯æŒå…ˆéªŒå®éªŒæ•°æ®çš„å‚æ•°ä¼˜åŒ–APIï¼Œé»˜è®¤sobolé‡‡æ ·ï¼Œæ”¯æŒå¤šç§é‡‡æ ·æ–¹å¼ï¼Œæ–°å¢è´å¶æ–¯ä¼˜åŒ–æ”¯æŒ",
    version="3.0.0"
)



# å®šä¹‰å‚æ•°ç©ºé—´æ¨¡å‹
class ParameterSpace(BaseModel):
    name: str = Field(..., description="å‚æ•°åç§°")
    type: Literal["choice", "range"] = Field(..., description="å‚æ•°ç±»å‹ï¼šchoiceï¼ˆç¦»æ•£é€‰æ‹©ï¼‰æˆ–rangeï¼ˆè¿ç»­èŒƒå›´ï¼‰")
    values: Union[List[Union[str, int, float]], List[float]] = Field(..., description="å½“typeä¸ºchoiceæ—¶è¡¨ç¤ºå¯é€‰å€¼åˆ—è¡¨ï¼Œå½“typeä¸ºrangeæ—¶è¡¨ç¤º[æœ€å°å€¼, æœ€å¤§å€¼]")
    step: Optional[Union[int, float]] = Field(None, description="æ­¥é•¿ï¼Œç”¨äºå°†rangeå‚æ•°è½¬æ¢ä¸ºchoiceå‚æ•°")

# å®šä¹‰å…ˆéªŒå®éªŒæ•°æ®æ¨¡å‹
class PriorExperiment(BaseModel):
    parameters: Dict[str, Union[str, int, float]] = Field(..., description="å‚æ•°ç»„åˆ")
    metrics: Dict[str, Union[int, float]] = Field(..., description="å®éªŒç»“æœæŒ‡æ ‡")

# å®šä¹‰åˆå§‹åŒ–è¯·æ±‚æ¨¡å‹
class InitRequest(BaseModel):
    parameter_space: List[ParameterSpace] = Field(..., description="å‚æ•°ç©ºé—´å®šä¹‰")
    objectives: List[str] = Field(..., description="ä¼˜åŒ–ç›®æ ‡åˆ—è¡¨")
    batch: int = Field(..., description="æ¯æ‰¹æ¬¡å‚æ•°æ•°é‡", ge=1, le=20)
    seed: Optional[int] = Field(None, description="éšæœºç§å­")
    prior_experiments: Optional[List[PriorExperiment]] = Field(None, description="å…ˆéªŒå®éªŒæ•°æ®")
    sampling_method: Optional[Literal["sobol", "lhs", "uniform"]] = Field("sobol", description="é‡‡æ ·æ–¹æ³•ï¼ˆä»…åœ¨æ²¡æœ‰å…ˆéªŒæ•°æ®æ—¶ç”Ÿæ•ˆï¼‰")

# å®šä¹‰å“åº”æ¨¡å‹
class InitResponse(BaseModel):
    success: bool
    sampling_method: str
    results: List[Dict[str, Any]]
    message: str

# å®šä¹‰æ›´æ–°è¯·æ±‚æ¨¡å‹
class UpdateRequest(BaseModel):
    parameter_space: List[ParameterSpace] = Field(..., description="å‚æ•°ç©ºé—´å®šä¹‰")
    objectives: Dict[str, Dict[str, bool]] = Field(..., description="ä¼˜åŒ–ç›®æ ‡é…ç½®ï¼Œæ ¼å¼ä¸º{'metric_name': {'minimize': bool}}")
    completed_experiments: List[PriorExperiment] = Field(..., description="å·²å®Œæˆçš„å®éªŒç»“æœ")
    batch: int = Field(1, description="ä¸‹ä¸€æ‰¹æ¬¡å‚æ•°æ•°é‡", ge=1, le=10)
    use_weights: Optional[bool] = Field(False, description="æ˜¯å¦ä½¿ç”¨æƒé‡ä¼˜åŒ–")
    objective_weights: Optional[Dict[str, float]] = Field(None, description="ç›®æ ‡æƒé‡")
    additional_metrics: Optional[List[str]] = Field(None, description="é¢å¤–è·Ÿè¸ªæŒ‡æ ‡")
    seed: Optional[int] = Field(None, description="éšæœºç§å­")
    # æ–°å¢è‡ªå®šä¹‰æ¨¡å‹é…ç½®
    surrogate_model_class: Optional[str] = Field(None, description="ä»£ç†æ¨¡å‹ç±»åï¼Œå¦‚ 'SingleTaskGP', 'MultiTaskGP' ç­‰")
    kernel_class: Optional[str] = Field(None, description="æ ¸å‡½æ•°ç±»åï¼Œå¦‚ 'MaternKernel', 'RBFKernel' ç­‰")
    kernel_options: Optional[Dict[str, Any]] = Field(None, description="æ ¸å‡½æ•°å‚æ•°ï¼Œå¦‚ {'nu': 2.5} for MaternKernel")
    # æ–°å¢é‡‡é›†å‡½æ•°é…ç½®
    acquisition_function_class: Optional[str] = Field(None, description="é‡‡é›†å‡½æ•°ç±»å")
    acquisition_function_options: Optional[Dict[str, Any]] = Field(None, description="é‡‡é›†å‡½æ•°å‚æ•°ï¼Œå¦‚ {'beta': 0.1} for UCB")

# å®šä¹‰æ›´æ–°å“åº”æ¨¡å‹
class UpdateResponse(BaseModel):
    success: bool
    next_parameters: List[Dict[str, Any]]
    message: str

# å®šä¹‰åˆ†æè¯·æ±‚æ¨¡å‹
class AnalysisRequest(BaseModel):
    parameters: List[str] = Field(..., description="å‚æ•°åˆ—ååˆ—è¡¨")
    objectives: List[str] = Field(..., description="ç›®æ ‡åˆ—ååˆ—è¡¨")
    search_space: List[Dict[str, Any]] = Field(..., description="å‚æ•°ç©ºé—´é…ç½®")
    # å¯é€‰çš„è‡ªå®šä¹‰ä»£ç†æ¨¡å‹é…ç½®
    surrogate_model_class: Optional[str] = Field(None, description="ä»£ç†æ¨¡å‹ç±»åï¼Œå¦‚ 'SingleTaskGP', 'MultiTaskGP' ç­‰")
    kernel_class: Optional[str] = Field(None, description="æ ¸å‡½æ•°ç±»åï¼Œå¦‚ 'MaternKernel', 'RBFKernel' ç­‰")
    kernel_options: Optional[Dict[str, Any]] = Field(None, description="æ ¸å‡½æ•°å‚æ•°ï¼Œå¦‚ {'nu': 2.5} for MaternKernel")

# å®šä¹‰åˆ†æå“åº”æ¨¡å‹
class AnalysisResponse(BaseModel):
    success: bool
    message: str
    generated_plots: List[str] = Field(..., description="ç”Ÿæˆçš„å›¾è¡¨åˆ—è¡¨")
    output_directory: str = Field(..., description="è¾“å‡ºç›®å½•è·¯å¾„")
    has_categorical_data: bool = Field(..., description="æ˜¯å¦åŒ…å«ç±»åˆ«æ•°æ®")

def convert_parameter_space_to_ax_format(parameter_space: List[ParameterSpace]) -> List[Dict[str, Any]]:
    """å°†å‚æ•°ç©ºé—´è½¬æ¢ä¸ºAxæ ¼å¼"""
    search_space = []
    for param in parameter_space:
        if param.type == "choice":
            # ç¡®å®švalue_typeï¼šå­—ç¬¦ä¸²ã€æµ®ç‚¹æ•°ã€æ•´æ•°
            if all(isinstance(x, str) for x in param.values):
                value_type = "str"
            elif any(isinstance(x, float) for x in param.values):
                value_type = "float"
            else:
                value_type = "int"
            
            # å¯¹äºæµ®ç‚¹æ•°choiceå‚æ•°ï¼Œç¡®ä¿å€¼éƒ½æ˜¯æµ®ç‚¹æ•°ç±»å‹
            if value_type == "float":
                values = [float(v) for v in param.values]
            else:
                values = param.values
            
            search_space.append({
                "name": param.name,
                "type": "choice",
                "values": values,
                "value_type": value_type,
                "is_ordered": True,
                "sort_values": True
            })
        else:  # rangeç±»å‹
            if len(param.values) != 2:
                raise ValueError(f"å‚æ•° {param.name} çš„rangeç±»å‹å¿…é¡»æä¾›[æœ€å°å€¼, æœ€å¤§å€¼]")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰stepå‚æ•°ï¼Œå¦‚æœæœ‰åˆ™è½¬æ¢ä¸ºchoice
            if param.step is not None:
                min_val, max_val = param.values
                step = param.step
                
                # ç”Ÿæˆæ­¥é•¿åºåˆ—
                values = []
                current_val = min_val
                while current_val <= max_val:
                    values.append(current_val)
                    current_val += step
                
                # ç¡®ä¿ä¸è¶…è¿‡æœ€å¤§å€¼
                if values and values[-1] > max_val:
                    values[-1] = max_val
                
                # ç¡®å®švalue_type
                if any(isinstance(x, float) for x in [min_val, max_val, step]) or any(isinstance(x, float) for x in values):
                    value_type = "float"
                    values = [float(v) for v in values]
                else:
                    value_type = "int"
                    values = [int(v) for v in values]
                
                search_space.append({
                    "name": param.name,
                    "type": "choice",
                    "values": values,
                    "value_type": value_type,
                    "is_ordered": True,
                    "sort_values": True
                })
            else:
                # æ²¡æœ‰stepå‚æ•°ï¼Œä¿æŒä¸ºrangeç±»å‹
                search_space.append({
                    "name": param.name,
                    "type": "range",
                    "bounds": param.values,
                    "value_type": "float" if any(isinstance(x, float) for x in param.values) else "int"
                })
    return search_space

def convert_prior_experiments_to_dict(prior_experiments: List[PriorExperiment]) -> List[Dict[str, Any]]:
    """å°†å…ˆéªŒå®éªŒæ•°æ®è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
    experiments = []
    for exp in prior_experiments:
        # åˆå¹¶å‚æ•°å’ŒæŒ‡æ ‡
        combined_data = {}
        combined_data.update(exp.parameters)
        combined_data.update(exp.metrics)
        experiments.append(combined_data)
    return experiments

def fix_float_precision(params_list: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """ä¿®å¤æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜"""
    fixed_params_list = []
    for params in params_list:
        fixed_params = {}
        for key, value in params.items():
            if isinstance(value, float):
                # å¯¹äºæµ®ç‚¹æ•°ï¼Œè¿›è¡Œå››èˆäº”å…¥åˆ°åˆç†çš„å°æ•°ä½æ•°
                # å¦‚æœçœ‹èµ·æ¥åƒæ˜¯æ•´æ•°ï¼ˆå¦‚8.0ï¼‰ï¼Œåˆ™è½¬æ¢ä¸ºæ•´æ•°
                if abs(value - round(value)) < 1e-10:
                    fixed_params[key] = int(round(value))
                else:
                    # å¯¹äºå°æ•°ï¼Œè¿›è¡Œæ›´ç²¾ç¡®çš„å¤„ç†
                    # å°è¯•æ‰¾åˆ°æœ€æ¥è¿‘çš„"å¹²å‡€"çš„å°æ•°å€¼
                    rounded = round(value, 10)
                    # å¦‚æœå››èˆäº”å…¥åçš„å°æ•°ä½æ•°å¾ˆå°‘ï¼Œç›´æ¥ä½¿ç”¨
                    if len(str(rounded).split('.')[-1]) <= 2:
                        fixed_params[key] = rounded
                    else:
                        # å¦åˆ™å°è¯•æ‰¾åˆ°æœ€æ¥è¿‘çš„ç®€å•åˆ†æ•°
                        # ä¾‹å¦‚ 0.7999999999999999 -> 0.8
                        for precision in [1, 2, 3, 4, 5]:
                            test_value = round(value, precision)
                            if abs(value - test_value) < 1e-10:
                                fixed_params[key] = test_value
                                break
                        else:
                            # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œä½¿ç”¨åŸå§‹å€¼
                            fixed_params[key] = value
            else:
                fixed_params[key] = value
        fixed_params_list.append(fixed_params)
    return fixed_params_list







@app.get("/")
async def root():
    """APIæ ¹è·¯å¾„"""
    return {
        "message": "å‚æ•°ä¼˜åŒ–API v3.0",
        "version": "3.0.0",
        "features": {
            "prior_experiments": "æ”¯æŒå…ˆéªŒå®éªŒæ•°æ®",
            "sampling_methods": "æ”¯æŒsobol/lhs/uniformä¸‰ç§é‡‡æ ·æ–¹å¼",
            "smart_sampling": "æœ‰å…ˆéªŒæ•°æ®æ—¶é»˜è®¤sobolï¼Œæ— å…ˆéªŒæ•°æ®æ—¶å¯é€‰æ‹©é‡‡æ ·æ–¹å¼",
            "bayesian_optimization": "æ”¯æŒè´å¶æ–¯ä¼˜åŒ–ï¼ŒåŸºäºå†å²æ•°æ®æ¨èå‚æ•°",
            "custom_surrogate_models": "æ”¯æŒè‡ªå®šä¹‰ä»£ç†æ¨¡å‹ï¼Œå¦‚ SingleTaskGP, MultiTaskGP ç­‰",
            "custom_kernels": "æ”¯æŒè‡ªå®šä¹‰æ ¸å‡½æ•°ï¼Œå¦‚ MaternKernel, RBFKernel ç­‰",
            "custom_acquisition_functions": "æ”¯æŒè‡ªå®šä¹‰é‡‡é›†å‡½æ•°ï¼ŒåŒ…æ‹¬å•ç›®æ ‡å’Œå¤šç›®æ ‡é‡‡é›†å‡½æ•°",
            "experiment_analysis": "æ”¯æŒå®éªŒæ•°æ®åˆ†æï¼Œç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"
        },
        "endpoints": {
            "POST /init": "åˆå§‹åŒ–ä¼˜åŒ–ï¼Œæ”¯æŒä¼ ç»Ÿé‡‡æ ·",
            "POST /update": "è´å¶æ–¯ä¼˜åŒ–æ¥å£ï¼Œæ”¯æŒè‡ªå®šä¹‰ä»£ç†æ¨¡å‹ã€æ ¸å‡½æ•°å’Œé‡‡é›†å‡½æ•°",
            "POST /analysis": "å®éªŒæ•°æ®åˆ†ææ¥å£ï¼Œç”Ÿæˆå¯è§†åŒ–å›¾è¡¨",
            "GET /available_classes": "è·å–å¯ç”¨çš„ä»£ç†æ¨¡å‹ã€æ ¸å‡½æ•°å’Œé‡‡é›†å‡½æ•°åˆ—è¡¨"
        }
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {"status": "healthy", "service": "parameter_optimization_v3"}

@app.get("/available_classes")
async def get_available_classes():
    """è·å–å¯ç”¨çš„ç±»åˆ—è¡¨"""
    try:
        import sys
        import os
        sys.path.append(os.path.dirname(__file__))
        from __init__ import get_available_classes, get_class_parameters
        return {
            "categories": get_available_classes(),
            "parameters": get_class_parameters()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å¯ç”¨ç±»åˆ—è¡¨å¤±è´¥: {str(e)}")



@app.post("/init", response_model=InitResponse)
async def initialize_optimization(request: InitRequest):
    """åˆå§‹åŒ–ä¼˜åŒ–ï¼Œæ”¯æŒå…ˆéªŒå®éªŒæ•°æ®"""
    try:
        # è½¬æ¢å‚æ•°ç©ºé—´æ ¼å¼
        search_space = convert_parameter_space_to_ax_format(request.parameter_space)
        
        # ç¡®å®šé‡‡æ ·æ–¹æ³•
        if request.prior_experiments:
            # æœ‰å…ˆéªŒæ•°æ®æ—¶ï¼Œå¼ºåˆ¶ä½¿ç”¨sobolé‡‡æ ·
            sampling_method = "sobol"
            
            # è½¬æ¢å…ˆéªŒå®éªŒæ•°æ®
            prior_experiments = convert_prior_experiments_to_dict(request.prior_experiments)
            
            # ä½¿ç”¨sobolé‡‡æ ·ï¼ˆå¸¦å…ˆéªŒæ•°æ®ï¼‰
            params_list = generate_sobol_parameters(
                search_space, 
                num_points=request.batch, 
                seed=request.seed,
                prior_experiments=prior_experiments
            )
        else:
            # æ²¡æœ‰å…ˆéªŒæ•°æ®æ—¶ï¼Œä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„é‡‡æ ·æ–¹æ³•
            sampling_method = request.sampling_method or "sobol"
            
            if sampling_method == "sobol":
                params_list = generate_sobol_parameters(search_space, num_points=request.batch, seed=request.seed)
            elif sampling_method == "lhs":
                params_list = generate_lhs_parameters(search_space, num_points=request.batch, seed=request.seed)
            elif sampling_method == "uniform":
                params_list = generate_uniform_parameters(search_space, num_points=request.batch, seed=request.seed)
            else:
                raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„é‡‡æ ·æ–¹æ³•: {sampling_method}")
        
        # æ£€æŸ¥ç”Ÿæˆçš„å‚æ•°åˆ—è¡¨
        if not params_list:
            raise HTTPException(status_code=500, detail="é‡‡æ ·å‡½æ•°æœªç”Ÿæˆä»»ä½•å‚æ•°ç»„åˆ")
        
        # ä¿®å¤æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜
        results = fix_float_precision(params_list)
        
        return InitResponse(
            success=True,
            sampling_method=sampling_method,
            results=results,
            message=f"åˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨{sampling_method}é‡‡æ ·ç”Ÿæˆ{len(results)}ä¸ªå‚æ•°ç»„åˆ"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆå§‹åŒ–å¤±è´¥: {str(e)}")

@app.post("/update", response_model=UpdateResponse)
async def update_optimization(request: UpdateRequest):
    """è´å¶æ–¯ä¼˜åŒ–æ¥å£ï¼šåŸºäºå†å²æ•°æ®æ¨èä¸‹ä¸€ç»„å‚æ•°"""
    try:
        # è½¬æ¢å‚æ•°ç©ºé—´æ ¼å¼
        search_space = convert_parameter_space_to_ax_format(request.parameter_space)
        
        # æ„å»ºä¼˜åŒ–é…ç½®
        optimization_config = {
            "objectives": request.objectives,
            "use_weights": request.use_weights or False,
            "objective_weights": request.objective_weights or {},
            "additional_metrics": request.additional_metrics or []
        }
        
        # åˆ›å»ºè´å¶æ–¯ä¼˜åŒ–å™¨
        optimizer = BayesianOptimizer(
            search_space=search_space,
            optimization_config=optimization_config,
            random_seed=request.seed,
            surrogate_model_class=request.surrogate_model_class,
            kernel_class=request.kernel_class,
            kernel_options=request.kernel_options,
            acquisition_function_class=request.acquisition_function_class,
            acquisition_function_options=request.acquisition_function_options
        )
        
        # æ·»åŠ å†å²å®éªŒæ•°æ®
        for exp in request.completed_experiments:
            experiment_result = ExperimentResult(
                parameters=exp.parameters,
                metrics=exp.metrics
            )
            optimizer.add_prior_experiments([experiment_result])
        
        # è·å–ä¸‹ä¸€ç»„æ¨èå‚æ•°
        next_trials = optimizer.get_next_parameters(n=request.batch)
        next_parameters = [params for params, _ in next_trials]
        
        # ä¿®å¤æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜
        next_parameters = fix_float_precision(next_parameters)
        
        # æ„å»ºå“åº”æ¶ˆæ¯
        message = f"æˆåŠŸæ¨è{len(next_parameters)}ä¸ªå‚æ•°ç»„åˆ"
        
        custom_components = []
        if request.surrogate_model_class:
            custom_components.append("ä»£ç†æ¨¡å‹:"+request.surrogate_model_class)
        if request.kernel_class:
            custom_components.append("æ ¸å‡½æ•°:"+request.kernel_class)
        if request.acquisition_function_class:
            custom_components.append("é‡‡é›†å‡½æ•°:"+request.acquisition_function_class)
        
        if custom_components:
            message += f"ï¼Œä½¿ç”¨{'+'.join(custom_components)}"
            
        parameter_info = []
        if request.kernel_options:
            parameter_info.append(f"æ ¸å‡½æ•°å‚æ•°: {request.kernel_options}")
        if request.acquisition_function_options:
            parameter_info.append(f"é‡‡é›†å‡½æ•°å‚æ•°: {request.acquisition_function_options}")     
        if parameter_info:
            message += f"ï¼Œ{', '.join(parameter_info)}"
        else:
            message += "ï¼Œä½¿ç”¨é»˜è®¤é…ç½®"
        
        return UpdateResponse(
            success=True,
            next_parameters=next_parameters,
            message=message
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¼˜åŒ–å¤±è´¥: {str(e)}")

def check_categorical_data(data: pd.DataFrame, parameters: List[str]) -> bool:
    """æ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦åŒ…å«ç±»åˆ«æ•°æ®"""
    for param in parameters:
        if param in data.columns:
            # æ£€æŸ¥æ˜¯å¦ä¸ºéæ•°å€¼ç±»å‹
            if not pd.api.types.is_numeric_dtype(data[param]):
                return True
            # æ£€æŸ¥æ•°å€¼ç±»å‹ä½†å”¯ä¸€å€¼æ•°é‡è¾ƒå°‘ï¼ˆå¯èƒ½æ˜¯ç¦»æ•£æ•°å€¼ï¼‰
            unique_count = data[param].nunique()
            if unique_count <= 10:  # å¦‚æœå”¯ä¸€å€¼æ•°é‡å°‘äºç­‰äº10ï¼Œè®¤ä¸ºæ˜¯ç±»åˆ«æ•°æ®
                return True
    return False



@app.post("/analysis", response_model=AnalysisResponse)
async def analyze_experiment_data(
    file: UploadFile = File(..., description="å®éªŒæ•°æ®CSVæ–‡ä»¶"),
    parameters: str = Field(..., description="å‚æ•°åˆ—åï¼Œç”¨é€—å·åˆ†éš”"),
    objectives: str = Field(..., description="ç›®æ ‡åˆ—åï¼Œç”¨é€—å·åˆ†éš”"),
    search_space: str = Field(..., description="å‚æ•°ç©ºé—´é…ç½®ï¼ŒJSONæ ¼å¼å­—ç¬¦ä¸²"),
    surrogate_model_class: Optional[str] = Field(None, description="ä»£ç†æ¨¡å‹ç±»å"),
    kernel_class: Optional[str] = Field(None, description="æ ¸å‡½æ•°ç±»å"),
    kernel_options: Optional[str] = Field(None, description="æ ¸å‡½æ•°å‚æ•°ï¼ŒJSONæ ¼å¼å­—ç¬¦ä¸²")
):
    """åˆ†æå®éªŒæ•°æ®ï¼Œç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
    try:
        # è§£æå‚æ•°
        param_list = [p.strip() for p in parameters.split(',')]
        objective_list = [o.strip() for o in objectives.split(',')]
        
        # è§£ææœç´¢ç©ºé—´
        search_space_dict = json.loads(search_space)
        
        # è§£ææ ¸å‡½æ•°å‚æ•°
        kernel_options_dict = None
        if kernel_options:
            kernel_options_dict = json.loads(kernel_options)
        
        # è·å–æ¨¡å‹ç±»ï¼ˆä½¿ç”¨é¡¹ç›®ç°æœ‰çš„ç±»è·å–æœºåˆ¶ï¼‰
        surrogate_model_cls = None
        kernel_cls = None
        if surrogate_model_class:
            surrogate_model_cls = get_class_from_string(surrogate_model_class)
        if kernel_class:
            kernel_cls = get_class_from_string(kernel_class)
        
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_file_path = tmp_file.name
        
        try:
            # è¯»å–æ•°æ®
            data = pd.read_csv(tmp_file_path)
            
            # æ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦åŒ…å«ç±»åˆ«æ•°æ®
            has_categorical = check_categorical_data(data, param_list)
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = f"api_analysis_output_{tempfile.mktemp()}"
            os.makedirs(output_dir, exist_ok=True)
            
            # åˆ›å»ºåˆ†æå™¨
            analyzer = ParameterOptimizationAnalysis(
                experiment_file=tmp_file_path,
                output_dir=output_dir
            )
            
            generated_plots = []
            
            # ç”Ÿæˆå¹¶è¡Œåæ ‡å›¾
            print("ğŸ“Š ç”Ÿæˆå¹¶è¡Œåæ ‡å›¾...")
            parallel_plots = analyzer.create_parallel_coordinates_plots(
                parameters=param_list,
                objectives=objective_list
            )
            generated_plots.extend([f"parallel_coords_{obj}" for obj in objective_list])
            
            # ç”Ÿæˆç‰¹å¾é‡è¦æ€§å›¾
            print("ğŸ“Š ç”Ÿæˆç‰¹å¾é‡è¦æ€§å›¾...")
            shap_plots = analyzer.create_feature_importance_plots(
                parameters=param_list,
                objectives=objective_list
            )
            generated_plots.extend([f"feature_importance_{obj}" for obj in objective_list])
            
            # ç”Ÿæˆäº¤å‰éªŒè¯å›¾
            print("ğŸ“Š ç”Ÿæˆäº¤å‰éªŒè¯å›¾...")
            cv_plots = analyzer.create_cross_validation_plots(
                parameters=param_list,
                objectives=objective_list,
                search_space=search_space_dict,
                untransform=True,
                surrogate_model_class=surrogate_model_cls,
                kernel_class=kernel_cls,
                kernel_options=kernel_options_dict
            )
            generated_plots.extend([f"cross_validation_{obj}" for obj in objective_list])
            
            # å¦‚æœæ²¡æœ‰ç±»åˆ«æ•°æ®ï¼Œç”Ÿæˆé¢å¤–çš„å›¾è¡¨
            if not has_categorical:
                print("ğŸ“Š ç”Ÿæˆåˆ‡ç‰‡å›¾...")
                slice_plots = analyzer.create_slice_plots(
                    parameters=param_list,
                    objectives=objective_list,
                    search_space=search_space_dict,
                    surrogate_model_class=surrogate_model_cls,
                    kernel_class=kernel_cls,
                    kernel_options=kernel_options_dict
                )
                generated_plots.extend([f"slice_{obj}_{param}" for obj in objective_list for param in param_list])
                
                print("ğŸ“Š ç”Ÿæˆç­‰é«˜çº¿å›¾...")
                contour_plots = analyzer.create_contour_plots(
                    parameters=param_list,
                    objectives=objective_list,
                    search_space=search_space_dict,
                    surrogate_model_class=surrogate_model_cls,
                    kernel_class=kernel_cls,
                    kernel_options=kernel_options_dict
                )
                generated_plots.extend([f"contour_{obj}_{param1}_{param2}" for obj in objective_list for param1 in param_list for param2 in param_list if param1 != param2])
            
            # ä¿å­˜æ‰€æœ‰å›¾è¡¨
            analyzer.save_plots()
            
            # æ„å»ºå“åº”æ¶ˆæ¯
            if has_categorical:
                message = f"æ£€æµ‹åˆ°ç±»åˆ«æ•°æ®ï¼Œç”Ÿæˆäº†3ç§å›¾è¡¨ï¼šå¹¶è¡Œåæ ‡å›¾ã€ç‰¹å¾é‡è¦æ€§å›¾ã€äº¤å‰éªŒè¯å›¾"
            else:
                message = f"æœªæ£€æµ‹åˆ°ç±»åˆ«æ•°æ®ï¼Œç”Ÿæˆäº†5ç§å›¾è¡¨ï¼šå¹¶è¡Œåæ ‡å›¾ã€ç‰¹å¾é‡è¦æ€§å›¾ã€äº¤å‰éªŒè¯å›¾ã€åˆ‡ç‰‡å›¾ã€ç­‰é«˜çº¿å›¾"
            
            if surrogate_model_class or kernel_class:
                custom_components = []
                if surrogate_model_class:
                    custom_components.append(f"ä»£ç†æ¨¡å‹:{surrogate_model_class}")
                if kernel_class:
                    custom_components.append(f"æ ¸å‡½æ•°:{kernel_class}")
                message += f"ï¼Œä½¿ç”¨{'+'.join(custom_components)}"
            
            return AnalysisResponse(
                success=True,
                message=message,
                generated_plots=generated_plots,
                output_directory=output_dir,
                has_categorical_data=has_categorical
            )
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(tmp_file_path):
                os.unlink(tmp_file_path)
                
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±è´¥: {str(e)}")



if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=3320)
