from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.responses import HTMLResponse
from starlette.responses import Response
from starlette.types import Scope
from starlette.staticfiles import StaticFiles
from fastapi.middleware.gzip import GZipMiddleware
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional, Union, Literal, Tuple
import uvicorn
import pandas as pd
import tempfile
import os
import json
import uuid
from pathlib import Path
from datetime import datetime
from doe_init import generate_sobol_parameters, generate_lhs_parameters, generate_uniform_parameters
from ax_optimizer import BayesianOptimizer, ExperimentResult
from analysis import ParameterOptimizationAnalysis
from __init__ import get_class_from_string

class CacheControlledStaticFiles(StaticFiles):
    async def get_response(self, path: str, scope: Scope) -> Response:
        response = await super().get_response(path, scope)
        response.headers["Cache-Control"] = "public, max-age=184600, immutable"
        return response

app = FastAPI(
    title="å‚æ•°ä¼˜åŒ–API v3",
    description="æ”¯æŒå…ˆéªŒå®éªŒæ•°æ®çš„å‚æ•°ä¼˜åŒ–APIï¼Œé»˜è®¤sobolé‡‡æ ·ï¼Œæ”¯æŒå¤šç§é‡‡æ ·æ–¹å¼ï¼Œæ–°å¢è´å¶æ–¯ä¼˜åŒ–æ”¯æŒ",
    version="3.0.0"
)
app.add_middleware(GZipMiddleware, minimum_size=1024)
app.mount("/static", CacheControlledStaticFiles(directory=Path("static"), html=True), name="static")


# æŒä¹…åŒ–å­˜å‚¨é…ç½® - ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•ï¼Œå…¼å®¹érootç”¨æˆ·å’ŒWindows
PERSISTENT_OUTPUT_DIR = Path.cwd() / "analysis_outputs"
CHART_METADATA_DIR = PERSISTENT_OUTPUT_DIR / "chart_metadata"
# ç¡®ä¿æŒä¹…åŒ–ç›®å½•å­˜åœ¨
PERSISTENT_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
CHART_METADATA_DIR.mkdir(parents=True, exist_ok=True)

# æ—§çš„åŠ è½½å‡½æ•°å·²ç§»é™¤ï¼Œç°åœ¨ä½¿ç”¨å°æ–‡ä»¶å­˜å‚¨

def save_single_chart_metadata(chart_id: str, metadata: Dict[str, Any]) -> bool:
    """ä¿å­˜å•ä¸ªå›¾è¡¨çš„å…ƒæ•°æ®åˆ°å°æ–‡ä»¶"""
    try:
        metadata_file = CHART_METADATA_DIR / f"{chart_id}.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"âŒ ä¿å­˜å›¾è¡¨å…ƒæ•°æ®å¤±è´¥ {chart_id}: {e}")
        return False

def load_single_chart_metadata(chart_id: str) -> Optional[Dict[str, Any]]:
    """åŠ è½½å•ä¸ªå›¾è¡¨çš„å…ƒæ•°æ®"""
    try:
        metadata_file = CHART_METADATA_DIR / f"{chart_id}.json"
        if not metadata_file.exists():
            return None
        with open(metadata_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âŒ åŠ è½½å›¾è¡¨å…ƒæ•°æ®å¤±è´¥ {chart_id}: {e}")
        return None

def list_all_chart_metadata() -> Dict[str, Dict[str, Any]]:
    """åˆ—å‡ºæ‰€æœ‰å›¾è¡¨çš„å…ƒæ•°æ®"""
    charts = {}
    try:
        for metadata_file in CHART_METADATA_DIR.glob("*.json"):
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                    chart_id = metadata_file.stem  # æ–‡ä»¶åä½œä¸ºchart_id
                    charts[chart_id] = metadata
            except Exception as e:
                print(f"âš ï¸ è¯»å–å…ƒæ•°æ®æ–‡ä»¶å¤±è´¥ {metadata_file}: {e}")
                continue
    except Exception as e:
        print(f"âŒ éå†å…ƒæ•°æ®ç›®å½•å¤±è´¥: {e}")
    return charts

# æ—§çš„ä¿å­˜å‡½æ•°å·²ç§»é™¤ï¼Œç°åœ¨ç›´æ¥ä½¿ç”¨å°æ–‡ä»¶å­˜å‚¨

def cleanup_expired_files(days=30):
    """æ¸…ç†è¶…è¿‡æŒ‡å®šå¤©æ•°çš„è¿‡æœŸæ–‡ä»¶"""
    try:
        from datetime import datetime, timedelta
        cutoff_date = datetime.now() - timedelta(days=days)
        
        # æ¸…ç†è¿‡æœŸçš„å›¾è¡¨æ–‡ä»¶
        expired_count = 0
        for metadata_file in CHART_METADATA_DIR.glob("*.json"):
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                
                created_at_str = metadata.get('created_at', '')
                if created_at_str:
                    created_at = datetime.fromisoformat(created_at_str)
                    if created_at < cutoff_date:
                        # åˆ é™¤å›¾è¡¨æ–‡ä»¶
                        file_path = metadata.get('path', '')
                        if file_path and os.path.exists(file_path):
                            try:
                                os.unlink(file_path)
                                print(f"ğŸ—‘ï¸ åˆ é™¤è¿‡æœŸæ–‡ä»¶: {file_path}")
                            except Exception as e:
                                print(f"âš ï¸ åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                        
                        # åˆ é™¤å…ƒæ•°æ®æ–‡ä»¶
                        metadata_file.unlink()
                        expired_count += 1
                        
            except Exception as e:
                print(f"âš ï¸ å¤„ç†æ–‡ä»¶å¤±è´¥ {metadata_file}: {e}")
                continue
        
        if expired_count > 0:
            print(f"âœ… æ¸…ç†äº† {expired_count} ä¸ªè¿‡æœŸæ–‡ä»¶")
        
        # æ¸…ç†ç©ºçš„è¾“å‡ºç›®å½•
        for output_dir in PERSISTENT_OUTPUT_DIR.iterdir():
            if output_dir.is_dir() and not any(output_dir.iterdir()):
                try:
                    output_dir.rmdir()
                    print(f"ğŸ—‘ï¸ åˆ é™¤ç©ºç›®å½•: {output_dir}")
                except Exception as e:
                    print(f"âš ï¸ åˆ é™¤ç›®å½•å¤±è´¥ {output_dir}: {e}")
                    
    except Exception as e:
        print(f"âš ï¸ æ¸…ç†è¿‡æœŸæ–‡ä»¶å¤±è´¥: {e}")

# å¯åŠ¨æ—¶æ¸…ç†è¿‡æœŸæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
# cleanup_expired_files(days=30)



# å®šä¹‰å‚æ•°ç©ºé—´æ¨¡å‹
class ParameterSpace(BaseModel):
    name: str = Field(..., description="å‚æ•°åç§°")
    type: Literal["choice", "range"] = Field(..., description="å‚æ•°ç±»å‹ï¼šchoiceï¼ˆç¦»æ•£é€‰æ‹©ï¼‰æˆ–rangeï¼ˆè¿ç»­èŒƒå›´ï¼‰")
    values: Union[List[Union[str, int, float]], List[float]] = Field(..., description="å½“typeä¸ºchoiceæ—¶è¡¨ç¤ºå¯é€‰å€¼åˆ—è¡¨ï¼Œå½“typeä¸ºrangeæ—¶è¡¨ç¤º[æœ€å°å€¼, æœ€å¤§å€¼]")
    step: Optional[Union[int, float]] = Field(None, description="æ­¥é•¿ï¼Œç”¨äºå°†rangeå‚æ•°è½¬æ¢ä¸ºchoiceå‚æ•°")

# å®šä¹‰å…ˆéªŒå®éªŒæ•°æ®æ¨¡å‹
class PriorExperiment(BaseModel):
    parameters: Dict[str, Union[str, int, float]] = Field(..., description="å‚æ•°ç»„åˆ")
    metrics: Dict[str, Union[int, float]] = Field(..., description="å®éªŒç»“æœæŒ‡æ ‡")

# å®šä¹‰åˆå§‹åŒ–è¯·æ±‚æ¨¡å‹
class InitRequest(BaseModel):
    parameter_space: List[ParameterSpace] = Field(..., description="å‚æ•°ç©ºé—´å®šä¹‰")
    objectives: List[str] = Field(..., description="ä¼˜åŒ–ç›®æ ‡åˆ—è¡¨")
    batch: int = Field(..., description="æ¯æ‰¹æ¬¡å‚æ•°æ•°é‡", ge=1)
    seed: Optional[int] = Field(None, description="éšæœºç§å­")
    prior_experiments: Optional[List[PriorExperiment]] = Field(None, description="å…ˆéªŒå®éªŒæ•°æ®")
    sampling_method: Optional[Literal["sobol", "lhs", "uniform"]] = Field("sobol", description="é‡‡æ ·æ–¹æ³•ï¼ˆä»…åœ¨æ²¡æœ‰å…ˆéªŒæ•°æ®æ—¶ç”Ÿæ•ˆï¼‰")

# å®šä¹‰å“åº”æ¨¡å‹
class InitResponse(BaseModel):
    success: bool
    sampling_method: str
    results: List[Dict[str, Any]]
    message: str

# å®šä¹‰æ›´æ–°è¯·æ±‚æ¨¡å‹
class UpdateRequest(BaseModel):
    parameter_space: List[ParameterSpace] = Field(..., description="å‚æ•°ç©ºé—´å®šä¹‰")
    objectives: Dict[str, Dict[str, bool]] = Field(..., description="ä¼˜åŒ–ç›®æ ‡é…ç½®ï¼Œæ ¼å¼ä¸º{'metric_name': {'minimize': bool}}")
    completed_experiments: List[PriorExperiment] = Field(..., description="å·²å®Œæˆçš„å®éªŒç»“æœ")
    batch: int = Field(1, description="ä¸‹ä¸€æ‰¹æ¬¡å‚æ•°æ•°é‡", ge=1)
    use_weights: Optional[bool] = Field(False, description="æ˜¯å¦ä½¿ç”¨æƒé‡ä¼˜åŒ–")
    objective_weights: Optional[Dict[str, float]] = Field(None, description="ç›®æ ‡æƒé‡")
    additional_metrics: Optional[List[str]] = Field(None, description="é¢å¤–è·Ÿè¸ªæŒ‡æ ‡")
    seed: Optional[int] = Field(None, description="éšæœºç§å­")
    # æ–°å¢è‡ªå®šä¹‰æ¨¡å‹é…ç½®
    surrogate_model_class: Optional[str] = Field(None, description="ä»£ç†æ¨¡å‹ç±»åï¼Œå¦‚ 'SingleTaskGP', 'MultiTaskGP' ç­‰")
    kernel_class: Optional[str] = Field(None, description="æ ¸å‡½æ•°ç±»åï¼Œå¦‚ 'MaternKernel', 'RBFKernel' ç­‰")
    kernel_options: Optional[Dict[str, Any]] = Field(None, description="æ ¸å‡½æ•°å‚æ•°ï¼Œå¦‚ {'nu': 2.5} for MaternKernel")
    # æ–°å¢é‡‡é›†å‡½æ•°é…ç½®
    acquisition_function_class: Optional[str] = Field(None, description="é‡‡é›†å‡½æ•°ç±»å")
    acquisition_function_options: Optional[Dict[str, Any]] = Field(None, description="é‡‡é›†å‡½æ•°å‚æ•°ï¼Œå¦‚ {'beta': 0.1} for UCB")

# å®šä¹‰æ›´æ–°å“åº”æ¨¡å‹
class UpdateResponse(BaseModel):
    success: bool
    results: List[Dict[str, Any]]
    message: str

# å®šä¹‰åˆ†æè¯·æ±‚æ¨¡å‹
class AnalysisRequest(BaseModel):
    parameter_space: List[ParameterSpace] = Field(..., description="å‚æ•°ç©ºé—´å®šä¹‰")
    objectives: Union[List[str], Dict[str, Dict[str, bool]]] = Field(..., description="ä¼˜åŒ–ç›®æ ‡é…ç½®ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨æˆ–å­—å…¸æ ¼å¼")
    completed_experiments: List[PriorExperiment] = Field(..., description="å·²å®Œæˆçš„å®éªŒç»“æœ")
    # å¯é€‰çš„è‡ªå®šä¹‰ä»£ç†æ¨¡å‹é…ç½®
    surrogate_model_class: Optional[str] = Field(None, description="ä»£ç†æ¨¡å‹ç±»åï¼Œå¦‚ 'SingleTaskGP', 'MultiTaskGP' ç­‰")
    kernel_class: Optional[str] = Field(None, description="æ ¸å‡½æ•°ç±»åï¼Œå¦‚ 'MaternKernel', 'RBFKernel' ç­‰")
    kernel_options: Optional[Dict[str, Any]] = Field(None, description="æ ¸å‡½æ•°å‚æ•°ï¼Œå¦‚ {'nu': 2.5} for MaternKernel")

# å®šä¹‰åˆ†æå“åº”æ¨¡å‹
class AnalysisResponse(BaseModel):
    success: bool
    message: str
    generated_plots: List[str] = Field(..., description="ç”Ÿæˆçš„å›¾è¡¨åˆ—è¡¨")
    output_directory: str = Field(..., description="è¾“å‡ºç›®å½•è·¯å¾„")
    has_categorical_data: bool = Field(..., description="æ˜¯å¦åŒ…å«ç±»åˆ«æ•°æ®")
    view_links: List[Dict[str, str]] = Field(default=[], description="å›¾è¡¨æŸ¥çœ‹é“¾æ¥åˆ—è¡¨ï¼ŒåŒ…å«nameã€urlã€typeå­—æ®µ")

# å®šä¹‰åˆ‡ç‰‡å›¾è¯·æ±‚æ¨¡å‹
class SliceAnalysisRequest(BaseModel):
    parameter_space: List[ParameterSpace] = Field(..., description="å‚æ•°ç©ºé—´å®šä¹‰")
    objectives: Union[List[str], Dict[str, Dict[str, bool]]] = Field(..., description="ä¼˜åŒ–ç›®æ ‡é…ç½®ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨æˆ–å­—å…¸æ ¼å¼")
    completed_experiments: List[PriorExperiment] = Field(..., description="å·²å®Œæˆçš„å®éªŒç»“æœ")
    parameter: str = Field(..., description="è¦åˆ†æçš„å‚æ•°åç§°")
    objective: str = Field(..., description="è¦åˆ†æçš„ç›®æ ‡åç§°")
    surrogate_model_class: Optional[str] = Field(None, description="ä»£ç†æ¨¡å‹ç±»å")
    kernel_class: Optional[str] = Field(None, description="æ ¸å‡½æ•°ç±»å")
    kernel_options: Optional[Dict[str, Any]] = Field(None, description="æ ¸å‡½æ•°å‚æ•°")

# å®šä¹‰ç­‰é«˜çº¿å›¾è¯·æ±‚æ¨¡å‹
class ContourAnalysisRequest(BaseModel):
    parameter_space: List[ParameterSpace] = Field(..., description="å‚æ•°ç©ºé—´å®šä¹‰")
    objectives: Union[List[str], Dict[str, Dict[str, bool]]] = Field(..., description="ä¼˜åŒ–ç›®æ ‡é…ç½®ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨æˆ–å­—å…¸æ ¼å¼")
    completed_experiments: List[PriorExperiment] = Field(..., description="å·²å®Œæˆçš„å®éªŒç»“æœ")
    parameter1: str = Field(..., description="ç¬¬ä¸€ä¸ªå‚æ•°åç§°")
    parameter2: str = Field(..., description="ç¬¬äºŒä¸ªå‚æ•°åç§°")
    objective: str = Field(..., description="è¦åˆ†æçš„ç›®æ ‡åç§°")
    surrogate_model_class: Optional[str] = Field(None, description="ä»£ç†æ¨¡å‹ç±»å")
    kernel_class: Optional[str] = Field(None, description="æ ¸å‡½æ•°ç±»å")
    kernel_options: Optional[Dict[str, Any]] = Field(None, description="æ ¸å‡½æ•°å‚æ•°")

# å®šä¹‰å•ä¸ªå›¾è¡¨å“åº”æ¨¡å‹
class SinglePlotResponse(BaseModel):
    success: bool
    message: str
    plot_name: str = Field(..., description="ç”Ÿæˆçš„å›¾è¡¨åç§°")
    view_link: Dict[str, str] = Field(..., description="å›¾è¡¨æŸ¥çœ‹é“¾æ¥ï¼ŒåŒ…å«nameã€urlã€typeå­—æ®µ")

def convert_parameter_space_to_ax_format(parameter_space: List[ParameterSpace]) -> Tuple[List[Dict[str, Any]], Dict[str, Dict[str, Any]]]:
    """å°†å‚æ•°ç©ºé—´è½¬æ¢ä¸ºAxæ ¼å¼ï¼Œè¿”å›(search_space, step_info)"""
    search_space = []
    step_info = {}  # å­˜å‚¨stepä¿¡æ¯ï¼Œç”¨äºåç»­èˆå…¥
    
    for param in parameter_space:
        if param.type == "choice":
            # ç¡®å®švalue_typeï¼šå­—ç¬¦ä¸²ã€æµ®ç‚¹æ•°ã€æ•´æ•°
            if all(isinstance(x, str) for x in param.values):
                value_type = "str"
            elif any(isinstance(x, float) for x in param.values):
                value_type = "float"
            else:
                value_type = "int"
            
            # å¯¹äºæµ®ç‚¹æ•°choiceå‚æ•°ï¼Œç¡®ä¿å€¼éƒ½æ˜¯æµ®ç‚¹æ•°ç±»å‹
            if value_type == "float":
                values = [float(v) for v in param.values]
            else:
                values = param.values
            
            search_space.append({
                "name": param.name,
                "type": "choice",
                "values": values,
                "value_type": value_type,
                "is_ordered": True,
                "sort_values": True
            })
        else:  # rangeç±»å‹
            if len(param.values) != 2:
                raise ValueError(f"å‚æ•° {param.name} çš„rangeç±»å‹å¿…é¡»æä¾›[æœ€å°å€¼, æœ€å¤§å€¼]")
            
            # ä¿æŒä¸ºrangeç±»å‹ï¼Œæ— è®ºæ˜¯å¦æœ‰stepå‚æ•°
            # stepå‚æ•°å°†åœ¨åå¤„ç†ä¸­ç”¨äºèˆå…¥æ¨èå€¼
            param_config = {
                "name": param.name,
                "type": "range",
                "bounds": param.values,
                "value_type": "float" if any(isinstance(x, float) for x in param.values) else "int"
            }
            
            # å¦‚æœæœ‰stepå‚æ•°ï¼Œå­˜å‚¨åˆ°step_infoä¸­ï¼Œè€Œä¸æ˜¯æ·»åŠ åˆ°Axé…ç½®ä¸­
            if param.step is not None:
                step_info[param.name] = {
                    "step": param.step,
                    "bounds": param.values
                }
            
            search_space.append(param_config)
    return search_space, step_info

def convert_parameter_space_to_ax_format_for_analysis(parameter_space: List[ParameterSpace]) -> List[Dict[str, Any]]:
    """å°†å‚æ•°ç©ºé—´è½¬æ¢ä¸ºAxæ ¼å¼ï¼ˆä¸“é—¨ç”¨äºanalysisæ¥å£ï¼Œå¿½ç•¥stepå‚æ•°ï¼‰"""
    search_space = []
    for param in parameter_space:
        if param.type == "choice":
            # ç¡®å®švalue_typeï¼šå­—ç¬¦ä¸²ã€æµ®ç‚¹æ•°ã€æ•´æ•°
            if all(isinstance(x, str) for x in param.values):
                value_type = "str"
                values = param.values
            else:
                # å¯¹äºæ•°å€¼ç±»å‹ï¼Œç»Ÿä¸€ä½¿ç”¨floatä»¥é¿å…ç±»å‹è½¬æ¢é—®é¢˜
                value_type = "float"
                values = [float(v) for v in param.values]
            
            search_space.append({
                "name": param.name,
                "type": "choice",
                "values": values,
                "value_type": value_type,
                "is_ordered": True,
                "sort_values": True
            })
        else:  # rangeç±»å‹
            if len(param.values) != 2:
                raise ValueError(f"å‚æ•° {param.name} çš„rangeç±»å‹å¿…é¡»æä¾›[æœ€å°å€¼, æœ€å¤§å€¼]")
            
            # åœ¨analysisæ¥å£ä¸­ï¼Œå¿½ç•¥stepå‚æ•°ï¼Œå§‹ç»ˆä¿æŒä¸ºrangeç±»å‹
            # ä¸ºäº†å…¼å®¹CSVæ•°æ®ä¸­çš„numpy.float64ç±»å‹ï¼Œç»Ÿä¸€ä½¿ç”¨floatç±»å‹
            value_type = "float"
            
            # ç¡®ä¿boundsä¸­çš„å€¼ä¹Ÿæ˜¯æµ®ç‚¹æ•°ç±»å‹
            float_bounds = [float(val) for val in param.values]
            
            search_space.append({
                "name": param.name,
                "type": "range",
                "bounds": float_bounds,
                "value_type": value_type
            })
    return search_space

def convert_prior_experiments_to_dict(prior_experiments: List[PriorExperiment]) -> List[Dict[str, Any]]:
    """å°†å…ˆéªŒå®éªŒæ•°æ®è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
    experiments = []
    for exp in prior_experiments:
        # åˆå¹¶å‚æ•°å’ŒæŒ‡æ ‡
        combined_data = {}
        combined_data.update(exp.parameters)
        combined_data.update(exp.metrics)
        experiments.append(combined_data)
    return experiments

def round_to_step(value: float, step: float, bounds: List[float]) -> float:
    """
    å°†å€¼èˆå…¥åˆ°æœ€è¿‘çš„stepå€¼
    
    Args:
        value: åŸå§‹å€¼
        step: æ­¥é•¿
        bounds: [min, max] è¾¹ç•Œ
        
    Returns:
        èˆå…¥åçš„å€¼
    """
    min_val, max_val = bounds
    
    # è®¡ç®—æœ€æ¥è¿‘çš„stepå€¼
    num_steps = round((value - min_val) / step)
    rounded_value = min_val + num_steps * step
    
    # ç¡®ä¿åœ¨è¾¹ç•Œå†…
    rounded_value = max(min_val, min(max_val, rounded_value))
    
    # è®¡ç®—å°æ•°ä½æ•°
    decimal_places = 0
    if isinstance(step, float):
        step_str = f"{step:.10f}".rstrip('0').rstrip('.')
        if '.' in step_str:
            decimal_places = len(step_str.split('.')[1])
    
    # ä½¿ç”¨ç›¸åŒçš„å°æ•°ä½æ•°è¿›è¡Œèˆå…¥
    rounded_value = round(rounded_value, decimal_places)
    
    return rounded_value

def apply_step_constraints(params_list: List[Dict[str, Any]], step_info: Dict[str, Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    åº”ç”¨stepçº¦æŸï¼Œå°†æ¨èå€¼èˆå…¥åˆ°æœ€è¿‘çš„stepå€¼
    
    Args:
        params_list: æ¨èçš„å‚æ•°åˆ—è¡¨
        step_info: åŒ…å«stepä¿¡æ¯çš„å­—å…¸
        
    Returns:
        åº”ç”¨stepçº¦æŸåçš„å‚æ•°åˆ—è¡¨
    """
    # åº”ç”¨stepçº¦æŸ
    constrained_params_list = []
    for params in params_list:
        constrained_params = {}
        for key, value in params.items():
            if key in step_info and isinstance(value, (int, float)):
                # åº”ç”¨stepèˆå…¥
                info = step_info[key]
                constrained_value = round_to_step(value, info["step"], info["bounds"])
                constrained_params[key] = constrained_value
            else:
                constrained_params[key] = value
        constrained_params_list.append(constrained_params)
    
    return constrained_params_list

def fix_float_precision(params_list: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """ä¿®å¤æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜"""
    fixed_params_list = []
    for params in params_list:
        fixed_params = {}
        for key, value in params.items():
            if isinstance(value, float):
                # å¯¹äºæµ®ç‚¹æ•°ï¼Œè¿›è¡Œå››èˆäº”å…¥åˆ°åˆç†çš„å°æ•°ä½æ•°
                # å¦‚æœçœ‹èµ·æ¥åƒæ˜¯æ•´æ•°ï¼ˆå¦‚8.0ï¼‰ï¼Œåˆ™è½¬æ¢ä¸ºæ•´æ•°
                if abs(value - round(value)) < 1e-10:
                    fixed_params[key] = int(round(value))
                else:
                    # å¯¹äºå°æ•°ï¼Œè¿›è¡Œæ›´ç²¾ç¡®çš„å¤„ç†
                    # å°è¯•æ‰¾åˆ°æœ€æ¥è¿‘çš„"å¹²å‡€"çš„å°æ•°å€¼
                    rounded = round(value, 10)
                    # å¦‚æœå››èˆäº”å…¥åçš„å°æ•°ä½æ•°å¾ˆå°‘ï¼Œç›´æ¥ä½¿ç”¨
                    if len(str(rounded).split('.')[-1]) <= 2:
                        fixed_params[key] = rounded
                    else:
                        # å¦åˆ™å°è¯•æ‰¾åˆ°æœ€æ¥è¿‘çš„ç®€å•åˆ†æ•°
                        # ä¾‹å¦‚ 0.7999999999999999 -> 0.8
                        for precision in [1, 2, 3, 4, 5]:
                            test_value = round(value, precision)
                            if abs(value - test_value) < 1e-10:
                                fixed_params[key] = test_value
                                break
                        else:
                            # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œä½¿ç”¨åŸå§‹å€¼
                            fixed_params[key] = value
            else:
                fixed_params[key] = value
        fixed_params_list.append(fixed_params)
    return fixed_params_list







@app.get("/")
async def root():
    """APIæ ¹è·¯å¾„"""
    return {
        "message": "å‚æ•°ä¼˜åŒ–API v3.0",
        "version": "3.0.0",
        "features": {
            "prior_experiments": "æ”¯æŒå…ˆéªŒå®éªŒæ•°æ®",
            "sampling_methods": "æ”¯æŒsobol/lhs/uniformä¸‰ç§é‡‡æ ·æ–¹å¼",
            "smart_sampling": "æœ‰å…ˆéªŒæ•°æ®æ—¶é»˜è®¤sobolï¼Œæ— å…ˆéªŒæ•°æ®æ—¶å¯é€‰æ‹©é‡‡æ ·æ–¹å¼",
            "bayesian_optimization": "æ”¯æŒè´å¶æ–¯ä¼˜åŒ–ï¼ŒåŸºäºå†å²æ•°æ®æ¨èå‚æ•°",
            "custom_surrogate_models": "æ”¯æŒè‡ªå®šä¹‰ä»£ç†æ¨¡å‹ï¼Œå¦‚ SingleTaskGP, MultiTaskGP ç­‰",
            "custom_kernels": "æ”¯æŒè‡ªå®šä¹‰æ ¸å‡½æ•°ï¼Œå¦‚ MaternKernel, RBFKernel ç­‰",
            "custom_acquisition_functions": "æ”¯æŒè‡ªå®šä¹‰é‡‡é›†å‡½æ•°ï¼ŒåŒ…æ‹¬å•ç›®æ ‡å’Œå¤šç›®æ ‡é‡‡é›†å‡½æ•°",
            "experiment_analysis": "æ”¯æŒå®éªŒæ•°æ®åˆ†æï¼Œç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"
        },
        "endpoints": {
            "POST /init": "åˆå§‹åŒ–ä¼˜åŒ–ï¼Œæ”¯æŒä¼ ç»Ÿé‡‡æ ·",
            "POST /update": "è´å¶æ–¯ä¼˜åŒ–æ¥å£ï¼Œæ”¯æŒè‡ªå®šä¹‰ä»£ç†æ¨¡å‹ã€æ ¸å‡½æ•°å’Œé‡‡é›†å‡½æ•°",
            "POST /analysis": "å®éªŒæ•°æ®åˆ†ææ¥å£ï¼Œç”Ÿæˆå¹¶è¡Œåæ ‡å›¾ã€ç‰¹å¾é‡è¦æ€§å›¾ã€äº¤å‰éªŒè¯å›¾",
            "POST /analysis/slice": "ç”Ÿæˆå•ä¸ªåˆ‡ç‰‡å›¾ï¼Œç”¨æˆ·æŒ‡å®šå‚æ•°å’Œç›®æ ‡",
            "POST /analysis/contour": "ç”Ÿæˆå•ä¸ªç­‰é«˜çº¿å›¾ï¼Œç”¨æˆ·æŒ‡å®šå‚æ•°å¯¹å’Œç›®æ ‡",
            "GET /available_classes": "è·å–å¯ç”¨çš„ä»£ç†æ¨¡å‹ã€æ ¸å‡½æ•°å’Œé‡‡é›†å‡½æ•°åˆ—è¡¨"
        }
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {"status": "healthy", "service": "parameter_optimization_v3"}

@app.get("/chart/{file_id}", response_class=HTMLResponse)
async def view_chart(file_id: str):
    """æŸ¥çœ‹å›¾è¡¨ï¼ˆåœ¨æµè§ˆå™¨ä¸­æ¸²æŸ“ï¼‰"""
    # ä½¿ç”¨æ–°çš„å°æ–‡ä»¶å­˜å‚¨æ–¹å¼ï¼Œç›´æ¥è¯»å–å•ä¸ªå›¾è¡¨çš„å…ƒæ•°æ®
    chart_metadata = load_single_chart_metadata(file_id)
    
    if not chart_metadata:
        raise HTTPException(status_code=404, detail="å›¾è¡¨ä¸å­˜åœ¨")
    
    file_path = chart_metadata.get("path", "")
    if not file_path or not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="å›¾è¡¨æ–‡ä»¶å·²è¢«åˆ é™¤")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            html_content = f.read()
        response = HTMLResponse(content=html_content)
        response.headers["Access-Control-Allow-Origin"] = "*"  # å…è®¸æ‰€æœ‰åŸŸè®¿é—®
        response.headers["Access-Control-Allow-Methods"] = "GET"  # å…è®¸çš„HTTPæ–¹æ³•
        response.headers["Access-Control-Allow-Headers"] = "Content-Type"  # å…è®¸çš„è¯·æ±‚å¤´
        return response
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è¯»å–å›¾è¡¨æ–‡ä»¶å¤±è´¥: {str(e)}")

@app.get("/charts")
async def list_charts():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å›¾è¡¨æ–‡ä»¶"""
    try:
        # ä½¿ç”¨æ–°çš„å°æ–‡ä»¶å­˜å‚¨æ–¹å¼ï¼Œéå†æ‰€æœ‰å°æ–‡ä»¶
        current_chart_files = list_all_chart_metadata()
        
        charts_info = []
        for file_id, file_info in current_chart_files.items():
            chart_info = {
                "file_id": file_id,
                "filename": file_info.get("filename", "unknown"),
                "type": file_info.get("type", "unknown"),
                "created_at": file_info.get("created_at", "unknown"),
                "url": f"/chart/{file_id}",
                "exists": os.path.exists(file_info.get("path", ""))
            }
            charts_info.append(chart_info)
        
        # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        charts_info.sort(key=lambda x: x.get("created_at", ""), reverse=True)
        
        return {
            "success": True,
            "total_charts": len(charts_info),
            "charts": charts_info,
            "output_directory": str(PERSISTENT_OUTPUT_DIR)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å›¾è¡¨åˆ—è¡¨å¤±è´¥: {str(e)}")

@app.delete("/charts/{file_id}")
async def delete_chart(file_id: str):
    """åˆ é™¤æŒ‡å®šçš„å›¾è¡¨æ–‡ä»¶"""
    # ä½¿ç”¨æ–°çš„å°æ–‡ä»¶å­˜å‚¨æ–¹å¼
    chart_metadata = load_single_chart_metadata(file_id)
    if not chart_metadata:
        raise HTTPException(status_code=404, detail="å›¾è¡¨ä¸å­˜åœ¨")
    
    try:
        file_path = chart_metadata.get("path", "")
        
        # åˆ é™¤å®é™…æ–‡ä»¶
        if file_path and os.path.exists(file_path):
            os.unlink(file_path)
        
        # åˆ é™¤å…ƒæ•°æ®æ–‡ä»¶
        metadata_file = CHART_METADATA_DIR / f"{file_id}.json"
        if metadata_file.exists():
            metadata_file.unlink()
        
        return {
            "success": True,
            "message": f"æˆåŠŸåˆ é™¤å›¾è¡¨æ–‡ä»¶: {chart_metadata.get('filename', 'unknown')}"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ é™¤å›¾è¡¨æ–‡ä»¶å¤±è´¥: {str(e)}")

@app.post("/charts/cleanup")
async def cleanup_charts(days: int = 30):
    """æ¸…ç†è¶…è¿‡æŒ‡å®šå¤©æ•°çš„è¿‡æœŸå›¾è¡¨æ–‡ä»¶"""
    try:
        cleanup_expired_files(days)
        return {
            "success": True,
            "message": f"æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº†è¶…è¿‡ {days} å¤©çš„è¿‡æœŸæ–‡ä»¶"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ¸…ç†æ–‡ä»¶å¤±è´¥: {str(e)}")




@app.post("/init", response_model=InitResponse)
async def initialize_optimization(request: InitRequest):
    """åˆå§‹åŒ–ä¼˜åŒ–ï¼Œæ”¯æŒå…ˆéªŒå®éªŒæ•°æ®"""
    try:
        # è½¬æ¢å‚æ•°ç©ºé—´æ ¼å¼
        search_space, step_info = convert_parameter_space_to_ax_format(request.parameter_space)
        
        # ç¡®å®šé‡‡æ ·æ–¹æ³•
        if request.prior_experiments:
            # æœ‰å…ˆéªŒæ•°æ®æ—¶ï¼Œå¼ºåˆ¶ä½¿ç”¨sobolé‡‡æ ·
            sampling_method = "sobol"
            
            # è½¬æ¢å…ˆéªŒå®éªŒæ•°æ®
            prior_experiments = convert_prior_experiments_to_dict(request.prior_experiments)
            
            # ä½¿ç”¨sobolé‡‡æ ·ï¼ˆå¸¦å…ˆéªŒæ•°æ®ï¼‰
            params_list = generate_sobol_parameters(
                search_space, 
                num_points=request.batch, 
                seed=request.seed,
                prior_experiments=prior_experiments
            )
        else:
            # æ²¡æœ‰å…ˆéªŒæ•°æ®æ—¶ï¼Œä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„é‡‡æ ·æ–¹æ³•
            sampling_method = request.sampling_method or "sobol"
            
            if sampling_method == "sobol":
                params_list = generate_sobol_parameters(search_space, num_points=request.batch, seed=request.seed)
            elif sampling_method == "lhs":
                params_list = generate_lhs_parameters(search_space, num_points=request.batch, seed=request.seed)
            elif sampling_method == "uniform":
                params_list = generate_uniform_parameters(search_space, num_points=request.batch, seed=request.seed)
            else:
                raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„é‡‡æ ·æ–¹æ³•: {sampling_method}")
        
        # æ£€æŸ¥ç”Ÿæˆçš„å‚æ•°åˆ—è¡¨
        if not params_list:
            raise HTTPException(status_code=500, detail="é‡‡æ ·å‡½æ•°æœªç”Ÿæˆä»»ä½•å‚æ•°ç»„åˆ")
        
        # åº”ç”¨stepçº¦æŸï¼ˆå¦‚æœæœ‰ï¼‰
        results = apply_step_constraints(params_list, step_info)
        
        # ä¿®å¤æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜
        results = fix_float_precision(results)
        
        return InitResponse(
            success=True,
            sampling_method=sampling_method,
            results=results,
            message=f"åˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨{sampling_method}é‡‡æ ·ç”Ÿæˆ{len(results)}ä¸ªå‚æ•°ç»„åˆ"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆå§‹åŒ–å¤±è´¥: {str(e)}")

@app.post("/update", response_model=UpdateResponse)
async def update_optimization(request: UpdateRequest):
    """è´å¶æ–¯ä¼˜åŒ–æ¥å£ï¼šåŸºäºå†å²æ•°æ®æ¨èä¸‹ä¸€ç»„å‚æ•°"""
    try:
        # è½¬æ¢å‚æ•°ç©ºé—´æ ¼å¼
        search_space, step_info = convert_parameter_space_to_ax_format(request.parameter_space)
        
        # æ„å»ºä¼˜åŒ–é…ç½®
        optimization_config = {
            "objectives": request.objectives,
            "use_weights": request.use_weights or False,
            "objective_weights": request.objective_weights or {},
            "additional_metrics": request.additional_metrics or []
        }
        
        # åˆ›å»ºè´å¶æ–¯ä¼˜åŒ–å™¨
        optimizer = BayesianOptimizer(
            search_space=search_space,
            optimization_config=optimization_config,
            random_seed=request.seed,
            surrogate_model_class=request.surrogate_model_class,
            kernel_class=request.kernel_class,
            kernel_options=request.kernel_options,
            acquisition_function_class=request.acquisition_function_class,
            acquisition_function_options=request.acquisition_function_options
        )
        
        # æ·»åŠ å†å²å®éªŒæ•°æ®
        for exp in request.completed_experiments:
            experiment_result = ExperimentResult(
                parameters=exp.parameters,
                metrics=exp.metrics
            )
            optimizer.add_prior_experiments([experiment_result])
        
        # è·å–ä¸‹ä¸€ç»„æ¨èå‚æ•°
        next_trials = optimizer.get_next_parameters(n=request.batch)
        next_parameters = [params for params, _ in next_trials]
        
        # åº”ç”¨stepçº¦æŸï¼ˆå¦‚æœæœ‰ï¼‰
        next_parameters = apply_step_constraints(next_parameters, step_info)
        
        # ä¿®å¤æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜
        next_parameters = fix_float_precision(next_parameters)
        
        # æ„å»ºå“åº”æ¶ˆæ¯
        message = f"æˆåŠŸæ¨è{len(next_parameters)}ä¸ªå‚æ•°ç»„åˆ"
        
        custom_components = []
        if request.surrogate_model_class:
            custom_components.append("ä»£ç†æ¨¡å‹:"+request.surrogate_model_class)
        if request.kernel_class:
            custom_components.append("æ ¸å‡½æ•°:"+request.kernel_class)
        if request.acquisition_function_class:
            custom_components.append("é‡‡é›†å‡½æ•°:"+request.acquisition_function_class)
        
        if custom_components:
            message += f"ï¼Œä½¿ç”¨{'+'.join(custom_components)}"
            
        parameter_info = []
        if request.kernel_options:
            parameter_info.append(f"æ ¸å‡½æ•°å‚æ•°: {request.kernel_options}")
        if request.acquisition_function_options:
            parameter_info.append(f"é‡‡é›†å‡½æ•°å‚æ•°: {request.acquisition_function_options}")     
        if parameter_info:
            message += f"ï¼Œ{', '.join(parameter_info)}"
        else:
            message += "ï¼Œä½¿ç”¨é»˜è®¤é…ç½®"
        
        return UpdateResponse(
            success=True,
            results=next_parameters,
            message=message
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¼˜åŒ–å¤±è´¥: {str(e)}")

def check_categorical_data(data: pd.DataFrame, parameters: List[str]) -> bool:
    """æ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦åŒ…å«ç±»åˆ«æ•°æ®"""
    for param in parameters:
        if param in data.columns:
            # æ£€æŸ¥æ˜¯å¦ä¸ºéæ•°å€¼ç±»å‹
            if not pd.api.types.is_numeric_dtype(data[param]):
                return True
            # æ£€æŸ¥æ•°å€¼ç±»å‹ä½†å”¯ä¸€å€¼æ•°é‡è¾ƒå°‘ï¼ˆå¯èƒ½æ˜¯ç¦»æ•£æ•°å€¼ï¼‰
            unique_count = data[param].nunique()
            if unique_count <= 10:  # å¦‚æœå”¯ä¸€å€¼æ•°é‡å°‘äºç­‰äº10ï¼Œè®¤ä¸ºæ˜¯ç±»åˆ«æ•°æ®
                return True
    return False



@app.post("/analysis", response_model=AnalysisResponse)
async def analyze_experiment_data(request: AnalysisRequest):
    """åˆ†æå®éªŒæ•°æ®ï¼Œç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
    try:
        # ä»è¯·æ±‚ä¸­æå–å‚æ•°å’Œç›®æ ‡
        param_list = [param.name for param in request.parameter_space]
        
        # å¤„ç†ä¸¤ç§æ ¼å¼çš„objectives
        if isinstance(request.objectives, list):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²åˆ—è¡¨æ ¼å¼
            objective_list = request.objectives
        else:
            # å¦‚æœæ˜¯å­—å…¸æ ¼å¼
            objective_list = list(request.objectives.keys())
        
        # è½¬æ¢å‚æ•°ç©ºé—´ä¸ºAxæ ¼å¼
        search_space_dict, _ = convert_parameter_space_to_ax_format(request.parameter_space)
        
        # è·å–æ¨¡å‹ç±»
        surrogate_model_cls = None
        kernel_cls = None
        if request.surrogate_model_class:
            surrogate_model_cls = get_class_from_string(request.surrogate_model_class)
        if request.kernel_class:
            kernel_cls = get_class_from_string(request.kernel_class)
        
        # å°†å®éªŒæ•°æ®è½¬æ¢ä¸ºDataFrameæ ¼å¼ï¼ˆç”¨äºæ£€æŸ¥ç±»åˆ«æ•°æ®ï¼‰
        data_rows = []
        for exp in request.completed_experiments:
            row = {}
            # æ·»åŠ å‚æ•°
            for param_name, param_value in exp.parameters.items():
                row[param_name] = param_value
            # æ·»åŠ ç›®æ ‡
            for obj_name, obj_value in exp.metrics.items():
                row[obj_name] = obj_value
            data_rows.append(row)
        
        data = pd.DataFrame(data_rows)
        
        # æ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦åŒ…å«ç±»åˆ«æ•°æ®
        has_categorical = check_categorical_data(data, param_list)
        
        # åˆ›å»ºæŒä¹…åŒ–è¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = PERSISTENT_OUTPUT_DIR / f"analysis_{timestamp}"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # å°†å®éªŒæ•°æ®è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        completed_experiments_dict = []
        for exp in request.completed_experiments:
            exp_dict = {
                "parameters": exp.parameters,
                "metrics": exp.metrics
            }
            completed_experiments_dict.append(exp_dict)
        
        # åˆ›å»ºåˆ†æå™¨ï¼Œç›´æ¥ä½¿ç”¨JSONæ•°æ®
        analyzer = ParameterOptimizationAnalysis(
            completed_experiments=completed_experiments_dict,
            output_dir=output_dir
        )
        
        generated_plots = []
        view_links = []  # å­˜å‚¨æŸ¥çœ‹é“¾æ¥ä¿¡æ¯
        
        # ç”Ÿæˆå¹¶è¡Œåæ ‡å›¾
        print("ğŸ“Š ç”Ÿæˆå¹¶è¡Œåæ ‡å›¾...")
        parallel_plots = analyzer.create_parallel_coordinates_plots(
            parameters=param_list,
            objectives=objective_list
        )
        # ç«‹å³ä¿å­˜å¹¶è¡Œåæ ‡å›¾
        if "parallel_coords_combined" in analyzer.plots:
            saved_path = analyzer.save_single_plot("parallel_coords_combined", analyzer.plots["parallel_coords_combined"])
            
            # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶ID
            file_id = str(uuid.uuid4())
            filename = f"parallel_coords_combined.html"
            
            # å­˜å‚¨æ–‡ä»¶æ˜ å°„åˆ°å°æ–‡ä»¶
            metadata = {
                "path": str(saved_path),
                "filename": filename,
                "type": "parallel_coordinates",
                "created_at": datetime.now().isoformat()
            }
            save_single_chart_metadata(file_id, metadata)
            
            # æ·»åŠ æŸ¥çœ‹é“¾æ¥
            view_links.append({
                "name": "parallel_coords_combined",
                "url": f"/chart/{file_id}",
                "type": "parallel_coordinates"
            })
            
        generated_plots.append("parallel_coords_combined")
        
        # ç”Ÿæˆç‰¹å¾é‡è¦æ€§å›¾
        print("ğŸ“Š ç”Ÿæˆç‰¹å¾é‡è¦æ€§å›¾...")
        shap_plots = analyzer.create_feature_importance_analysis(
            parameters=param_list,
            objectives=objective_list
        )
        # ç«‹å³ä¿å­˜ç‰¹å¾é‡è¦æ€§å›¾
        for obj in objective_list:
            plot_name = f"feature_importance_{obj}"
            if plot_name in analyzer.plots:
                saved_path = analyzer.save_single_plot(plot_name, analyzer.plots[plot_name])
                
                # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶ID
                file_id = str(uuid.uuid4())
                filename = f"{plot_name}.html"
                
                # å­˜å‚¨æ–‡ä»¶æ˜ å°„åˆ°å°æ–‡ä»¶
                metadata = {
                    "path": str(saved_path),
                    "filename": filename,
                    "type": "feature_importance",
                    "created_at": datetime.now().isoformat()
                }
                save_single_chart_metadata(file_id, metadata)
                
                # æ·»åŠ æŸ¥çœ‹é“¾æ¥
                view_links.append({
                    "name": plot_name,
                    "url": f"/chart/{file_id}",
                    "type": "feature_importance"
                })
                
        generated_plots.extend([f"feature_importance_{obj}" for obj in objective_list])
        
        # ç”Ÿæˆäº¤å‰éªŒè¯å›¾
        print("ğŸ“Š ç”Ÿæˆäº¤å‰éªŒè¯å›¾...")
        cv_plots = analyzer.create_cross_validation_plots(
            parameters=param_list,
            objectives=objective_list,
            search_space=search_space_dict,
            untransform=True,
            surrogate_model_class=surrogate_model_cls,
            kernel_class=kernel_cls,
            kernel_options=request.kernel_options
        )
        # ç«‹å³ä¿å­˜äº¤å‰éªŒè¯å›¾
        for obj in objective_list:
            plot_name = f"cross_validation_{obj}"
            if plot_name in analyzer.plots:
                saved_path = analyzer.save_single_plot(plot_name, analyzer.plots[plot_name])
                
                # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶ID
                file_id = str(uuid.uuid4())
                filename = f"{plot_name}.html"
                
                # å­˜å‚¨æ–‡ä»¶æ˜ å°„åˆ°å°æ–‡ä»¶
                metadata = {
                    "path": str(saved_path),
                    "filename": filename,
                    "type": "cross_validation",
                    "created_at": datetime.now().isoformat()
                }
                save_single_chart_metadata(file_id, metadata)
                
                # æ·»åŠ æŸ¥çœ‹é“¾æ¥
                view_links.append({
                    "name": plot_name,
                    "url": f"/chart/{file_id}",
                    "type": "cross_validation"
                })
                
        generated_plots.extend([f"cross_validation_{obj}" for obj in objective_list])
        
        # æ³¨æ„ï¼šsliceå›¾å’Œcontourå›¾å·²ç§»è‡³å•ç‹¬çš„æ¥å£
        # ä½¿ç”¨ /analysis/slice æ¥å£ç”Ÿæˆå•ä¸ªåˆ‡ç‰‡å›¾
        # ä½¿ç”¨ /analysis/contour æ¥å£ç”Ÿæˆå•ä¸ªç­‰é«˜çº¿å›¾
        
        # æ„å»ºå“åº”æ¶ˆæ¯
        plot_count = len(generated_plots)
        message = f"ç”Ÿæˆäº†3ç§ç±»å‹å…±{plot_count}ä¸ªå›¾è¡¨ï¼šå¹¶è¡Œåæ ‡å›¾ï¼ˆ1ä¸ªï¼‰ã€ç‰¹å¾é‡è¦æ€§å›¾ï¼ˆ{len(objective_list)}ä¸ªï¼‰ã€äº¤å‰éªŒè¯å›¾ï¼ˆ{len(objective_list)}ä¸ªï¼‰"
        
        if request.surrogate_model_class or request.kernel_class:
            custom_components = []
            if request.surrogate_model_class:
                custom_components.append(f"ä»£ç†æ¨¡å‹:{request.surrogate_model_class}")
            if request.kernel_class:
                custom_components.append(f"æ ¸å‡½æ•°:{request.kernel_class}")
            message += f"ï¼Œä½¿ç”¨{'+'.join(custom_components)}"
        
        return AnalysisResponse(
            success=True,
            message=message,
            generated_plots=generated_plots,
            output_directory=str(output_dir),
            has_categorical_data=has_categorical,
            view_links=view_links
        )
                
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±è´¥: {str(e)}")

@app.post("/analysis/slice", response_model=SinglePlotResponse)
async def analyze_slice_plot(request: SliceAnalysisRequest):
    """ç”Ÿæˆå•ä¸ªåˆ‡ç‰‡å›¾"""
    try:
        # è½¬æ¢å‚æ•°ç©ºé—´ä¸ºAxæ ¼å¼ï¼ˆåˆ†ææ¥å£å¿½ç•¥stepå‚æ•°ï¼‰
        search_space_dict = convert_parameter_space_to_ax_format_for_analysis(request.parameter_space)
        
        # è·å–æ¨¡å‹ç±»
        surrogate_model_cls = None
        kernel_cls = None
        if request.surrogate_model_class:
            surrogate_model_cls = get_class_from_string(request.surrogate_model_class)
        if request.kernel_class:
            kernel_cls = get_class_from_string(request.kernel_class)
        
        # åˆ›å»ºæŒä¹…åŒ–è¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = PERSISTENT_OUTPUT_DIR / f"slice_{timestamp}"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # å°†å®éªŒæ•°æ®è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        completed_experiments_dict = []
        for exp in request.completed_experiments:
            exp_dict = {
                "parameters": exp.parameters,
                "metrics": exp.metrics
            }
            completed_experiments_dict.append(exp_dict)
        
        # åˆ›å»ºåˆ†æå™¨ï¼Œç›´æ¥ä½¿ç”¨JSONæ•°æ®
        analyzer = ParameterOptimizationAnalysis(
            completed_experiments=completed_experiments_dict,
            output_dir=output_dir
        )
        
        # ç”Ÿæˆå•ä¸ªåˆ‡ç‰‡å›¾
        print(f"ğŸ“Š ç”Ÿæˆåˆ‡ç‰‡å›¾: {request.parameter} vs {request.objective}")
        # ä¼ å…¥å®Œæ•´çš„å‚æ•°åˆ—è¡¨æ„å»ºä¼˜åŒ–å™¨ï¼Œä½†åªç”Ÿæˆç”¨æˆ·æŒ‡å®šå‚æ•°çš„åˆ‡ç‰‡å›¾
        all_parameters = [param["name"] for param in search_space_dict]
        slice_plots = analyzer.create_slice_plots(
            parameters=all_parameters,  # ä¼ å…¥æ‰€æœ‰å‚æ•°ï¼Œç¡®ä¿ä¼˜åŒ–å™¨æœ‰å®Œæ•´æ•°æ®
            objectives=[request.objective],
            search_space=search_space_dict,
            surrogate_model_class=surrogate_model_cls,
            kernel_class=kernel_cls,
            kernel_options=request.kernel_options,
            target_parameters=[request.parameter],  # åªç”Ÿæˆç”¨æˆ·æŒ‡å®šå‚æ•°çš„åˆ‡ç‰‡å›¾
            target_objectives=[request.objective]   # åªç”Ÿæˆç”¨æˆ·æŒ‡å®šç›®æ ‡çš„åˆ‡ç‰‡å›¾
        )
        
        # ä½¿ç”¨JSONæ•°ç»„æ ¼å¼å‘½åï¼šslice_["ç›®æ ‡","å‚æ•°"]
        plot_name = f'slice_["{request.objective}","{request.parameter}"]'
        # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†ç”¨æˆ·æŒ‡å®šçš„åˆ‡ç‰‡å›¾
        if plot_name in analyzer.plots:
            # ä¿å­˜å›¾è¡¨å¹¶è·å–å®é™…ä¿å­˜è·¯å¾„
            # æ³¨ï¼šanalysis.pyå†…éƒ¨å·²ä¿å­˜ä¸€æ¬¡ï¼Œè¿™é‡Œå†æ¬¡ä¿å­˜ä»¥ç¡®ä¿è·å¾—å‡†ç¡®çš„æ–‡ä»¶è·¯å¾„
            saved_path = analyzer.save_single_plot(plot_name, analyzer.plots[plot_name])
            
            # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶ID
            file_id = str(uuid.uuid4())
            filename = f"{plot_name}.html"
            
            # å­˜å‚¨æ–‡ä»¶æ˜ å°„åˆ°å°æ–‡ä»¶
            metadata = {
                "path": str(saved_path),
                "filename": filename,
                "type": "slice",
                "created_at": datetime.now().isoformat()
            }
            save_single_chart_metadata(file_id, metadata)
            
            # æ„å»ºæŸ¥çœ‹é“¾æ¥
            view_link = {
                "name": plot_name,
                "url": f"/chart/{file_id}",
                "type": "slice"
            }
            
            # æ„å»ºå“åº”æ¶ˆæ¯
            message = f"æˆåŠŸç”Ÿæˆåˆ‡ç‰‡å›¾: {request.parameter} vs {request.objective}"
            if request.surrogate_model_class or request.kernel_class:
                custom_components = []
                if request.surrogate_model_class:
                    custom_components.append(f"ä»£ç†æ¨¡å‹:{request.surrogate_model_class}")
                if request.kernel_class:
                    custom_components.append(f"æ ¸å‡½æ•°:{request.kernel_class}")
                message += f"ï¼Œä½¿ç”¨{'+'.join(custom_components)}"
            
            return SinglePlotResponse(
                success=True,
                message=message,
                plot_name=plot_name,
                view_link=view_link
            )
        else:
            return SinglePlotResponse(
                success=False,
                message=f"æœªèƒ½ç”ŸæˆæŒ‡å®šçš„åˆ‡ç‰‡å›¾: {request.parameter} vs {request.objective}",
                plot_name="",
                view_link={}
            )
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ‡ç‰‡å›¾åˆ†æå¤±è´¥: {str(e)}")

@app.post("/analysis/contour", response_model=SinglePlotResponse)
async def analyze_contour_plot(request: ContourAnalysisRequest):
    """ç”Ÿæˆå•ä¸ªç­‰é«˜çº¿å›¾"""
    try:
        # éªŒè¯å‚æ•°
        if request.parameter1 == request.parameter2:
            raise HTTPException(status_code=400, detail="ä¸¤ä¸ªå‚æ•°ä¸èƒ½ç›¸åŒ")
        
        # è½¬æ¢å‚æ•°ç©ºé—´ä¸ºAxæ ¼å¼ï¼ˆåˆ†ææ¥å£å¿½ç•¥stepå‚æ•°ï¼‰
        search_space_dict = convert_parameter_space_to_ax_format_for_analysis(request.parameter_space)
        
        # è·å–æ¨¡å‹ç±»
        surrogate_model_cls = None
        kernel_cls = None
        if request.surrogate_model_class:
            surrogate_model_cls = get_class_from_string(request.surrogate_model_class)
        if request.kernel_class:
            kernel_cls = get_class_from_string(request.kernel_class)
        
        # åˆ›å»ºæŒä¹…åŒ–è¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = PERSISTENT_OUTPUT_DIR / f"contour_{timestamp}"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # å°†å®éªŒæ•°æ®è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        completed_experiments_dict = []
        for exp in request.completed_experiments:
            exp_dict = {
                "parameters": exp.parameters,
                "metrics": exp.metrics
            }
            completed_experiments_dict.append(exp_dict)
        
        # åˆ›å»ºåˆ†æå™¨ï¼Œç›´æ¥ä½¿ç”¨JSONæ•°æ®
        analyzer = ParameterOptimizationAnalysis(
            completed_experiments=completed_experiments_dict,
            output_dir=output_dir
        )
        
        # ç”Ÿæˆå•ä¸ªç­‰é«˜çº¿å›¾
        print(f"ğŸ“Š ç”Ÿæˆç­‰é«˜çº¿å›¾: {request.parameter1} vs {request.parameter2} for {request.objective}")
        # ä¼ å…¥å®Œæ•´çš„å‚æ•°åˆ—è¡¨æ„å»ºä¼˜åŒ–å™¨ï¼Œä½†åªç”Ÿæˆç”¨æˆ·æŒ‡å®šå‚æ•°å¯¹çš„ç­‰é«˜çº¿å›¾
        all_parameters = [param["name"] for param in search_space_dict]
        contour_plots = analyzer.create_contour_plots(
            parameters=all_parameters,  # ä¼ å…¥æ‰€æœ‰å‚æ•°ï¼Œç¡®ä¿ä¼˜åŒ–å™¨æœ‰å®Œæ•´æ•°æ®
            objectives=[request.objective],
            search_space=search_space_dict,
            surrogate_model_class=surrogate_model_cls,
            kernel_class=kernel_cls,
            kernel_options=request.kernel_options,
            target_parameter_pairs=[(request.parameter1, request.parameter2)],  # åªç”Ÿæˆç”¨æˆ·æŒ‡å®šå‚æ•°å¯¹çš„ç­‰é«˜çº¿å›¾
            target_objectives=[request.objective]  # åªç”Ÿæˆç”¨æˆ·æŒ‡å®šç›®æ ‡çš„ç­‰é«˜çº¿å›¾
        )
        
        # ä½¿ç”¨JSONæ•°ç»„æ ¼å¼å‘½åï¼šcontour_["ç›®æ ‡","å‚æ•°1","å‚æ•°2"]
        plot_name = f'contour_["{request.objective}","{request.parameter1}","{request.parameter2}"]'
        # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†ç”¨æˆ·æŒ‡å®šçš„ç­‰é«˜çº¿å›¾
        if plot_name in analyzer.plots:
            # ä¿å­˜å›¾è¡¨å¹¶è·å–å®é™…ä¿å­˜è·¯å¾„
            # æ³¨ï¼šanalysis.pyå†…éƒ¨å·²ä¿å­˜ä¸€æ¬¡ï¼Œè¿™é‡Œå†æ¬¡ä¿å­˜ä»¥ç¡®ä¿è·å¾—å‡†ç¡®çš„æ–‡ä»¶è·¯å¾„
            saved_path = analyzer.save_single_plot(plot_name, analyzer.plots[plot_name])
            
            # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶ID
            file_id = str(uuid.uuid4())
            filename = f"{plot_name}.html"
            
            # å­˜å‚¨æ–‡ä»¶æ˜ å°„åˆ°å°æ–‡ä»¶
            metadata = {
                "path": str(saved_path),
                "filename": filename,
                "type": "contour",
                "created_at": datetime.now().isoformat()
            }
            save_single_chart_metadata(file_id, metadata)
            
            # æ„å»ºæŸ¥çœ‹é“¾æ¥
            view_link = {
                "name": plot_name,
                "url": f"/chart/{file_id}",
                "type": "contour"
            }
            
            # æ„å»ºå“åº”æ¶ˆæ¯
            message = f"æˆåŠŸç”Ÿæˆç­‰é«˜çº¿å›¾: {request.parameter1} vs {request.parameter2} for {request.objective}"
            if request.surrogate_model_class or request.kernel_class:
                custom_components = []
                if request.surrogate_model_class:
                    custom_components.append(f"ä»£ç†æ¨¡å‹:{request.surrogate_model_class}")
                if request.kernel_class:
                    custom_components.append(f"æ ¸å‡½æ•°:{request.kernel_class}")
                message += f"ï¼Œä½¿ç”¨{'+'.join(custom_components)}"
            
            return SinglePlotResponse(
                success=True,
                message=message,
                plot_name=plot_name,
                view_link=view_link
            )
        else:
            return SinglePlotResponse(
                success=False,
                message=f"æœªèƒ½ç”ŸæˆæŒ‡å®šçš„ç­‰é«˜çº¿å›¾: {request.parameter1} vs {request.parameter2} for {request.objective}",
                plot_name="",
                view_link={}
            )
            
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"âŒ ç­‰é«˜çº¿å›¾åˆ†æå¤±è´¥è¯¦ç»†é”™è¯¯:\n{error_details}")
        raise HTTPException(status_code=500, detail=f"ç­‰é«˜çº¿å›¾åˆ†æå¤±è´¥: {str(e)}")

if __name__ == "__main__":
    # å•è¿›ç¨‹å¯åŠ¨ï¼ˆç”¨äºå¼€å‘æµ‹è¯•ï¼‰
    # ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨å‘½ä»¤è¡Œå¯åŠ¨å¤šè¿›ç¨‹ï¼šuvicorn api_parameter_optimizer_v3:app --host 0.0.0.0 --port 3320 --workers 4
    print("ğŸš€ å¯åŠ¨APIæœåŠ¡ï¼ˆå•è¿›ç¨‹æ¨¡å¼ï¼‰")
    print("ğŸ’¡ æç¤ºï¼šç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨å¤šè¿›ç¨‹ï¼š")
    print("   uvicorn api_parameter_optimizer_v3:app --host 0.0.0.0 --port 3320 --workers 4")
    uvicorn.run(app, host="0.0.0.0", port=3320)
